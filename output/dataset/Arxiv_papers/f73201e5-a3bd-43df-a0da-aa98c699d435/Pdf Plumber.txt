Conformalized Ordinal Classification with Marginal and
Conditional Coverage
Subhrasish Chakraborty1, Chhavi Tyagi1, Haiyan Qiao2, and Wenge Guo∗1
1Department of Mathematical Sciences, New Jersey Institute of Technology
2School of Computer Science & Engineering, California State University San Bernardino
April 26, 2024
Abstract
Conformal prediction is a general distribution-free approach for constructing prediction sets combined
with any machine learning algorithm that achieve valid marginal or conditional coverage in finite samples.
Ordinal classification is common in real applications where the target variable has natural ordering
among the class labels. In this paper, we discuss constructing distribution-free prediction sets for such
ordinal classification problems by leveraging the ideas of conformal prediction and multiple testing with
FWER control. Newer conformal prediction methods are developed for constructing contiguous and
non-contiguous prediction sets based on marginal and conditional (class-specific) conformal p-values,
respectively. Theoretically, we prove that the proposed methods respectively achieve satisfactory levels of
marginal and class-specific conditional coverages. Through simulation study and real data analysis, these
proposed methods show promising performance compared to the existing conformal method.
KEY WORDS: Conformal prediction, ordinal classification, multiple testing, FWER control, marginal
coverage, class-specific conditional coverage
1 Introduction
Ordinal classification, also known as ordinal regression or ordinal prediction, is a machine learning task that
involves predicting a target variable with ordered categories (McCullagh, 1980; Agresti, 2010). In ordinal
classification, the target variable has a natural ordering or hierarchy among its categories, but the intervals
between the categories may not be evenly spaced or defined. Unlike regular classification, where the classes
are nominal and unordered, ordinal classification takes into account the ordering relationship between the
classes. This makes it suitable for situations where the outcome variable has multiple levels of severity,
satisfaction ratings, or rankings. Here are a few examples of ordinal classification: customer satisfaction
levels, movie ratings, disease severity levels, and education levels (Agresti, 2010).
Inordinalclassification,thegoalistolearnamodelthatcanaccuratelypredicttheordinalvariable’svalue
given a set of input features. The model needs to understand the ordering of the classes and make predictions
∗Authore-mailaddresses: sc2325@njit.edu,ct364@njit.edu,hqiao@csusb.edu,wenge.guo@njit.edu
1
4202
rpA
52
]EM.tats[
1v01661.4042:viXrathat respect this order. In the literature, some conventional classification algorithms have been adapted
or modified to address ordinal classification, for example, ordinal logistic regression, SVM, decision trees,
random forest, and neural networks (Harrell, 2015; da Costa et al., 2010; Kramer et al., 2001; Janitza et al.,
2016; Cheng et al., 2008). Some alternative methods are also specifically developed for ordinal classification
problemsbyfullyexploitingtheordinalstructureoftheresponsevariables(FrankandHall,2001;Cardosoand
da Costa, 2007; Gutiérrez et al., 2015). However, these existing methods can only provide point prediction,
which is not adequate in some high stakes areas such as medical diagnosis and automatic driving. Uncertainty
quantification (UQ) techniques aim to go beyond point predictions and provide additional information about
the reliability of these predictions. There are various techniques for UQ in machine learning, including
Bayesian methods, calibration, and conformal prediction (Hüllermeier and Waegeman, 2021).
Conformal prediction is a unique distribution-free UQ technique that provides a prediction set rather
than a point prediction for the true response with guaranteed coverage (Vovk et al., 1999, 2005; Shafer and
Vovk, 2008; Angelopoulos and Bates, 2021; Fontana et al., 2023). It can be used as a wrapper with any
black-box algorithm. In this paper, we use the conformal prediction technique to construct prediction sets for
ordinal classification problems. By combining the ideas of conformal prediction and multiple testing, two new
conformal prediction methods are introduced for constructing contiguous and non-contiguous prediction sets.
Firstly, the problem of ordinal classification is reformulated as a problem of multiple testing; Secondly, for
each constructed hypothesis, the marginal and conditional conformal p-values are respectively calculated;
Thirdly, based on these marginal (conditional) conformal p-values, three multiple testing procedures are
developed for controlling marginal (conditional) familywise error rate (FWER); Finally, based on the testing
outcomes of these procedures, the prediction sets are constructed and proved having guaranteed marginal
(conditional) coverage.
There are almost no works of applying conformal prediction to address ordinal classification in the
literature. To our knowledge, Lu et al. (2022) is the only existing work, in which, a new (split) conformal
predictionmethodisdevelopedforconstructingadaptivecontiguouspredictionregion. Thismethodisproved
tohaveguaranteedmarginalcoverage,however,itcannotguaranteetohavemoredesiredconditionalcoverage.
Moreover, it does not work well for high dimensional data. Compared to the method introduced in Lu et al.
(2022), our proposed methods generally show via theoretical and numerical studies performing better in the
settings of higher dimensions and in terms of class-specific conditional coverage; especially for the conditional
conformal p-values based methods, they are proved to have guaranteed conditional coverage.
The rest of this paper is structured as follows. In Section 2, we briefly introduce split-conformal prediction
and review related works, followed by Section 3 which presents the development of our proposed conformal
methods using the idea of multiple testing. Section 4 provides numerical studies to evaluate the performance
of the proposed methods compared to the existing method. Some discussions are presented in Section 5 and
all proofs
2 Preliminaries
In this section, we briefly describe the conformal prediction framework and review the related literature.
22.1 Conformal Prediction
Conformal prediction is a general approach to construct prediction sets combined with a pre-trained classifier.
Themainadvantageofthisapproachisthatitisdistribution-freeandcanworkwithanyblack-boxalgorithm.
Conformal prediction is broadly of two types – full conformal prediction and split-conformal prediction. The
full conformal prediction uses all the observations to train the black-box algorithms (Vovk et al., 2005). In
contrast,split-conformalprediction(Papadopoulosetal.,2002)involvessplittingthetrainingdataintoproper
training data to train the black-box algorithm and calibration data to calculate the threshold for forming
prediction sets. Our proposed methods are based on the split-conformal method. Consider a multi-class
classification problem with feature space X and labels Y ={1,2,··· ,K}. Given the training observations
(X ,Y )2n and a test input X , the goal is to find a prediction set C(X ):X (cid:55)→2Y that contains the
i i i=1 2n+1 2n+1
unknown response Y with enough statistical coverage.
2n+1
Thesplit-conformalproceduresuggeststosplit2nobservationstontrainingobservations, i.e., (X ,Y )n ,
i i i=1
which are used to train fˆ, a black-box classifier such that fˆ: X (cid:55)→ Y and the remaining n observations
(X ,Y )2n for calibration. The central part of this technique involves calculating the conformity scores for
i i i=n+1
each observation, which measures how much the test observation conforms with the calibration observations.
There can be several choices of conformity scores for multi-class classification problem, including posterior
classprobability, cumulativeprobability, andregularizedcumulativeprobability(Sadinleetal.,2019;Romano
et al., 2020; Angelopoulos et al., 2020). Given the score function s:X ×Y (cid:55)→R, the conformity score for the
ith calibration observation is defined as s =s(X ,Y ), i=n+1,··· ,2n.
i i i
For a test input X , we compute the conformity score for each class label. Therefore, for a class label
2n+1
y ∈ Y the conformity score corresponding to (X ,y) is s = s(X ,y). By using the conformity
2n+1 2n+1 2n+1
scores obtained for the calibration observations and the test input coupled with a given label y, we can
calculate the conformal p-value to test whether the unknown true label Y corresponding to the test input
2n+1
X is y or not. The (marginal) conformal p-value is defined as,
2n+1
2n
(cid:80) I(s ≤s )+1
2n+1 i
p(X ,y)= i=n+1 . (1)
2n+1 n+1
The final step involves constructing the prediction set C(X )={y :p(X ,y)≥α}, which satisfies
2n+1 2n+1
P(Y ∈C(X ))≥1−α, (2)
2n+1 2n+1
when the calibration and test observations (X ,Y )2n+1 are exchangeably distributed, where α∈(0,1) is a
i i i=n+1
pre-specified mis-coverage level. Equation (2) is called marginal validity of the prediction set C(X ). It
2n+1
guarantees that the true label Y is contained in the prediction set with 100(1−α)% confidence. Vovk
2n+1
(2012) introduced another type of conformal p-value which is called as the conditional conformal p-value. Let
D ={n+1,...,2n}denotetheindicesofthecalibrationobservations(X ,Y )2n . ForatestinputX
cal i i i=n+1 2n+1
and any class y =1,...,K, the (class-specific) conditional conformal p-value given Y =y is defined as
2n+1
(cid:80) I{s ≤s }+1
p(X |y)= i∈Iy i 2n+1 , (3)
2n+1 n +1
y
where I ={i∈D :Y =y}, n =|I | is the size of I , and s =s(X ,y) for i=n+1,...,2n+1.
y cal i y y y i i
3In general, the concept of conditional coverage such as object conditional validity and class-specific
conditional validity are more relevant to practical applications (Vovk, 2012; Lei, 2014; Barber et al., 2021).
If it is satisfied, the more desired results are often guaranteed. Specifically, in classification problems,
class-specific conditional validity provides conditional coverage for each given class, which is defined as
P(Y ∈C(X )|Y =y)≥1−α (4)
2n+1 2n+1 2n+1
for any y =1,...,K. Proposition 1 and 2 below ensure that the marginal and conditional conformal p-values
are valid, which result in desired marginal and (class-specific) conditional coverage.
To simplify the notation, we let Z =(X ,Y ) for i=1,...,2n+1 and denote the conformity scores of
i i i
the calibration data, {Z }2n , as s ’s, and the conformity score of the test data, Z =(X ,Y ),
i i=n+1 i 2n+1 2n+1 2n+1
as s , where Y is unknown. These notations are used in all propositions and theorems presented in
2n+1 2n+1
this paper.
Proposition 1. Suppose that {Z }2n+1 where Z = (X ,Y ) are exchangeable random variables, then the
i i=1 i i i
marginal conformal p-values defined below as,
(cid:80)2n I(s ≤s )+1
p(Z )= i=n+1 i 2n+1 (5)
2n+1 n+1
is valid in the sense that for any t∈[0,1], we have
P(p(Z )≤t)≤t.
2n+1
(cid:110) (cid:111)
Moreover, if the conformity scores {s }2n+1 are distinct surely, we have p(Z )∼U 1 ,··· ,1 .
i i=n+1 2n+1 n+1
Proposition 2. Suppose that {Z }2n+1 where Z = (X ,Y ) are exchangeable random variables, then for
i i=1 i i i
any y ∈ Y, given I ⊆ D and Y = y, the corresponding conditional conformal p-value as defined in
y cal 2n+1
equation (3), is conditionally valid in the sense that for any t∈[0,1],
P(cid:0)
p(X 2n+1|y)≤t
(cid:12)
(cid:12) I y,Y 2n+1
=y(cid:1)
≤t.
Moreover, if {s } are distinct surely, we have that conditional on I and Y =y,
i i∈Iy∪{2n+1} y 2n+1
(cid:110) 1 (cid:111)
p(X |y)∼U ,··· ,1 .
2n+1 n +1
y
2.2 Related work
The framework of Conformal prediction was introduced by Vladimir Vovk and his collaborators Vovk et al.
(1999, 2005) and has found many applications in classification problems. Shafer and Vovk (2008) and
Angelopoulos and Bates (2021) provided a tutorial introduction and brief literature review on this field.
Several conformal methods have been developed to address binary classification (Lei, 2014) and multi-class
classification problems (Hechtlinger et al., 2018; Sadinle et al., 2019; Romano et al., 2020; Angelopoulos et al.,
2020; Tyagi and Guo, 2023). Coverage guarantees of all these methods are established under the assumption
ofexchangeability. Veryrecently, somenewconformalpredictionmethodshavebeendevelopedinthesettings
of non-exchangeability (Tibshirani et al., 2019; Cauchois et al., 2021; Gibbs and Candes, 2021).
4Although various conformal prediction methods have been developed for conventional classification
problems, however, to our knowledge, Lu et al. (2022) is the only reference that is specifically devoted to
address ordinal classification problems using conformal prediction methods, in which an adaptive conformal
method is developed for constructing contiguous prediction sets for ordinal response and is applied to AI
disease rating in medical imaging. In addition, Xu et al. (2023) is the closely related reference in which newer
methods are developed for two types of loss functions specially designed for ordinal classification in the more
general framework of conformal risk control.
3 Method
In this section, we introduce several new conformal prediction methods for ordinal classification problems, in
which there is a natural ordering among the classes labels. For simplicity, we assume a descending order of
priority from class 1 to K in the response space Y ={1,2,··· ,K}.
3.1 Problem Formulation
We formulate the ordinal classification problem as a multiple testing problem. Specifically, by using the
One-vs-All (OVA) strategy (Rifkin and Klautau, 2004), for each class label, we construct a hypothesis to test
whether or not a given test input X belongs to the particular class. The construction of the hypothesis
2n+1
is described as follows,
H :Y =i vs H′ :Y ̸=i, (6)
i 2n+1 i 2n+1
for i=1,··· ,K. It is easy to see that all these hypotheses are random and there is only one true null. To
test each individual hypothesis H , we use the corresponding marginal conformal p-value p(X ,i); to test
i 2n+1
H ,...,H simultaneously, we consider the following three p-value-based testing procedures:
1 K
• Procedure 1 : Test H ,H ,··· ,H sequentially. The test is performed as follows.
1 2 K
– If p(X ,1)≤α, reject H , move to test H else stop testing;
2n+1 1 2
– For i=2,··· ,K−1, if p(X ,i)≤α, reject H , move to test H else stop testing;
2n+1 i i+1
– If p(X ,K)≤α, reject H else stop testing.
2n+1 K
• Procedure 2 : Test H ,H ,··· ,H sequentially. The test is performed as follows.
K K−1 1
– If p(X ,K)≤α, reject H , move to test H else stop testing;
2n+1 K K−1
– For i=K−1,··· ,2, if p(X ,i)≤α, reject H , move to test H else stop testing;
2n+1 i i−1
– If p(X ,1)≤α, reject H else stop testing.
2n+1 1
• Procedure 3 : Single-step procedure with common critical value α. This procedure rejects any
hypothesis H if and only if p(X ,i)≤α.
i 2n+1
Procedure 1 and 2 are two pre-ordered testing procedures for which Procedure 1 follows the same testing
order as that of the K classes whereas Procedure 2 uses the reverse order of these classes (Dmitrienko et al.,
2009). Procedure 3 is actually a conventional Bonferroni procedure for a single true null. Since there is only
one true null among the K tested hypotheses, by Proposition 1, we have that all these three (marginal)
5Figure 1: Graphical representation of Ordinal Prediction Interval (OPI) with K nulls where p(i) represents
the conformal p-values.
conformal p-value based procedures strongly control family-wise error rate (FWER) at a pre-specified level α
(Dmitrienko et al., 2009). For each Procedure i,i=1,2,3 defined above, the index set A of the accepted
i
hypotheses is described as follows,
1. A ={y ,y +1,··· ,K}, where y =min{y ∈Y :p(X ,y)>α};
1 min min min 2n+1
2. A ={1,2,··· ,y }, where y =max{y ∈Y :p(X ,y)>α};
2 max max 2n+1
3. A ={y :p(X ,y)>α}.
3 2n+1
3.2 Ordinal Prediction Interval
Based on the the acceptance sets A and A of Procedure 1 and 2 given as above, we can obtain a new
1 2
acceptance region A =A ∩A ={y ,...,y }, which is used to define the prediction region C(X )
12 1 2 min max 2n+1
for the unknown response Y . Specifically, the prediction region C(X ) consists of the class labels for
2n+1 2n+1
which the corresponding hypotheses are both accepted by Procedure 1 and 2, resulting in a contiguous set of
labels {y ,...,y }. This prediction region is referred to as a prediction interval in this context. The
min max
procedure for constructing the prediction interval C(X ) is summarized in Algorithm 1 and illustrated in
2n+1
Figure 1.
Algorithm 1: Ordinal Prediction Interval
Input: training set D =(X ,Y )n , calibration set D =(X ,Y )2n , test input X ,
train i i i=1 cal i i i=n+1 2n+1
black-box algorithm A, conformity score function s, mis-coverage level α.
Output: Prediction interval, C(X ).
2n+1
Train a classifier A on D ;
train
for (X ,Y )∈D do
i i cal
Compute conformity score s =s(X ,Y );
i i i
end
For each y ∈Y, compute conformity score s =s(X ,y) and corresponding conformal p-value
2n+1 2n+1
p(X ,y) using equation (1);
2n+1
y =min{y ∈Y :p(X ,y)>α} ;
min 2n+1
y =max{y ∈Y :p(X ,y)>α} ;
max 2n+1
Prediction interval, C(X )={y ,...,y }.}
2n+1 min max
63.3 Ordinal Prediction Set
Our second method for constructing ordinal prediction regions is based on Procedure 3. In this method,
the prediction region C(X ) is defined simply using the acceptance region A of Procedure 3, that is,
2n+1 3
C(X ) = {y ∈ Y : p(X ,y) > α}. Specifically, the prediction region consists of any class labels for
2n+1 2n+1
which the corresponding hypotheses are not rejected by Procedure 3, resulting in a non-contiguous set of
labels. This prediction region is referred to as a prediction set in this context. The procedure for constructing
the prediction set is detailed in Algorithm 2 below.
Algorithm 2: Ordinal Prediction Set
Input: training set D =(X ,Y )n , calibration set D =(X ,Y )2n , test observation X ,
train i i i=1 cal i i i=n+1 2n+1
black-box algorithm A, conformity score function s, mis-coverage level α.
Output: Prediction set, C(X ).
2n+1
Train a classifier A on D ;
train
for (X ,Y )∈D do
i i cal
Compute conformity score s =s(X ,Y );
i i i
end
For each y ∈Y, compute conformity score s =s(X ,y) and corresponding conformal p-value
2n+1 2n+1
p(X ,y) using equation (1);
2n+1
Prediction Set, C(X )={y :p(X ,y)>α}.
2n+1 2n+1
Inthefollowing,wepresenttworesultsregardingtheFWERcontrolofProcedure1-3and(marginal)coverage
guarantees of Algorithm 1-2 introduced as above.
Proposition 3. Suppose that (X ,Y )2n+1 are exchangeable random variables, then Procedure 1-3 based on
i i i=n+1
marginal conformal p-values, all strongly control the FWER at level α, i.e., FWER≤α. Specifically, if the
conformity scores {s }2n+1 are distinct surely, then for Procedure 3, we also have, FWER≥α− 1 .
i i=n+1 n+1
Theorem 1. Suppose that (X ,Y )2n+1 are exchangeable random variables, then the prediction region
i i i=n+1
C(X ) determined by Algorithm 1 and 2 both satisfy
2n+1
P(Y ∈C(X ))≥1−α.
2n+1 2n+1
Specifically, for C(X ) determined by Algorithm 2, if the conformity scores {s }2n+1 are distinct surely,
2n+1 i i=n+1
we have
1
P(Y ∈C(X ))≤1−α+ .
2n+1 2n+1 n+1
3.4 Class-specific conditional coverage
To achieve more desired class-specific conditional coverage for our constructed prediction intervals and
predictionsets,inProcedure1-3weuse(class-specific)conditionalconformalp-valuesp(X |y)asdescribed
2n+1
inequation(3), insteadofthemarginalconformalp-valuesp(X ,y)forsimultaneouslytestingH ,...,H
2n+1 1 K
formulatedinequation(6). ItisshowninProposition4belowthatallthesethreemodifiedproceduresstrongly
control the conditional familywise error rate (FWER) at level α, i.e., FWER =P(V >0|Y =y)≤α,
y 2n+1
for any y ∈ Y, where V is the number of type 1 errors. This result in turn leads to that the prediction
7regionsC(X |y)constructedbyAlgorithm1and2basedonp(X |y)satisfymoredesired(class-specific)
n+1 2n+1
conditional coverage, as stated in Theorem 2.
Proposition 4. Under the same exchangeability assumption as in Proposition 2, Procedure 1-3 based on
conditional conformal p-values p(X |y) all strongly control the conditional FWER at level α, i.e., for any
2n+1
y ∈Y,
FWER =P{reject H |Y =y}≤α.
y y 2n+1
Specifically, if the conformity scores {s } are distinct surely, then for Procedure 3 based on
i i∈Iy∪{2n+1}
p(X |y), we have that for any y ∈Y and I ⊆D .
2n+1 y cal
1
P(reject H |Y =y,I )≥α− .
y 2n+1 y n +1
y
Theorem 2. Under the same exchangeability assumption as in Theorem 1, the prediction region C(X |y)
2n+1
determined by Algorithm 1 or 2 based on conditional conformal p-values p(X |y) satisfies
2n+1
P(cid:0)
Y
2n+1
∈C(X 2n+1|y)
(cid:12)
(cid:12)Y
2n+1
=y(cid:1)
≥1−α
for any y ∈Y. Specifically, for the prediction set C(X |y) determined by Algorithm 2 based on p(X |y),
n+1 2n+1
if the conformity scores {s } are distinct surely, we have
i i∈Iy∪{2n+1}
P(cid:0)
Y
2n+1
∈C(X 2n+1|y)
(cid:12)
(cid:12)Y
n+1
=y,I
y(cid:1)
≤1−α+
n
1
+1
y
for any y ∈Y and I ⊆D .
y cal
4 Numerical Study
In this section, we evaluate the performance of our four proposed methods, Ordinal Prediction Interval
(OPI) in Algorithm 1 based on marginal conformal p-values (marginal OPI), the OPI based on conditional
conformal p-values (conditional OPI), Ordinal Prediction Set (OPS) in Algorithm 2 based on marginal
conformal p-values (marginal OPS), and the OPS based on conditional conformal p-values (conditional OPS),
in comparison with the existing counterpart developed in Lu et al. (2022), Ordinal Adaptive Prediction
Set (OAPS), on simulated data and one real dataset. The comparison is based on the marginal coverage,
average set size, and class-specific conditional coverage of the prediction regions for a pre-specified level α.
The empirical metric we use to measure the class-specific conditional coverage (CCV) of the above methods
is defined as
CCV = max {(1−α)−P ,0},
y
y∈{1,2,···,K}
where P is the estimate of P(Y ∈ C(X |y) |Y = y) and C(X |y) is the prediction region obtained
y 2n+1 2n+1
from Algorithm 1 or 2 using conditional conformal p-values for any y ∈Y. Intuitively, the metric measures
the maximum of the deviance of the conditional coverage for each of the classes from the desired level of
conditional coverage 1−α.
In the whole numerical investigations including simulation studies and real data analysis, we use the
logistic regression algorithm as the black-box algorithm for our experiments and compute the conformity
scores as estimated posterior probabilities of classes.
8Figure 2: Performance comparison of four proposed methods OPS and OPI using marginal and conditional
conformal p-values with the existing Ordinal APS under simulation setting 1 in terms of marginal coverage
(left), average set size (middle) and class-specific conditional coverage (right) of the prediction sets.
4.1 Simulations
We present the simulation study to evaluate the performance of our proposed methods along with the existing
method. We consider two simulation settings below, a Gaussian mixture model and a sparse model.
1. Gaussian mixture. (X|Y = k) ∼ π N (µ ,Σ)+π N (µ ,Σ) for k = 1,2,3 and (X|Y = 4) ∼
1 d k 2 d k+1
π N(µ ;Σ)+π N(µ ;Σ) with π =0.2,π =0.8.
1 4 2 1 1 2
In the above setting, we set d = 2, µ = (−1,0), µ = (−1,−1), µ = (0,−1), µ = (1,−1), and Σ as the
1 2 3 4
equal correlation matrix with correlation =0.1.
2. Sparse model. The sparse model is generated with different dimensions of feature vector with
d = 5,10,20,50, or 100. The features are generated with X ∼ N(0,1) with Cov(X ,X ) = 0.5 for i ̸= j.
i i j
The class labels are generated using the sigmoid function f(x) and the the following decision rule,
k−1 k
Y =k if ≤f(x )< , where k =1,2,3,4,
i 4 i 4
where f(x) = 1/(1+e−β′ x) with β = (β ,··· ,β )′ and x = (x ,...,x )′. The value of β is set as
1 d 1 d
√
(β ,...,β )=(1,1,1,− 2,1), and β =0 for any 5<i≤d.
1 5 i
The sample size for these two simulation settings is 2,000, out of which 500 samples have been used to
train the classifier, 525 observations for calibration, and 975 for validation. The simulations are repeated 500
times, and the results are averaged to obtain the final performance metrics.
Figure 2 displays the performance of our proposed methods along with the existing method under
simulation setting 1. It can be seen from the left panel of Figure 2 that all these five methods empirically
achieve the desired level of marginal coverage. The middle panel of Figure 2 compares the set sizes of the
prediction regions corresponding to these five methods. It can be seen from the figure that the marginal OPS
and the conditional OPS use shorter set sizes to attain the proper marginal coverage than the existing OAPS
whereas the OAPS has shorter set sizes than the marginal OPI and the conditional OPI. Finally, while the
marginal coverage is guaranteed by all the methods, the right panel of Figure 2 shows their differences in
class-specific conditional coverage; the existing OAPS exhibits the largest value of CCV compared to the
proposed methods and among the four proposed methods, the conditional OPI and conditional OPS exhibit
lower values of CCV than the marginal OPI and marginal OPS.
9Figure 3: Performance comparison of four proposed methods with existing Ordinal APS under simulation
setting2withdifferentdimensionsofinputsandfixedmis-coveragelevelα=0.1intermsofmarginalcoverage
(left), average set size (middle) and CCV (right) of the prediction sets.
Figure3showstheperformanceofourproposedmethodsalongwiththeexistingmethodundersimulation
setting 2 with different dimensions of inputs. It can be seen from the left panel of this figure that all these
methods empirically achieve desired marginal coverage for lower dimensions, however, the existing OAPS
massively undercovers for higher dimensions and thus loses the control of mis-coverage rate. From the middle
and right panels of Figure 3, we can also see that the conditional OPI and conditional OPS achieve lower
valuesofCCVthantheexistingOAPS,althoughtheOAPShasthelowersetsizesthanourproposedmethods
for various dimensions of input.
4.2 Application to real data
We also evaluate the performance of our proposed methods on a real dataset, Traffic accident data, which
is publicly available on the website of Leeds City Council. The real data consists of 1,908 traffic accidents
that occurred in the year 2019. The objective is to predict the severity of the casualties, which are classified
into three categories – mild, serious, and fatal based on the features available. In the numerical experiment,
500 observations are used to train the logistic regression model, 35% of the remaining observations are used
for calibration, and 65% for validation. Figure 4 shows that all these methods empirically achieve desired
marginalcoveragefordifferentlevelsofmis-coverage, however, theproposedmarginalOPIandmarginalOPS,
and existing OAPS have lower set sizes than the conditional OPI and conditional OPS. It is also evident
from Figure 4 that the proposed conditional OPS and conditional OPI both attain desired class-specific
conditional coverage unlike the existing method, OAPS, which seems to largely deviate from the desired level
of conditional coverage.
5 Concluding Remarks
In this paper, we discussed the ordinal classification problem in the framework of conformal prediction and
introduced two types of conformal methods, OPI and OPS, for constructing distribution-free contiguous
predictionregionsandnon-contiguous predictionsets,respectively. Thesemethodsaredevelopedbyleveraging
the idea of multiple testing with the FWER control andare specifically designed based on marginalconformal
p-values and (class-specific) conditional conformal p-values, respectively. Theoretically, it was proved that
10Figure 4: Performance comparison of four proposed methods OPS and OPI using marginal and conditional
conformal p-values with the existing Ordinal APS in terms of marginal coverage (left), average set size
(middle) and CCV (right) of the prediction regions for Traffic Accident Data.
the proposed methods based on marginal and conditional p-values respectively achieve satisfactory levels of
marginalandclass-specificconditionalcoverages. Throughsomenumericalinvestigationsincludingsimulations
and real data analysis, our proposed methods show promising results for the settings of higher dimensions
and for class-specific conditional coverage.
This paper discussed constructing valid prediction set for single test input. It would be interesting to
discusshowtoconstruct(simultaneous)predictionsetsformultipletestinputswithsomeoverallerrorcontrol
such as false discovery rate (FDR) control. Another interesting extension might be to relax the conventional
distributional assumption we used for classification problems, for which the training data and the test data
followfromthesamedistribution. Itwillbeinterestingtoseewhethertheproposedmethodscanbeextended
to the settings of distribution shift where the training and test data sets have different distributions.
References
Alan Agresti. Analysis of ordinal categorical data. John Wiley & Sons, 2010.
A.N. Angelopoulos and S. Bates. A gentle introduction to conformal prediction and distribution-free
uncertainty quantification. arXiv preprint arXiv:2107.07511, 2021.
Anastasios Angelopoulos, Stephen Bates, Jitendra Malik, and Michael I. Jordan. Uncertainty sets for image
classifiers using conformal prediction. arXiv preprint arXiv:2009.14193, 2020.
RinaFoygelBarber,EmmanuelJCandes,AadityaRamdas,andRyanJTibshirani. Thelimitsofdistribution-
free conditional predictive inference. Information and Inference: A Journal of the IMA, 10(2):455–482,
2021.
Jaime Cardoso and Joaquim Pinto da Costa. Learning to classify ordinal data: The data replication method.
Journal of Machine Learning Research, 8:1393–1429, 2007.
MaximeCauchois,SuyashGupta,andJohnCDuchi. Knowingwhatyouknow: validandvalidatedconfidence
sets in multiclass and multilabel prediction. The Journal of Machine Learning Research, 22(1):3681–3722,
2021.
11Jianlin Cheng, Zheng Wang, and Gianluca Pollastri. A neural network approach to ordinal regression. In
2008 IEEE International Joint Conference on Neural Networks, pages 1279–1284. IEEE, 2008.
Joaquim F Pinto da Costa, Ricardo Sousa, and Jaime S Cardoso. An all-at-once unimodal svm approach
for ordinal classification. In 2010 Ninth International Conference on Machine Learning and Applications,
pages 59–64. IEEE, 2010.
Alex Dmitrienko, Ajit C Tamhane, and Frank Bretz. Multiple testing problems in pharmaceutical statistics.
CRC press, 2009.
Matteo Fontana, Gianluca Zeni, and Simone Vantini. Conformal prediction: a unified review of theory and
new challenges. Bernoulli, 29(1):1–23, 2023.
Eibe Frank and Mark Hall. A simple approach to ordinal classification. In 12th European Conference on
Machine Learning, Proceedings 12, pages 145–156. Springer, 2001.
Isaac Gibbs and Emmanuel Candes. Adaptive conformal inference under distribution shift. Advances in
Neural Information Processing Systems, 34:1660–1672, 2021.
Pedro Antonio Gutiérrez, Maria Perez-Ortiz, Javier Sanchez-Monedero, Francisco Fernandez-Navarro, and
Cesar Hervas-Martinez. Ordinal regression methods: survey and experimental study. IEEE Transactions
on Knowledge and Data Engineering, 28(1):127–146, 2015.
Frank E Harrell. Ordinal logistic regression. In Regression modeling strategies: with applications to linear
models, logistic and ordinal regression, and survival analysis, pages 311–325. Springer, 2015.
Yotam Hechtlinger, Barnabás Póczos, and Larry Wasserman. Cautious deep learning. arXiv preprint
arXiv:1805.09460, 2018.
Eyke Hüllermeier and Willem Waegeman. Aleatoric and epistemic uncertainty in machine learning: an
introduction to concepts and methods. Machine Learning, 110:457–506, 2021.
Silke Janitza, Gerhard Tutz, and Anne-Laure Boulesteix. Random forest for ordinal responses: prediction
and variable selection. Computational Statistics & Data Analysis, 96:57–73, 2016.
Stefan Kramer, Gerhard Widmer, Bernhard Pfahringer, and Michael De Groeve. Prediction of ordinal classes
using regression trees. Fundamenta Informaticae, 47(1-2):1–13, 2001.
J. Lei. Classification with confidence. Biometrika, 101(4):755–769, 2014.
C. Lu, A.N. Angelopoulos, and S. Pomerantz. Improving trustworthiness of ai disease rating in medical
imaging with ordinal conformal prediction sets. arXiv preprint arXiv:2207.02238, 2022.
Peter McCullagh. Regression models for ordinal data. Journal of the Royal Statistical Society B, 42:109–142,
1980.
Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman. Inductive confidence machines
for regression. In 13th European Conference on Machine Learning, Proceedings 13, pages 345–356. Springer,
2002.
12Ryan Rifkin and Aldebaro Klautau. In defense of one-vs-all classification. The Journal of Machine Learning
Research, 5:101–141, 2004.
Y. Romano, M. Sesia, and E. Candès. Classification with valid and adaptive coverage. In Advances in Neural
Information Processing Systems, volume 33, pages 3581–3591, 2020.
M. Sadinle, J. Lei, and L. Wasserman. Least ambiguous set-valued classifiers with bounded error levels.
Journal of American Statistical Association, 114:223–234, 2019.
G.ShaferandV.Vovk. Atutorialonconformalprediction. Journal of Machine Learning Research, 9:371–421,
2008.
Ryan J Tibshirani, Rina Foygel Barber, Emmanuel Candes, and Aaditya Ramdas. Conformal prediction
under covariate shift. Advances in Neural Information Processing Systems, 32, 2019.
Chhavi Tyagi and Wenge Guo. Multi-label classification under uncertainty: a tree-based conformal prediction
approach. In Conformal and Probabilistic Prediction with Applications, pages 488–512. PMLR, 2023.
V. Vovk, A. Gammerman, and G. Shafer. Algorithmic learning in a random world. Springer, 2005.
Vladimir Vovk. Conditional validity of inductive conformal predictors. In Asian Conference on Machine
Learning, pages 475–490. PMLR, 2012.
Vladimir Vovk, Alex Gammerman, and Craig Saunders. Machine-learning applications of algorithmic
randomness. In Sixteenth International Conference on Machine Learning, pages 444–453, 1999.
Yunpeng Xu, Wenge Guo, and Zhi Wei. Conformal risk control for ordinal classification. In Uncertainty in
Artificial Intelligence, pages 2346–2355. PMLR, 2023.
13A Proofs
A.1 Proof of Proposition 1
Proof. Suppose,foranygivenvaluesofconformityscores,v ,··· ,v ,theycanberearrangedasv˜ <···<v˜
1 n+1 1 k
with repetitions n of v˜ such that (cid:80)k n = n+1. Let E denote the event of {s ,··· ,s } =
i i i=1 i v n+1 2n+1
{v ,··· ,v }. Then, under E , for i=1,··· ,k, we have
1 n+1 v
n
P(s =v˜|E )= i ,
2n+1 i v n+1
due to the exchangeability of s ’s,
i
We also note that under E and s =v˜ we have from equation (5),
v 2n+1 i
(cid:80)i
n
p(Z )= l=1 l. (7)
2n+1 n+1
Then, for any t∈[0,1] and i=1,··· ,k, we have
 0 if t< (cid:80)i l=1nl,
P(p(Z )≤t|E ,s =v˜)= n+1 (8)
2n+1 v 2n+1 i
1 o.w.
Thus, for any i=1,··· ,k and (cid:80) li =− 11nl ≤t< (cid:80)i l=1nl, we have
n+1 n+1
P(p(Z )≤t|E )
2n+1 v
k
(cid:88)
= P(p(Z )≤t|E ,s =v˜)·P(s =v˜|E )
2n+1 v 2n+1 l 2n+1 l v
l=1
(cid:80)i−1n
= l=1 l ≤t.
n+1
Bytakingtheexpectationontheaboveinequality,itfollowsthattheconformalp-valuep(Z )ismarginally
2n+1
valid.
Specifically,ifconformityscores{s }2n+1 aredistinctsurely,thenk =n+1andn =1fori=1,...,n+1.
i i=n+1 i
Thus,
P(p(Z )≤t|E )= i−1, if i−1 ≤t< i ,
2n+1 v n+1 n+1 n+1
that is,
(cid:110) 1 (cid:111)
p(Z )|E ∼U ,··· ,1 .
2n+1 v n+1
This completes the proof.
A.2 Proof of Proposition 2
Proof. For any given y ∈Y, the corresponding (class-specific) conditional conformal p-value is given by
 
1 (cid:88)
p(X 2n+1|y)= n +1 I{s i ≤s 2n+1}+1, (9)
y
i∈Iy
14where I ={i:(X ,Y )∈D ,Y =y}, n =|I |, s =s(X ,y) for i∈I , and s =s(X ,y). Given
y i i cal i y y i i y 2n+1 2n+1
I and Y = y, (X ) ∪{X } are exchangeably distributed, which is due to the assumption that
y 2n+1 i i∈Iy 2n+1
(X ,Y )2n+1 are exchangeably distributed. Using the similar arguments as in the proof of Proposition 1, for
i i i=1
any given values of v ,··· ,v , suppose that they can be arranged as v˜ <···<v˜ with repetitions m of
1 ny+1 1 l i
v˜ such that (cid:80)l m =n +1.
i i=1 i y
Let E denote the event {s } ∪{s } = {v ,··· ,v }. Then, given E ,I , and Y = y, we
v i i∈Iy 2n+1 1 ny+1 v y 2n+1
have
m
P(s =v˜|E ,I ,Y =y)= i
2n+1 i v y 2n+1 n +1
y
for i=1,··· ,l and y =1,··· ,K, due to exchangeability of s , i∈I ∪{2n+1} given I , which in turn is
i y y
due to exchangeability of (X ,Y )2n+1. Note that given E , I , Y = y, and s = v˜, we have from
i i i=1 v y 2n+1 2n+1 i
equation (9),
(cid:80)i
m
p(X |y)= j=1 j .
2n+1 n +1
y
Thus, for any t∈[0,1] and i=1,··· ,l,
P(cid:0) p(X 2n+1|y)≤t(cid:12) (cid:12)E v,I y,Y
2n+1
=y,s
2n+1
=v˜ i(cid:1)
= 0 if t< (cid:80) ni j= y+1m 1j,
(10)
1 o.w.
Then, for any given i=1,··· ,l and (cid:80)i j=1mj ≤t< (cid:80)i j+ =1 1mj, we have
ny+1 ny+1
P(cid:0)
p(X
2n+1|y)≤t(cid:12)
(cid:12)E v,I y,Y
2n+1
=y(cid:1)
l
=(cid:88) P(cid:0)
p(X
2n+1|y)≤t(cid:12)
(cid:12)E v,I y,Y
2n+1
=y,s
2n+1
=v˜
i(cid:1) ·P(cid:0)
s
2n+1
=v˜
i(cid:12)
(cid:12)E v,I y,Y
2n+1
=y(cid:1)
j=1
(cid:80)i
m
= j=1 j ≤t.
n +1
y
By taking expectation, it follows that p(X |y) is conditionally valid given Y =y.
2n+1 2n+1
A.3 Proof of Proposition 3
Proof. Consider Procedure 1-3 based on marginal conformal p-values. Note that among the tested hypotheses
H ,...,H , there is exactly one hypothesis H to be true. Thus, the FWER of Procedure 1-3 are all
1 K Y2n+1
equal to
P(reject H )≤P(p(X ,Y )≤α)≤α,
Y2n+1 2n+1 2n+1
where the last inequality follows by Proposition 1.
Specifically, for Procedure 3, if the conformity scores {s }2n+1 are distinct surely, by Proposition 1, we have
i i=n+1
(cid:110) (cid:111) 1
FWER=P(reject H )=P p(X ,Y )≤α ≥α− ,
Y2n+1 2n+1 2n+1 n+1
the desired result.
15A.4 Proof of Theorem 1
Proof. Note that the prediction set derived from Algorithm 1 is given by C(X ) = A ∩A . Thus, by
2n+1 1 2
Proposition 1,
P(Y ∈C(X ))≥P(p(X ),Y )>α)≥1−α.
2n+1 2n+1 2n+1 2n+1
Similarly, for Algorithm 2, its prediction set is given by C(X ) = {y ∈ Y : p(X ,y) > α}. By
2n+1 2n+1
Proposition 1, it is easy to check that
P(Y ∈C(X ))=P(p(X ,Y )>α)≥1−α.
2n+1 2n+1 2n+1 2n+1
Specifically, if the conformity scores {s }2n+1 are distinct surely, for Algorithm 2, we have
i i=1
1
P(Y ∈C(X ))=1−P(p(X ,Y )≤α)≤1−α+ .
2n+1 2n+1 2n+1 2n+1 n+1
This completes the proof.
A.5 Proof of Proposition 4
Proof. Consider Procedure 1-3 based on conditional conformal p-values. For any y = 1,··· ,K, given
Y =y, the conditional FWER of Procedure 1-3 are all equal to
2n+1
P(reject H |Y =y)≤P(p(X |y)≤α|Y =y)≤α,
y 2n+1 2n+1 2n+1
where the inequalities follow the definitions of Procedure 1-3 and Proposition 2.
Specifically, for Procedure 3, if the conformity scores {s } are distinct surely, then by Proposition
i i∈Iy∪{2n+1}
2, the FWER conditional on I and Y =y is equal to
y 2n+1
P(cid:110) reject H
y
(cid:12) (cid:12)I y,Y
2n+1
=y(cid:111) =P(p(X 2n+1|y)≤α|I y,Y
2n+1
=y)≥α−
n
1 +1.
y
This completes the proof.
A.6 Proof of Theorem 2
Proof. By using Proposition 4 and the similar arguments as in the proof of Theorem 1, the prediction sets
C(X |y) derived from Algorithm 1 and 2 based on the conditional conformal p-values p(X |y) all
2n+1 2n+1
satisfy,
P(cid:110)
Y
2n+1
∈C(X 2n+1|y)
(cid:12)
(cid:12)I y,Y
2n+1
=y(cid:111)
≥1−α
for any y =1,...,K. Specifically, if the conformity scores {s } are distinct surely, for Algorithm
i i∈Iy∪{2n+1}
2, we have
P(cid:110)
Y
2n+1
∈C(X 2n+1|y)
(cid:12)
(cid:12)I y,Y
2n+1
=y(cid:111) =P(cid:110)
p(X 2n+1|y)>α
(cid:12)
(cid:12)I y,Y
2n+1
=y(cid:111)
1
≤1−α+ ,
n +1
y
the desired result.
16