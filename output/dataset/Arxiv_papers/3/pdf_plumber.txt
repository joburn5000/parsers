Differentially Private Federated Learning:
Servers Trustworthiness, Estimation, and Statistical
Inference
Zhe Zhang∗ Ryumei Nakada† Linjun Zhang‡
April 26, 2024
Abstract
Differentially private federated learning is crucial for maintaining privacy in dis-
tributed environments. This paper investigates the challenges of high-dimensional
estimationandinferenceundertheconstraintsofdifferentialprivacy. First,westudy
scenarios involving an untrusted central server, demonstrating the inherent difficul-
tiesofaccurateestimationinhigh-dimensionalproblems. Ourfindingsindicatethat
the tight minimax rates depends on the high-dimensionality of the data even with
sparsity assumptions. Second, we consider a scenario with a trusted central server
and introduce a novel federated estimation algorithm tailored for linear regression
models. This algorithm effectively handles the slight variations among models dis-
tributed across different machines. We also propose methods for statistical infer-
ence, including coordinate-wise confidence intervals for individual parameters and
strategiesforsimultaneousinference. Extensivesimulationexperimentssupportour
theoretical advances, underscoring the efficacy and reliability of our approaches.
1 Introduction
1.1 Overview
Federated learning is an efficient approach for training machine learning models on dis-
tributed networks, such as smartphones and wearable devices, without moving data to a
central server [26, 25, 30]. Since its proposal in [32], federated learning has gained sig-
nificant attention in both practical and theoretical machine learning communities. One
of the key attractions of federated learning is its ability to provide a certain level of
data privacy by keeping raw data on local machines. However, without specific design
choices, there are no formal privacy guarantees. To fully exploit the benefits of federated
learning, researchers have introduced the concept of differential privacy [1, 12, 13, 14, 15]
∗Rutgers University. Email: zzres0131@gmail.com.
†Rutgers University. Email: rn375@stat.rutgers.edu.
‡Rutgers University. Email: lz412@stat.rutgers.edu.
1
4202
rpA
52
]LM.tats[
1v78261.4042:viXrato quantify the exact privacy level in federated learning. A series of research papers
have focused on federated learning with differential privacy, applying various algorithms
and methods [23, 37, 39]. Despite these efforts, there remains a significant gap between
practical usage and statistical guarantees, particularly in the high-dimensional setting
with sparsity assumptions, where theoretical results for the optimal rate of convergence
and statistical inference results are largely missing.
In this paper, we focus on studying the estimation and inference problems in the
federated learning setting under differential privacy, particularly in the high-dimensional
regime. In federated learning, there are several local machines containing data sets from
different sources, and a central server to coordinate all local machines to train learning
models collaboratively. We present our key results in two major settings for privacy and
federatedlearning. Inthefirstsetting,weconsideranuntrustedcentralserver[31,39,23]
whereeachmachinesendsonlyprivatizedinformationtothecentralserver. Forexample,
whenusingsmartphones,whereusersmaynotfullytrusttheserveranddonotwanttheir
personal information to be directly updated on the remote central server. In the second
setting, we consider a trusted central server where each machine sends raw information
without making it private. [33, 19, 34] For example, in different hospitals, patient data
may not be shared among hospitals to protect patient privacy, but they can all report
their data to a central server, such as a non-profit organization or an institute, to gain
more information and publish statistics on certain diseases.
In the first part of our paper, we demonstrate that under the assumption that
the central server is untrusted, the optimal rate of convergence for mean estimation
is O(sd/(mnϵ2)), where m is the number of local machines and each containing n data
points, d is the parameter of interest, s is the sparsity level, and ϵ is the privacy pa-
rameter. As commonly assumed in high-dimensional settings where the dimension is
comparable or even larger than the number of data, such an optimality result shows the
incompatibility of untrusted central server setting and high-dimensional statistics. As a
result, we can only hope to get a good estimation under the trusted central server setting
in the high-dimensional regime.
In the second part of the paper, we consider the case of a trusted central server and
design algorithms that allow for accurate estimations and obtain a near-optimal rate of
convergence up to logarithm factors. We also present statistical inference results, includ-
ing the construction of coordinate-wise confidence intervals with privacy guarantees, and
the solution to conduct simultaneous inference privately. This will assist in hypothesis
testing problems and construction of confidence intervals for a given subset of indices of
a vector simultaneously in high-dimensional settings. We emphasize that our algorithms
for estimation and inference are suited for practical purposes, considering its capacity
to (1) leverage data from multiple devices to improve machine learning models and (2)
draw accurate conclusions about a population from a sample while preserving individual
privacy. For instance, in healthcare, we could combine patient data from multiple hospi-
tals to develop more accurate models for disease diagnosis and treatment, while ensuring
that patient privacy is protected. We summarize our major contributions as follows:
• Fortheuntrustedcentralserversetting,weprovablyshowthatfederatedlearningis
2notsuitedforhigh-dimensionalmeanestimationproblemsbyprovidingtheoptimal
rate of convergence under the untrusted central server constraints. This suggests
us to consider a trusted central server setting to utilize federated learning for such
problems.
• For the trusted central server setting, we design novel algorithms to achieve private
estimation with federated learning. We first consider the estimation in homoge-
neous federated learning setting and then we extend it to a more complicated het-
erogeneous federated learning setting. We also provide a sharp rate of convergence
for our algorithm in both settings.
• In addition, we consider statistical inference problems in both homogeneous and
heterogeneous federated learning settings. We provide algorithms for coordinate-
wise and simultaneous confidence intervals, which are two common inference prob-
lemsinhigh-dimensionalstatistics. Itisworthmentioningthatourproposedmeth-
ods for high-dimensional differentially private inference problems are novel and
unique, which has not been developed even for the single-source and non-federated
learning setting. Theoretical results show that our proposed confidence intervals
are asymptotically valid, supported by simulations.
1.2 Related Work
In the literature, several works focused on designing private algorithms in federated
learning/distributed learning based on variants of stochastic gradient decent algorithms.
[3]proposedacommunicationefficientalgorithm, CP-SGDalgorithmforlearningmodels
with local differential privacy (LDP). [17] proposed a distributed LDP gradient descent
algorithm by applying LDP on gradients with ESA framework [6]. [20] extended works
on LDP approach for federated learning and proposed a distributed communication-
efficient LDP stochastic gradient descent algorithm through shuffled model and analyzed
the upper bound of the convergence rate. However, the trade-off between statistical
accuracy and the privacy cost has not been considered in these works.
In the distributed settings, the trade-off between statistical accuracy and information
constraints has been discussed in various papers. Two common types of information
constraints are communication constraints and privacy constraints. We refer to [43, 7,
21, 5, 18] for more discussions on communication constraints, considering the situation
where the bits of the information during communication have constraints.
Aseriesofworkdiscussesthetrade-offbetweenaccuracyandprivacyinhigh-dimensional
and non-federated learning problems, including top-k selection [35], sparse mean estima-
tion[8], linearregression[8, 36], generalizedlinearmodels[9], latentvariablemodels[46].
However, the discussion on privacy constraints in the distributed settings are still largely
lacking. Among the existing works, most of them focus on the local differential privacy
(LDP) constraint. In [4], the mean estimation under ℓ loss for Gaussian and sparse
2
Bernoulli distributions are discussed. [11] discussed the lower bounds under LDP con-
straintsintheblackboardcommunicationmodelformeanestimationofproductBernoulli
3distributions and sparse Gaussian distributions. [2] proposed a more general approach
to combine both communication constraints and privacy constraints. Compared with
previous works, we focus on the problem where there are n data points on each machine.
Our interest lies in the (ϵ,δ)-DP instead of LDP, which is a weaker constraint containing
broader settings. We further note that, compared with the blackboard communication
model [7, 18], in the federated learning setting, we assume that the existence of a central
server and that each server is only allowed to communicate with the central server. This
setting enables us to enhance more privacy.
When we are finalizing this paper1, we realized an independent and concurrent work
[28]. [28] also considers differentially private federated transfer learning under high-
dimensional sparse linear regression model. Namely, they proposed a notion of federated
differential privacy that allows multiple rounds of (ϵ,δ)-differentially private transmis-
sions between local machines and the central server, and provides algorithms to filter
out irrelevant sources, and exploit information from relevant sources to improve the per-
formance of estimation of target parameters. We differntiate our research with their
paper as follows: (1) While they consider differentially private federated learning under
untrusted server setting, we deal with both trusted and untrusted server settings. We
also highlight a fundamental difficulty of pure ϵ-differentially private estimation under
untrusted central server settings in federated learning by establishing a tight minimax
lower bound, and resort to trusted server settings for estimation and inference prob-
lems. (2) While their investigation centers on differentially private estimation within a
federated transfer learning framework—specifically focusing on parameter estimation for
a target distribution using similar source data—our work focuses on private estimation
and inference for parameters that are either common across all participating machines,
or vary across different machines.
We also cite papers that provided us inspirations for the design of our proposed
algorithmsandmethods. [24]introducesade-biasingproduceforthestatisticalinference
problems. [29]considersthetransferlearningprobleminhigh-dimensionalsettings,which
enablesustocombineinformationfromothersourcestobenefittheestimationproblems.
Such idea could be adopted in the hetergeneous federated learning problems. For the
simultaneous inference problems, we refer to [42, 41], which discussed how to conduct
simultaneous inference for high-dimensional problems.
Notation. We introduce several notations used throughout the paper. Let v =
(v ,v ,...,v )⊤ ∈ Rd represent a vector. Given a set of indices S, v refers to the
1 2 d S
components of v corresponding to the indices in S. The ℓ norm of v, for 1 ≤ q ≤ ∞, is
q
given by ∥v∥ , whereas ∥v∥ represents the number of non-zero elements in v, also called
q 0
as its sparsity level.
We use m to indicate the number of machines, n for the number of samples per
machine, d for the dimensionality of vectors, and s for their sparsity level. The total
number of samples across all machines is denoted by n = m·n. Additionally, we define
0
the truncation function Π : Rd → Rd, which projects a vector onto the ℓ ball of radius
T ∞
T centered at the origin.
1An initial draft of this paper was published as a Ph.D. dissertation in 2023 [45].
4ForamatrixΣ,max v⊤Σvandmin v⊤Σvdenotethelargest
∥v∥2=1,∥v∥0≤s ∥v∥2=1,∥v∥0≤s
and smallest s-restricted eigenvalues of Σ, denoted as µ (Σ) and ν (Σ), respectively.
s s
For sequences a and b , a = o(b ) implies a /b → 0 as n grows, a = O(b )
n n n n n n n n
signifies that a is upper bounded by a constant multiple of b , and a = Ω(b ) indicates
n n n n
that a is lower bounded by a constant multiple of b , where constants are independent
n n
ofn. Thenotationa ≍ b denotesthata isbothupperandlowerboundedbyconstant
n n n
multiples of b .
n
In this work, we often use symbols c ,c ,m ,m ,C,C′,K,K′ to represent univer-
0 1 0 1
sal constants. Their specific values may vary depending on the context, but they are
independent from other tunable parameters.
2 Preliminaries
2.1 Differential Privacy
Westartformthebasicconceptsandpropertiesofdifferentialprivacy[13]. Theintuition
behind differential privacy is that a randomized algorithm produces similar outputs even
whenanindividual’sinformationinthedatasetischangedorremoved,therebypreserving
theprivacyofindividualdata. Theformaldefinitionofdifferentialprivacyisgivenbelow.
Definition 2.1 (Differential Privacy [13]) Let X be the sample space for an individ-
ual data, a randomized algorithm M : Xn → R is (ϵ,δ)-differentially private if and only
if for every pair of adjacent data sets X,X′ ∈ Xn and for any S ⊆ R, the inequality
below holds:
P(M(X) ∈ S) ≤ eε·P(cid:0) M(X′) ∈ S(cid:1) +δ,
where we say that two data sets X = {x }n and X′ = {x′}n are adjacent if and only
i i=1 i i=1
if they differ by one individual datum.
In the above definition, the two parameters ϵ,δ control the privacy level. From the
definition, with smaller ϵ and δ, the outcomes given adjacent X and X′ become closer,
making it harder for an adversary to distinguish if the original dataset is X or X′,
indicating the privacy constraint becomes more stringent. Furthermore, when δ = 0, we
could use ϵ-differentially private as the abbreviation of (ϵ,0)-differentially private.
Intherestofthissection, weintroduceseveralusefulpropertiesofdifferentialprivacy
and how to create a differential private algorithm from non-private counterparts. One
common strategy is through noise injection. The scale of noise is characterized by the
sensitivity of the algorithm:
Definition 2.2 For any algorithm f : Xn → Rd and two adjacent data sets X and X′,
the ℓ -sensitivity of f is defined as:
p
∆ (f) = sup ∥f(X)−f(X′)∥ .
p p
X,X′∈Xn adjacent
5We then introduce two mechanisms. For algorithms with finite ℓ -sensitivity, we add
1
Laplace noises to achieve differential privacy, while for ℓ -sensitivity, we inject Gaussian
2
noises.
Proposition 2.3 (The Laplace Mechanism [13, 14]) Let f : Xn → Rd be a deter-
ministic algorithm with ∆ (f) < ∞. For w ∈ Rd with coordinates w ,w ,··· ,w be i.i.d
1 1 2 d
samples drawn from Laplace(∆ (f)/ϵ), f(X)+w is (ϵ,0)-differentially private.
1
Proposition 2.4 (The Gaussian Mechanism [13, 14]) Let f : Xn → Rd be a de-
terministic algorithm with ∆ (f) < ∞. For w ∈ Rd with coordinates w ,w ,··· ,w be
2 1 2 d
i.i.d samples drawn from N(0,2(∆ (f)/ϵ)2log(1.25/δ)), f(X)+w is (ϵ,δ)-differentially
2
private.
The post-processing and composition properties are two key properties in differential
privacy, which enable us to design complicated differentially private algorithms by com-
bining simpler ones. Such properties are pivotal in the design of algorithms in later
chapters.
Proposition 2.5 (Post-processing Property [13]) Let M be an (ϵ,δ)-differentially
private algorithm and g be an arbitrary function which takes M(X) as input, then
g(M(X)) is also (ϵ,δ)-differentially private.
Proposition 2.6 (Composition property [13]) Fori = 1,2,letM be(ε ,δ )-differentially
i i i
private algorithm, then (M ,M ) is (ϵ +ϵ ,δ +δ )-differentially private algorithm.
1 2 1 2 1 2
We also mention NoisyHT algorithm (Algorithm 1) introduced by [16], which stands for
the noisy hard-thresholding algorithm. The algorithm aims to pursue both sparsity of
the output and privacy at the same time.
Algorithm 1: Noisy Hard Thresholding Algorithm (NoisyHT(v,s,λ,ϵ,δ)) [16]
1 Input: vector-valued function v = v(X) ∈ Rd with data X, sparsity s, privacy
parameters ε,δ, sensitivity λ.
2 Initialization: S = ∅.
3 For i in 1 to s:
(cid:18) √ (cid:19)
4 Generate w i ∈ Rd with w i1,w i2,··· ,w id i. ∼i.d. Laplace λ· 2 3sl εog(1/δ) .
5 Append j∗ = argmax j∈[d]\S(|v j|+w ij) to S.
6 End For
(cid:18) √ (cid:19)
7 Generate w˜ with w˜ 1,··· ,w˜ d i. ∼i.d. Laplace λ· 2 3sl εog(1/δ) .
8 Output: P S(v+w˜).
In the last step, P (u) denotes the operator that makes u = 0 while preserving u .
S Sc S
This algorithm could be seen as a private top-k selection algorithm, which helps build
our proposed algorithm in later section.
6Specifically,whenthesparsitysischosentobe1,thealgorithmoutputsthemaximum
elementchosenafterasingleiterationintheprivatemanner. Wereferthisspecialcaseas
the Private Max algorithm, which is implemented in Algorithm 7 used for simultaneous
inference.
2.2 Federated Learning
Federated learning introduced in [32] is a technique designed to train a machine learning
algorithm across multiple devices, without exchanging data samples. A central server
coordinatestheprocess, witheachlocalmachinesendingmodelupdatestobeaggregated
centrally. Figure 1 illustrates the basic concept of federated learning
Figure 1: Federated Learning
One characteristic of federated learning is that the training of machine learning mod-
els occurs locally, and only parameters and updates are transferred to the central server
and shared by each node. Specifically, communication between local machines and the
server is bidirectional: machines send updates to the central server, and in return, they
receiveaggregatedinformationafterprocessing. Communicationamonglocalmachinesis
prohibited to prevent privacy leakage. Intuitively, federated learning inherently provides
a certain level of privacy.
Although without rigorous definitions, there are two main branches of central server
settingsinfederatedlearning: theuntrustedcentralserversettingandthetrustedcentral
server setting [31, 39, 33, 19]. In the first setting, where the central server is untrusted,
each piece of information sent from the machine to the central server should be differ-
entially private. In the second setting, we assume a trusted central server exists. In
this scenario, it is safe to send raw information from the machine to the central server
without additional privacy measures. However, to prevent information leakage among
local machines, the information sent back from the server should also be differentially
private.
Another key aspect of federated learning is that the datasets on each local machine
are commonly not independent and identically distributed (i.i.d.). This allows federated
7learning to train on heterogeneous datasets, aligning with practical scenarios where the
datasets on different machines are typically diverse and their sizes may also vary. We
will demonstrate that federated learning can efficiently estimate the local model when
models on different local machines differ but share some similarities, a concept we refer
to as heterogeneous federated learning in Section 5.
2.3 Problem Formulation
In this paper, we assume that there exists a central server and m local machines. We de-
note the data on these machines by X 1,X 2,X 3,...,X m, respectively, with X
i
∈ Rni×d.
On any machine i = 1,2,...,m, there are n data points X = [X ,X ,...,X ]. For
i i i1 i2 ini
simplicity, we assume that there are equal data points n = n = n = ··· = n for each
1 2 i
machine. We note that the result could be easily generalized to cases where the sample
sizes on each machine differ.
We consider both untrusted and trusted central server settings. For the untrusted
setting, we require that the information sent from local machines to the server is pri-
vate. In this scenario, we show that in the high-dimensional setting, even with sparsity
assumptions, it is impossible to achieve small estimation error when the central server
is untrusted. In the trusted setting, we consider the high-dimensional linear regression
problem Y = Xβ+W with s-sparse β. We will first study the case where all machines
share the same β, (referred to homogeneous federation learning,) and then study a more
general case where models on different machines are not equal, but share certain simi-
larities (referred to heterogeneous federation learning.) We show that our algorithm can
adapt to such similarity—with larger similarity, the algorithm achieves a faster rate of
convergence.
3 An Impossibility Result in the Untrusted Central Server
setting
In this section, we study the untrusted server setting where the local machines need to
send privatized information to the central server to ensure privacy. We show an impos-
sibility result that in high-dimensional settings where the data dimension is comparable
to or greater than the sample size, accurate estimation is not feasible even if we consider
a simple sparse mean estimation problem.
As mentioned in Section 2.3, we consider a federated learning setting with m ma-
chines, where each machine i ∈ [m] handles n data points X := [X ,X ,...,X ] ∈
i i1 i2 in
Rn×d. LetD = {X }m . WeassumethateachdatapointX ∈ Rd followsaGaussian
all i i=1 ij
distribution N(µ,I ), where µ is a sparse d-dimensional vector with sparsity s. The goal
d
is to estimate µ in the federated learning setting when the central server is untrusted. In
this section, we provide an optimal rate of convergence for this problem and show that
the untrusted central server setting is not suited for high-dimensional problems.
We begin by deriving the minimax lower bound, which characterizes the fundamental
difficulty of this estimation problem. In untrusted server setting, we additionally assume
8that each piece of information sent from the local machine to the central server follows
ϵ-differential privacy. To achieve this, we introduce the privacy channel Wϵ-priv : Xn →
Z, a function that is responsible for privatizing the information transmitted from the
local machines. Given the input X ∈ Xn and the privacy channel Wϵ-priv, Z ∈ Z
representingalltheinformation(frommultiplerounds)transmittedtothecentralserver.
More precisely, we require privacy guarantees such that for any two adjacent datasets X
and X′ ∈ Xn, differing by only one data point on any local machine, and for an output
Z ∈ Z representing the information sent from the local machine to the central server,
differential privacy guarantee P(Wϵ-priv(X) = Z) ≤ eϵ·P(Wϵ-priv(X′) = Z) holds.
WeconsideranymechanismM inthefederatedlearningsettingwithmlocalmachines
andonecentralserver, operatedonthedatasetD . M servesasaproceduretoestimate
all
µ, where each local machine collaborates exclusively with the central server without
direct interaction among themselves. On each machine i, the mechanism M uses the
privacy channel Wϵ-priv and data sample X to generate Z , which is then transmitted to
i i i
the central server. The central server receives the information from all machines. After
multi-rounds of collaboration between local machines and the central server, we obtain
the sparse and private estimator µˆ ∈ Rd. We denote the class of all mechanisms that
satisfy the above constraints as Muntrust(D ). Under this setting we establish a lower
m,ϵ all
bound for the estimation error of the mean in Theorem 1.
Theorem 1 Suppose D is generated as above. Let µ be a s-sparse d-dimensional mean
all
of Gaussian distribution satisfying ∥µ∥ ≤ 1. We consider the estimation of the mean
∞
vector µˆ under the untrusted central server federated learning setting with m local ma-
chines and n data points in each machine. Then, there exists a constant c > 0 such
that
(cid:18) (cid:19)
s sd
inf sup ∥µ−M(D )∥2 ≥ c·min , .
M∈Mu mn ,t ϵrust µ∈Rd,∥µ∥∞≤1 all 2 n mnϵ2
Thelowerboundcontainstwoterms. Thefirstterm,oforders/n,representstheminimax
riskofmeanestimationusingonlythesamplesfromalocalmachine. Thesecondterm,of
order sd/(mnϵ2), accounts for the error from federated learning across multiple machines
underprivacyconstraints. Theorem1suggeststhatwecannotperformbetterthaneither
choosing to estimate the mean using only the local machine or adopting the federated
learning approach and combining information from different machines. However, in the
latter approach, we must at least incur a rate of O(d/(mnϵ2)), which is linearly pro-
portional to the dimension d. This result suggests that privacy constraints significantly
impact the efficiency of federated learning in high-dimensional settings. Furthermore, as
the number of machines m increases, we can possibly attain better performance, high-
lighting the merit of federated learning.
We also show the tightness of the lower bound in Theorem 1 by providing the upper
bound.
Theorem 2 SupposethatconditionsinTheorem1hold. Then,thereexistsanϵ-differentially
9private algorithm for the estimation of µ as µˆ
s·d
∥µ−µˆ∥2 ≤ c· ,
2 mnϵ2
where c > 0 is some constant.
The proof follows by constructing an algorithm that transforms Gaussian mean to
Bernoulli mean according to the sign of the Gaussian mean, motivated by Algorithm 2
discussed in [2], where the authors discuss l-bit protocol for estimating the product of
Bernoulli family. More details of the algorithm are deferred to Section A.2. Based
on the results from Theorems 1 and 2, we obtain the optimal rate of convergence for
sparse mean estimation under differentially private federated learning setting. As a
result, when the central server is untrusted, it is impossible to find an approach to
achieve accurate estimation under the untrusted server assumption. This highlights the
necessity of the trusted server setting for statistical estimation and inference in high-
dimensionalfederatedlearningscenarios. Inthefollowingsections,wedevelopestimation
and inference procedures under the trusted server settings.
4 Homogeneous Federated Learning Setting
4.1 Algorithms for Estimation Problems
In this section, we consider the setting of a trusted central server, where local machines
fully trust the central server and send unprivatized information to it without implement-
ing privacy measures. However, when the central server sends information back to the
local machines, it must ensure that this information is privatized to avoid any privacy
leakage across local machines.
In this subsection, we first focus on the statistical estimation problems in this setting
and then develop inference results in the next subsection. More specifically, our primary
focus is on the linear regression problem in a high-dimensional setting, where the ground
truth, denoted as β, is a sparse d-dimensional vector. We initially study the simpler
case in this section, where the underlying generative models for each local machine are
identical, which we refer to as the homogeneous federated learning setting. A more
complicated heterogeneous setting will be discussed in the following section. Specifically,
we consider the following high-dimensional linear regression model:
Y = Xβ+W,
where we assume W is the error term whose coordinates are independent and following
sub-Gaussian distribution with variance proxy σ2, denoted by W ∼ subG(σ2). X is
i
a random matrix whose rows are following sub-Gaussian distribution with a covariance
matrix Σ.
We first introduce the parameter estimation algorithm under differentially private
federated settings with a trusted central server.
10Algorithm 2: Differentially Private Sparse Linear Regression under Federated
Learning
Input : Dataset D = {(X ,Y )} , number of machines m, number of
all i i i∈[m]
samples on each machine n, step size η0, privacy parameters ε,δ, noise
scale B , number of iterations T, truncation level R, feasibility
0
parameter C , sparsity s, initial value β0.
0
1 for t from 0 to T −1 do
2 Step 1:
3 On each local machine i = 1,2,...,m, calculate the local gradient
n
1 (cid:88)
g = (X⊤βt−Π (y ))X .
i n ij R ij ij
j=1
Send the gradient g to the central server.
i
4 Step 2:
5 Compute βt+0.5 = βt−(η0/m)(cid:80)m i=1g i at the central server;
(cid:16) (cid:17)
6 Compute βt+1 = Π C0 NoisyHT(βt+0.5,s, Tε, Tδ, η m0B n0) at the central
server.
7 Step 3: Send the output βt+1 back to each local machine from the server.
8 end
9 Output: Return βT.
In Step 1 of Algorithm 2, the information computed on each local machine is trans-
mitted to the central server. The second step involves calculations performed at the
central server. Prior to sending the information back to the local machines, it undergoes
privacy preservation through the application of the NoisyHT algorithm, as introduced
in Algorithm 1. Subsequently, the local machine updates its estimation based on the
information received from the central server.
We compare Algorithm 2 with Algorithm 4.2 in [8], which addresses the private
estimation in linear regression under non-federated learning settings. Unlike the latter,
ouralgorithmdoesnottransmitalldatapointstothecentralserver. Instead,wecalculate
the gradient updates locally on each machine and send only these local gradients to the
server. This design enhances privacy protection, as the original data remains visible
only on the local machine and is not exposed externally. Furthermore, this approach of
gradient updates also reduces communication costs by transmitting only a d-dimensional
vector from each local machine for the gradient update. Previous research has also
considered non-private distributed methods for linear regression problems, such as [27,
44]. Our algorithm, however, ensures differential privacy. In practice, the sparsity level
s can be determined using a private version of cross-validation, while other parameters
may be pre-chosen based on our theoretical analysis.
114.2 Algorithms for Inference Problems
In this subsection, we focus on statistical inference problems in the homogeneous feder-
ated learning setting, such as constructing coordinate-wise confidence intervals for pa-
rameters and performing simultaneous inference. To begin, we develop a method for
constructing coordinate-wise confidence intervals, for example, for the k-th index of β,
β . However, it is important to note that the output of Algorithm 2 is biased due to
k
hard thresholding. To overcome this bias, we employ a de-biasing procedure, a common
technique in high-dimensional statistics, as demonstrated in previous studies [24]. This
procedure involves approximating the k-th column of the precision matrix Θ = Σ−1
to construct confidence intervals for each β . Subsequently, we focus on obtaining an
k
estimate of the precision matrix in a private manner.
Algorithm 3: Differentially Private Precision Matrix Estimation in Federated
Learning
Input : Number of machines m, number of data points in each machine n,
dataset X = (x ,...,x ) for i = 1,...,m, step size η1, privacy
i i1 in
parameters ε,δ, noise scale B , number of iterations T, feasibility
1
parameter C , sparsity s, initial value Θ0.
1 k
1 for t from 0 to T −1 do
2 Step 1: On each local machine i = 1,2,...,m, calculate local gradient
g = 1 (cid:80)n X X⊤Θt −e . Send the gradients (g ,g ,...,g ) to the
i n j=1 ij ij k j 1 2 m
central server.
3 Step 2:
4 Compute Θt k+0.5 = Θt k −(η0/m)(cid:80)m i=1g i at the central server;
(cid:16) (cid:17)
5 Compute Θt k+1 = Π C1 NoisyHT(w kt+0.5,s, Tε, Tδ, η m1B n1) at the central
server.
6 Step 3: Send Θt+1 back to each local machine from the server.
k
7 end
8 Output: Return ΘT.
k
The structure of Algorithm 3 is similar to Algorithm 2, as both adopt an iterative
communication between the central server and the local machines; the information is ini-
tiallytransmittedfromthelocalmachinestotheserver, then, thecentralserverperforms
calculations and use the NoisyHT algorithm (Algorithm 1) to ensure the privacy of the
information. Subsequently,eachlocalmachineupdatesthegradientandprogressestothe
next iteration. The primary distinction between two algorithms lies in the computation
of the gradient on each machine.
Denote the output of Algorithm 2 as βˆ and the output of Algorithm 3 as Θˆ . Then
k
the de-biased differentially private estimator of β is given by
k
m
1 (cid:88)
βˆu = βˆ + Θˆ⊤g +E , (4.1)
k k m k i k
i=1
where g = (1/n)(cid:80)n (X⊤βˆ − Π (y ))X , and E is the injected random noise to
i j=1 ij R ij ij k
12ensure privacy, following a Gaussian distribution N(0,8∆2log(1.25/δ)/(n2m2ϵ2)), where
√ 1
∆ = sc c R+sc c c2 with some constants c ,c ,c defined later.
1 1 x 0 1 x 0 1 x
The debiased estimator in (4.1) enables us to construct a differentially private con-
fidence intervals. Although the variance σ of the error term W in the linear regression
model is usually unknown, we can estimate σ from the data in a private manner. The
estimation is based on the residual term between the response Y and the fitted value
Xβˆ. We summarize the method to estimate σ in the private federated learning setting
in Algorithm 4.
Algorithm 4:DifferentiallyPrivateVarianceEstimationinFederatedLearning
Input : Dataset (X ,Y ) , privacy parameters ε, noise scale B ,
i i [i=1,2,...,m] 2
truncation level R, estimated parameter βˆ from Algorithm 2.
1 Step 1: On each machine i = 1,2,...,m, compute Wˆ i = ∥Π R(Y i)−X iβˆ∥2 2/n
and send Wˆ to the central server.
i
2 Step 2: Generate a random variable Evar, where Evar ∼
N(0,2B2log(1.25/δ)/ϵ2)
2
3 Step 3: Compute σˆ2 such that σˆ2 = (cid:80)m i=1Wˆ i/m+Evar at the central server
Output: Estimated variance σˆ2.
When examining the convergence rates of βˆ and Θˆ in Theorem 3, we observe the
k
crucialrolesofthelargestandsmallestrestrictedeigenvaluesofΣ. Sincetheseeigenvalues
directlyinfluencetheconstructionofconfidenceintervalsandcannotbedirectlyobtained
fromthedata,theirprivateestimationbecomesessential. Below,weoutlineanalgorithm
to estimate the largest restricted eigenvalue, µ (Σ). To estimate the smallest restricted
s
eigenvalue, ν (Σ), the same algorithm can be used by modifying Step 4 from “argmax”
s
to “argmin”.
Algorithm 5: Differentially Private Restricted Eigenvalue Estimation in Fed-
erated Learning
Input : Number of machines m, dataset (X ) , number of data points
i [i=1,...,m]
in each machine n, privacy parameters ε, noise scale B , number of
3
vectors n .
1
1 Step 1: Sample n 1 d-dimensional, s-sparse unit vectors v 1,v 2,...,v n1.
2 Step 2: On each machine, compute t i,k = (v kTX iTX iv k)/n where
k = 1,2...,n and send them on to the central server.
1
3 Step 3: Sample ξ 1,...,ξ n1 ∼ Laplace (2B 3/ϵ).
4 Step 4: Compute k max such that k max = argmax k(cid:80)m i=1t i,k/m+ξ k.
Output: µ (Σˆ) = (cid:80)m t /m+ξ, where ξ ∼ Laplace(2B /ϵ) independently.
s i=1 i,kmax 3
BasedonAlgorithms4and5,weprovideaconstuctionforcoordinate-wiseconfidence
intervals in Algorithm 6.
13Algorithm 6: Differentially Private Coordinate-wise Confidence interval for β
k
in Federated Learning
Input : Number of machines m, dataset (X ,Y ) , number of data
i i [i=1,...,m]
points in each machine n, privacy parameters ε,δ, truncation level R,
sparsity s, estimators of parameters βˆ, Θˆ from Algorithms 2 and 3,
k
constants ∆ ,γ.
1
1 Step 1: On each local machine i = 1,2,...,m, calculate local gradient
g = 1 (cid:80)n (X⊤βˆ−Π (y ))X . Send the gradient (g ,g ,...,g ) to the
i n j=1 ij R ij ij 1 2 m
central server.
2 Step 2: Generate a random variable E from the Gaussian distribution
N(0,8∆2log(1.25/δ)/n2m2ϵ2).
1
3 Step 3: Calculate de-biased estimation, βˆ ku = βˆ k + m1 (cid:80)m i=1Θˆ⊤ kg i+E
4 Step 4: Estimate σˆ from Algorithm 4 and µˆ s,νˆ s from Algorithm 5.
5 Step 5: Calculate the confidence interval J k(α).
(cid:20) γµˆ2s2log2dlog(1/δ)log3mn σ (cid:114) 8∆2log(1/δ)
J (α) = βˆu− s −Φ−1(1−α/2)√ Θˆ⊤ΣˆΘˆ + 1 ,
k k νˆ2 m2n2ϵ2 mn k k mnϵ2
s
γµˆ2s2log2dlog(1/δ)log3mn σ (cid:114) 8∆2log(1/δ)(cid:21)
βˆu+ s +Φ−1(1−α/2)√ Θˆ⊤ΣˆΘˆ + 1
6 k νˆ2 m2n2ϵ2 mn k k mnϵ2
s
Output: Return the final result J (α).
k
So far we focused on constructing confidence intervals for individual coordinates of
the parameter vector β. However, in high-dimensional settings, we are often interested
in group inference problem, where we test hypotheses involving multiple coordinates
simultaneously. Specifically, we consider the problem of testing the null hypothesis given
by
H : βˆ = β , for all k ∈ G
0 k k
against the alternative hypothesis,
H : βˆ ̸= β ,
1 k k
for at least one k ∈ G, where G is a subset of all coordinates {1,2,...,d} and we allow
|G| to be the same order as d. Additionally, we also construct simultaneous confidence
intervals for all coordinates in G. Note that the problem discussed above are common in
high-dimensionaldataanalysis,withapplicationssuchasmulti-factoranalysisofvariance
[22], additive modeling [40]. Previous research works have discussed similar problems in
the non-private setting, including [10, 42, 41].
Toaddresstheproblem,simultaneousinferencecanbeconductedusingateststatistic
max|βˆu−β |.
k k
k∈G
Major challenges of simultaneous inference in a private federated learning setting
include: (1) minimizing the communication cost from local machines to the server while
14retaining all data on the local machines, and (2) ensuring the privacy of the procedure,
whichnecessitatesatailoredprivacy-preservingmechanismateachstepofthealgorithm.
Inourframework,weproposeanalgorithmbasedonthebootstrapmethod. Asprevi-
ously mentioned, to build confidence intervals, our interest lies in the statistic computed
by the maximum coordinate of βˆu−β over G. By decomposing this statistic, we obtain
k k
a term √ mσ n (cid:80)m i=1(cid:80)n j=1ΘˆX ij(y ij −X iT jβ). To determine the distribution of this term,
we bootstrap the residuals y −XTβ.
ij ij
We outline the algorithm as follows: we first estimate βˆ and Θˆ using Algorithm 2
k
and 3, respectively. Accordingly, by stacking Θˆ for all k, we get an estimator of the
k
precision matrix Θˆ. The details are provided in Algorithm 7.
Algorithm 7: Private Bootstrap Method for Simultaneous Inference in Feder-
ated Learning
Input : number of machines m, dataset (X ,Y ) , number of data on
i i [i=1,2,...m]
each machine n, privacy parameters ε,δ, estimators of parameters βˆ,
Θˆ from Algorithms 2 and 3, number of iterations for bootstrap q,
quantile α, noise level B , subset of coordinates G.
4
1 for t from 0 to q do
2 Step 1: For each local machine i = 1,...,m, generate n independent
standard Gaussian random variables e ,...,e . Calculate
i1 in
u
i
= √1
n
(cid:80)n j=1ΘˆX ije ij.
3 Step 2: Send (u i) [i=1,2,...,m] from local m √achines to the central server.
4 Step 3: Calculate U t = Privatemax([(1/ m)(cid:80)m i=1u i] G,ϵ,δ,B 4) at the
central server.
5 end
6 Output: Compute the α-quantile C U(α) of (|U 1|,|U 2|,...|U q|) for α ∈ (0,1).
On line 4 of Algorithm 7, we employ the Private Max algorithm, which we mentioned
earlier as a variation of NoisyHT algorithm (Algorithm 1) by directly picking s = 1, to
obtain the maximum element in a vector in a private manner. It is also important to
note that the Private Max algorithm is applied to a subset of G. After presenting the
algorithm, we denote M as:
√
M(βˆ) = max| mn(βˆu−β )|.
k k
k∈G
M is used as the statistic for inference problems later.
As previously mentioned, we can easily construct a simultaneous confidence interval
for each k ∈ G by:
(cid:20) (cid:21)
σˆ σˆ
βˆu− √ C (α), βˆu+ √ C (α) ,
k mn U k mn U
where C (α) is obtained from our algorithm with prespecified α. We can similarly
U
perform hypothesis testing; first calculate the test statistic and obtain C (α) from our
U
algorithm with prespecified α, then reject if the statistic lies in the rejection region.
154.3 Theoretical Results
In this subsection, we provide theoretical guarantee for the algorithms and methods
discussed in the previous subsections. Before proceeding, we outline key assumptions
concerning the design matrix X, precision matrix Θ, and the true parameter β of the
linear regression model, which are essential for our subsequent analyses.
(P1) Parameter Sparsity: The true parameter vector β satisfies ∥β∥ < c for some
2 0
constant 0 < c < ∞ and ∥β∥ ≤ s∗ = o(n).
0 0 0
(P2) Precision matrix sparsity: For each column of the precision matrix Θ , k =
k
1,2,...,d, it satisfies that ∥Θ ∥ < c for some constant 0 < c < ∞ and
k 2 1 1
∥Θ ∥ ≤ s∗ = o(n).
k 0 1
(D1) Design Matrix: for each row of the design matrix X, denote by x, xΣ−1/2 is
sub-Gaussian with sub-Gaussian norm κ := ∥Σ−1/2x∥ .
ψ2
(D2) Bounded Eigenvalues of the covariance matrix: For the covariance matrix Σ =
Exx⊤, there exists a constant 0 < L < ∞ such that 0 < 1/L < λ (Σ) ≤
min
λ (Σ) < L.
max
Theaboveassumptions(P1)and(P2)boundstheℓ normandℓ normoftheparameters
2 0
β and Θ , and assumption (D1) guarantees that each row of X follows a sub-Gaussian
k
distribution, and assumption (D2) requires the covariance matrix has bounded eigen-
values. These assumptions are commonly used for theoretical analysis of differentially
private algorithms and debiased estimators [9, 8, 24].
Withassumptions(P1)-(D2),weanalyzethealgorithmswepresented. Webeginwith
the estimation problem and provide a rate of convergence of βˆ and Θˆ .
k
Theorem 3 Let {(y ,X )} be an i.i.d. samples from the high-dimensional
ij ij i∈[m],j∈[n]
linear model. Suppose that assumptions (P1), (P2), (D1), (D2) are satisfied. Addition-
ally,
√
• we choose parameters as follows: let s∗ = max(s∗,s∗), R = σ 2logmn, C = c ,
(cid:112) √0 1 √ 0 0
C = c , c = 3 2Lκ2logd, B = 2(R + sc c )c , B = 2 sc c2, ∆ =
√1 1 x 0 0 x x 1 1 x 1
sc c R+sc c c2 and γ = max(µ (9µ +1/4),17/16µ +1/96), where µ ,ν are
1 x 0 1 x s s s s s
the largest and smallest s-restricted eigenvalues of Σˆ.
• wesetβ0 = 0andΘ0 = 0astheinitializationusedinAlgorithm2andAlgorithm3.
k
Then there exists some absolute constant ρ > 0 such that, if s = ρL4s∗, η0 = η1 = s/6L,
T = ρL2log(cid:0) 8c2Ln(cid:1) and n ≥ KR(s∗)3/2logd(cid:112) log(1/δ)logn/ε for a sufficiently large
0
constant K > 0, then, for the output from Algorithm 2 and Algorithm 3,
(cid:18)
slogd 6γµ
s2log2dlog(1/δ)log3mn(cid:19)
∥βˆ−β∥2 ≤ σ2 k · + s · , (4.2)
2 0 mn ν2 m2n2ϵ2
s
16and
(cid:18)
slogd 6γµ
s2log2dlog(1/δ)log3mn(cid:19)
∥Θˆ −Θ ∥2 ≤ σ2 k · + s , (4.3)
k k 2 1 mn ν2 m2n2ϵ2
s
hold with probability 1−exp(−Ω(log(d/slogd)+logn)).
The upper bound of Algorithm 3 in (4.3) can be interpreted as follows. The first
term represents the statistical error, while the second term accounts for the privacy cost.
Furthermore, the result is comparable to that of Theorem 4.4 in [8], which addresses
private linear regression in a non-federated setting. This comparison suggests that the
federated learning approach does not affect the convergence rate adversely; instead, it
allows us to leverage the benefits of federated learning. We also note that the advantages
of federated learning will be further explored in the heterogeneous federated learning
setting, which will be discussed in the next chapter.
The remainder of this subsection presents the theoretical results for the inference
problem. We begin with the construction of coordinate-wise confidence intervals. As
mentionedbefore,σ isusuallyunknownandweestimateσ inaprivatemanner,presented
in Algorithm 4. Lemma 4.1 states the statistical guarantee of our algorithm.
√
Lemma 4.1 Let σˆ2 be the output from Algorithm 4 by choosing R = O( 2logmn),
B = 4 (R2 + s2c2c2) and βˆ as the output from Algorithm 2. Then, Algorithm 4 is
2 mn 0 x
(ϵ,δ)-differentially private, and it follows that
(cid:18)
1 slogd
s2log2dlog(1/δ)log3mn(cid:19)
|σ2−σˆ2| ≤ c· √ + + ,
mn mn m2n2ϵ2
where c > 0 is a universal constant.
Next, we consider a simplified version of the confidence interval, where the privacy
cost is dominated by the statistical error. In this scenario, we assume that the privacy
level is relatively low and the privacy constraints are loose, meaning that the privacy
parameters ϵ and δ are relatively large, allowing for nearly cost-free estimation. We
present our result in the following theorem.
Theorem 4 Suppose that the conditions in Theorem 3 hold. Assume that s √∗logd = o(1)
mn
and s∗2log2dlog(1.25/δ)log3mn = o(1). Also assume that the privacy cost is dominated
mnϵ2
by statistical error, i.e., there exists a constant k such that s∗2log2dlog(1/δ)log3mn ≤
0 m2n2ϵ2
k ·s∗logd. Then, given the de-biased estimator βˆu defined in (4.1), the confidence interval
0 mn k
is asymptotically valid:
lim P(β ∈ J (α)) = 1−α,
k k
mn→∞
where
(cid:20) σˆ (cid:113) σˆ (cid:113) (cid:21)
J (α) = βˆu−Φ−1(1−α/2)√ Θˆ⊤ΣˆΘˆ , βˆ +Φ−1(1−α/2)√ Θˆ⊤ΣˆΘˆ
k k mn k k k mn k k
Also, the confidence interval J (α) is (ϵ,δ)-differentially private.
k
17Theorem 4 assumes that the privacy cost is dominated by the statistical error. How-
ever, when the privacy constraint is more stringent with small privacy parameters ϵ and
δ, the privacy cost may be larger than the statistical error. In this scenario, we general-
ize Theorem 4 to analyze Algorithm 6. We note that the largest and smallest restricted
eigenvalues of Σˆ also need to be estimated by Algorithm 5. Lemma 4.2 quantifies the
estimation error of the largest restricted eigenvalue of Σˆ.
Lemma 4.2 If n = cds and B = 2sc2/n for some constant c > 0, then the output
1 3 x
fromAlgorithm5is(ϵ,0)-differentiallyprivate. Moreover, (1/9)λ ≤ λˆ ≤ λ holdswhere
s s s
λ is the largest restricted eigenvalue of Σˆ.
s
We then present a theoretical result for the confidence interval in a more general case
in Theorem 5.
Theorem 5 Assume the conditions in Theorem 3 hold. Suppose that s √∗logd = o(1)
mn
and s∗2log2dlog(1.25/δ)log3mn = o(1), then, given the de-biased estimator βˆu defined in
m2n2ϵ2 k
(4.1) and the estimated restricted eigenvalues µˆ and νˆ from Algorithm 5, the confidence
s s
interval constructed by Algorithm 6 is asympotically valid:
lim P(β ∈ J (α)) = 1−α,
k k
mn→∞
where
(cid:20) γµˆ2s2log2dlog(1/δ)log3mn σˆ (cid:114) 8∆2log(1/δ)
J (α) = βˆu− s −Φ−1(1−α/2)√ Θˆ⊤ΣˆΘˆ + 1 ,
k k νˆ2 m2n2ϵ2 mn k k mnϵ2
s
γµˆ2s2log2dlog(1/δ)log3mn σˆ (cid:114) 8∆2log(1/δ)(cid:21)
βˆ + s +Φ−1(1−α/2)√ Θˆ⊤ΣˆΘˆ + 1 .
j νˆ2 m2n2ϵ2 mn k k mnϵ2
s
Also, J (α) is (ϵ,δ)-differentially private.
k
Comparedtothenon-privatecounterpartin[24],weclaimthatourconfidenceinterval
has a similar form but with additional noise injected to ensure privacy. When the noise
level is low, the confidence interval closely approximates the non-private counterpart,
allowing us to nearly achieve privacy without incurring additional costs. Furthermore,
when the privacy level is high, the confidence interval has a larger length to attain the
same confidence level.
Finally, for the simultaneous inference problems, we demonstrate that α-quantile
of statistic M in (6) is close to the α-quantile of U calculated in Algorithm 7 for each
α ∈ (0,1)usingthebootstrapmethod. Thenexttheoremstatesthestatisticalproperties
of Algorithm 7.
Theorem 6 Assume the conditions in Theorem 4 hold. Additionally, we assume that
s √∗logd = o(1) and the privacy cost is dominated by the statistical error, i.e., there exists
mn
a constant c > 0 such that s∗2log2dlog(1/δ)log3mn ≤ c · s∗logd. We also assume that
m2n2ϵ2 mn
18there exists a constant k such that log7(dmn)/mn ≤ 1 , and that q = o(mn),
0 (mn)k0
where q is the number of iterations for bootstrap q. The noise level is chosen as B =
√ √ √ 4
4L logmc (R+c c s∗)/ mn. Then, C (α) computed in Algorithm 7 satisfies
x 0 x U
sup |P(M ≤ C (α))−α| = o(1).
U
α∈(0,1)
Theorem 6 has useful applications: we can obtain a good estimator of the α-quantile
of U using the bootstrap method and then use it to construct confidence intervals or
perform hypothesis testing. Numerical results will be presented in later chapters to
further support our claims.
5 Heterogeneous Federated Learning Setting
5.1 Methods and Algorithms
In this section, we consider a more general setting where the parameters of interest on
each machine are not identical, but they share some similarities. Specifically, we consider
thescenariowhere, oneachmachinei = 1,2,...,m, weassumealinearregressionmodel:
Y = Xβ(i)+W ,
i
where β(i) represents the true parameter on machine i. We assume that each W is
i
a vector whose coordinates follow a sub-Gaussian distribution: W ∼ subG(σ2), k =
ik
1,2...,d i.i.d. We also assume that each row of X follows a sub-Gaussian distribution
i.i.d. with mean zero and covariance matrix Σ. We further quantify the similarity of
each β(i) by assuming that that there exists a subset S ∈ {1,2,...,d} with |S| = s
0
satisfying β(i1) = β(i2) for any i ,i ∈ {1,2,...,m}.
S S 1 2
A naive approach would be estimating each β(i) locally, as in the non-private setting.
However, in the context of federated learning, we can improve the estimation with a
sharper rate of convergence by exploiting similarities of the model across machines. To
achieve this, we decompose β(i) into the sum of two vectors, β(i) = u + v , where u
i
captures the signals common to all β(i), and v captures the signals unique to each
i
machine.
We employ a two-stage procedure to estimate each β(i): in the first stage, we esti-
mate u using Algorithm 2 with a sparsity level of ∥u∥ = s indicating the number of
0 0
shared signals. In the second stage, we estimate v on the individual machine. Our final
i
estimationofβ(i) isgivenbyβˆ(i) = vˆ +uˆ. TheprocedureissummarizedinAlgorithm8.
i
Similar to the previous section, we next address inference problems. Our algorithms
consist of two parts: the construction of coordinate-wise confidence intervals and simul-
taneous inference. We begin by describing the algorithm for coordinate-wise confidence
intervals in Algorithm 9.
In Algorithm 9, Θˆ is the (ϵ,δ)-differentially private estimator of the j-th row of the
j
precision matrix of covariance matrix Σˆ = 1/(mn)(cid:80)m (cid:80)n X X⊤. We define the
i=1 j=1 ij ij
19Algorithm 8: Differentially Private Sparse Linear Regression in Heterogeneous
Federated Learning Setting
Input : Number of machines m, dataset (y ,X ) , number of data on
i i [i=1,...,m]
each machine n, step size η0, privacy parameters ε,δ, noise scale B ,
5
number of iterations T, truncation level R, feasibility parameter C ,
0
initial value v0, sparsity level of similar vector s , sparsity level s.
i 0
1 Step 1: Estimate a s 0 sparse vector u using Algorithm 2.
2 Step 2: Estimate a s 1 := s−s 0 sparse vector v i with samples (y i,X i) on
machine i with the following iterations from line 3-6.
3 for t from 0 to T −1 do
4 Compute v it+0.5 = v it−(η0/n)(cid:80)n i=1(x⊤
i
v it−Π R(y i−x⊤
i
u))x i;
5 v it+1 = Π C0(cid:0)NoisyHT(v it+0.5,(y i,X i),s,ε/T,δ/T,η0B 5/n)(cid:1).
6 end
7 Step 3: Estimate β(i) by βˆ(i) := vˆ i+uˆ.
Output: βˆ(i).
Algorithm 9: Differentially Private Coordinate-wise Confidence interval for β
k
in Heterogeneous Federated Learning
Input : Number of machines m, dataset (X ,Y ) , number of data
i i [i=1,...,m]
points in each machine n, privacy parameters ε,δ, truncation level R,
sparsity s, estimated parameters βˆ(i), Θˆ from Algorithms 8 and 3,
k
and estimated eigenvalues µˆ , νˆ from Algorithm 5, constants ∆ ,γ.
s s 1
1 Step 1: Generate a random variable E 3 from a Gaussian distribution
N(0,8∆2log(1.25/δ)/(n2ϵ2)).
1
2 Step 2: Calculate de-biased estimation,
βˆ(i,u) = βˆ(i) + 1 (cid:80)n (Θˆ⊤X Π (y )−Θˆ⊤X X⊤βˆ(i) )+E .
k k n j=1 k ij R ij k ij ij k 3
3 Step 3: Calculate the confidence interval J k(α).
(cid:20) σΦ−1(1−α/2)(cid:114) 8∆2log(1/δ)
J (α) = βˆ(i,u) −a− √ Θˆ⊤ΣˆΘˆ + 1 ,
k k n k k nϵ2
σΦ−1(1−α/2)(cid:114) 8∆2log(1/δ)(cid:21)
βˆ(i,u) +a+ √ Θˆ⊤ΣˆΘˆ + 1 ,
k n k k nϵ2
where a is defined in (5.1).
4 Output: Return the final result J k(α).
variable a in step 3 by
2γµˆ2s2log2dlog(1/δ)log3mn 2γµˆ2s2log2dlog(1/δ)log3n
a := s 1 + s 0 . (5.1)
νˆ2 m2n2ϵ2 νˆ2 n2ϵ2
s s
We then provide Algorithm 10 for the simultaneous inference problem. Similar to the
20previous chapter, we can perform simultaneous inference for each β(i) to build simulta-
neous confidence interval and hypothesis testing.
Algorithm 10: Private Bootstrap Method for Simultaneous Inference in Het-
erogeneous Federated Learning for Machine i ∈ {1,...,m}
Input : Dataset (y ,X ), number of data n, privacy parameters ε,δ, estimators
i i
of parameters βˆ(i), Θˆ from Algorithms 8 and 3, number of iterations
for Bootstrap q, quantile α, noise level B . (RN: σ?)
6
1 for t from 0 to q do
2 Generate n independent standard Gaussian random variables e 1,...,e n.
3 Calculate U t = ∥Privatemax([√σ n (cid:80)n j=1ΘˆX ije j] G,ϵ,δ,B 6)∥ ∞
4 end
5 Output: Compute the α-quantile C U(α) of (|U 1|,|U 2|,...,|U q|) for α ∈ (0,1).
Compared with Algorithm 7 introduced for simultaneous inference in homogeneous
federated learning, bootstrap algorithm in Algorithm 10 runs within the local machine
of interest. Using the output from Algorithm 10, we build a simultaneous confidence
interval for each β(i) (k ∈ G) using C (α) by
k U
(cid:20) (cid:21)
1 1
βˆ(i,u)
− √ C (α),
βˆ(i,u)
+ √ C (α) .
k n U k n U
5.2 Theoretical Results
Inthissubsection,weprovidetheoreticalanalysisforthealgorithmsinheterogeneousfed-
erated learning settings. We begin our theoretical analysis with the estimation problem,
which resembles Theorem 3.
Intuitively, when β(i) are similar but not identical, federated learning can be used to
estimate their common elements and the remaining parameters can be estimated indi-
vidually on each machine. This results in a sharper rate of convergence as the estimation
of the common component u can exploit the information from more data points. We
summarize the result in Theorem 7.
Theorem 7 Assume that the conditions in Theorem 5 hold. Further assume that for
Algorithm 8, ∥v ∥ = s = s−s for all i = 1,...,m, ∥u∥ = s , ∥u∥ ≤ c /2, and
i 0 1 √0 0 0 2 0
∥v ∥ ≤ c /2. Let B = c (2R+ s c c ). Then, for the output βˆ(i) from Algorithm 8,
i 2 0 5 x 1 0 x
we have
s logd s 2logd2log(1/δ)log3mn s logd s 2logd2log(1/δ)log3n
∥βˆ(i)−β(i)∥2 ≤ c 0 +c 0 +c 1 +c 1 ,
2 0 mn 1 m2n2ϵ2 2 n 3 n2ϵ2
(5.2)
where c ,c ,c ,c > 0 are some constants.
0 1 2 3
Inthecasewheres ≪ s , i.e., themodelsarelargelydifferentacrossmachines, thethird
0 1
and fourth term on the right hand side of (5.2) dominates the estimation error, and the
estimation accuracy of β(i) via federated learning becomes closer to that with a single
21machine (m = 1). In high level, this is because the information from other machines
is not helpful in the estimation when there exists a large dissimilarity of models across
machines. However, with a large s ≫ s , federated learning can leverage the similarity
0 1
of models to improve estimation accuracy. As a result, the rate in (5.2) becomes closer
to the rate in 4.2 for homogeneous federated learning setting when s /s → 0.
0 1
We next present our results for the inference problems. To start we verify that the
output from Algorithm 9 is a asymptotic 1−α confidence interval for β(i).
k
Theorem 8 Assume the conditions in Theorem 3 hold and assume that s∗ √logd = o(1)
n
and max(2γµˆ2 s s2 1log2dlog(1/δ)log3mn , 2γµˆ2 s s2 0log2dlog(1/δ)log3n ) = o(1). Let a be the variable
νˆ2 m2n2ϵ2 νˆ2 n2ϵ2
s s
defined in (5.1). Then, for the de-biased estimator βˆ(i,u) defined in (4.1), the constructed
k
confidence interval is asympotically valid:
lim
P(β(i)
∈ J (α)) = 1−α,
k k
n→∞
where
(cid:20) σˆΦ−1(1−α/2)(cid:114) 8∆2log(1/δ)
J (α) = βˆ(i,u) −a− √ Θˆ⊤ΣˆΘˆ + 1 ,
k k n k k nϵ2
σˆΦ−1(1−α/2)(cid:114) 8∆2log(1/δ)(cid:21)
βˆ(i,u) +a+ √ Θˆ⊤ΣˆΘˆ + 1
k n k k nϵ2
Also, J (α) is (ϵ,δ)-differentially private.
k
Finally, we provide a statistical guarantee for Algorithm 10. Similar to the previous
section, we define M as:
√
M = M(βˆ(i,u)) = max| n(βˆ(i,u) −β(i) )|.
k k
k∈G
Theorem 9 AssumethattheconditionsinTheorem4hold. Weadditionallyassumethat
s∗ √logd = o(1) and the privacy cost is dominated by the statistical error, i.e., there exists a
n
constant c such that s∗2log2dlog(1/δ)log3mn ≤ c·s∗logd and s∗2log2dlog(1/δ)log3n ≤ c·s∗logd.
m2n2ϵ2 mn n2ϵ2 n
We also assume that there exists a constant k such that log7(dn)/n ≤ 1 . The noise
0 nk0
(cid:113)
level is chosen as B = 2 slognc c . Then,
6 n x 1
sup |P(M ≤ C (α))−α| = o(1).
U
α∈(0,1)
Theorem 9 states that α-quantile of M is asymptotically close to C (α), which vali-
U
dates the 1−α simultaneous confidence intervals based on C (α) obtained by the boot-
U
strap method. This result allows us to perform simultaneous inference such as the con-
fidence intervals and hypothesis testing based on C (α).
U
226 Simulations
In this section, we conduct simulations to investigate the performance of our proposed
algorithm as discussed in the preceding sections. Specifically, we explore the more com-
plex heterogeneous federated learning setting, where each machine operates on different
models yet exhibits similarities. Our simulations are divided into three main parts.
In Section 6.1, we present the simulation results for the coordinate-wise estimation
problem within a private federated setting, discussing the differences between the esti-
mated βˆ and the true β∗ across various scenarios. We also examine the coverage of our
proposedconfidenceintervals. Section6.2extendsthesettingstosimultaneousinference.
Wegeneratesimulateionsimulationdatasetsasfollows. First,wesamplethedataX ,
i
for i = 1,2,...,m, where each X follows a Gaussian distribution with mean zero and
i
covariance matrix Σ. We set Σ such that for each j,j′ ∈ {1,2,...,d}, Σ = 0.5|j−j′|.
j,j′
On each machine, we assume a s∗-sparse unit vector β(i) with s∗ = s +s , where s is
0 1 0
the number of non-zero shared signals. For each β(i), we set the first s shared elements
√ 0
to 1/ s∗ and additionally select machine-specific s entries from the remaining d−s
√ 1 0
indices to be 1/ s∗. We then compute Y = X β(i) + W , where each W follows a
i i i i
Gaussian distribution N(0,σ2I) with σ = 0.5.
6.1 Estimation and Confidence Interval
In this subsection, we investigate the estimation accuracy and confidence interval cov-
erage of our algorithm for coordinate-wise inference. Namely, we consider the following
scenarios:
• Fix number of machines m = 15, ϵ = 0.8, δ = 1/(2mn), d = 800, s∗ = 15
and s = 6. Set the number of samples on each machine to be 4000,5000,6000,
0
respectively.
• Fix number of samples on each machine n = 4000, ϵ = 0.8, δ = 1/(2mn), d = 800,
s∗ = 15 and s = 6. Set the number of machines m to be 5,10,15,
0
• Fix number of machines m = 15, number of samples on each machine n = 4000,
ϵ = 0.8, δ = 1/(2mn), d = 800. Set, s∗ = 15,s = 6, s∗ = 10,s = 4, s∗ = 20,s =
0 0 0
8, respectively.
• Fix number of machines m = 15, number of samples on each machine n = 4000,
ϵ = 0.8, δ = 1/(2mn), d = 800, s∗ = 15. Set s = 6,8,10, respectively.
0
• Fix number of machines m = 15, number of samples on each machine n = 4000,
δ = 1/(2mn), d = 800, s∗ = 15 and s = 6. Set ϵ = 0.3,0.5,0.8 respectively.
0
• Fix number of machines m = 15, number of samples on each machine n = 4000,
ϵ = 0.8, δ = 1/(2mn), s∗ = 15 and s = 6. Set d = 600,800,1000, respectively.
0
Foreachsetting, wereporttheaverageestimationerror∥βˆ−β∗∥2 among50replications.
2
Also, in each setting, we calculate the confidence interval with α = 0.95 for each index
23of β∗ using our proposed algorithm. To evaluate the quality of confidence interval, we
define cov as the coverage of the confidence interval:
d
(cid:88)
cov := d−1 P[β∗ ∈ J (α)].
i i
i=1
We also define the coverage for non-zero and zero entries of β∗ by cov and cov ,
S Sc
respectively, where S is the set of non-zero indices in β∗.
(cid:88) (cid:88)
cov = |S|−1 P[β∗ ∈ J (α)] , cov = |Sc|−1 P[β∗ ∈ J (α)].
S i i Sc i i
i∈S i∈Sc
We report the estimation error, coverage of true parameter and length of confidence
interval for each configuration listed above in Table 2:
Simulation Results
(n,m,d,s∗,s ,ϵ) Estimation Error cov cov cov length
0 S Sc
(Sd)
(3000,15,800,15,8,0.8) 0.0213 (0.0028) 0.940 0.929 0.940 0.0532
(4000,15,800,15,8,0.8) 0.0170 (0.0032) 0.945 0.960 0.944 0.0437
(5000,15,800,15,8,0.8) 0.0141 (0.0021) 0.940 0.945 0.940 0.0378
(4000,10,800,15,8,0.8) 0.0218 (0.0047) 0.945 0.945 0.945 0.0437
(4000,20,800,15,8,0.8) 0.0126 (0.0025) 0.944 0.941 0.944 0.0437
(4000,15,600,15,8,0.8) 0.0162 (0.0031) 0.946 0.933 0.946 0.0436
(4000,15,1000,15,8,0.8) 0.0191 (0.0027) 0.940 0.933 0.940 0.0439
(4000,15,800,15,4,0.8) 0.0188 (0.0032) 0.952 0.945 0.953 0.0420
(4000,15,800,15,12,0.8) 0.0137 (0.0016) 0.944 0.937 0.944 0.0462
(4000,15,800,10,8,0.8) 0.0105 (0.0017) 0.946 0.947 0.946 0.0389
(4000,15,800,20,8,0.8) 0.0243 (0.0036) 0.941 0.932 0.941 0.0497
(4000,15,800,15,8,0.5) 0.0240 (0.0038) 0.940 0.949 0.940 0.0550
(4000,15,800,15,8,0.3) 0.0943 (0.0281) 0.928 0.941 0.928 0.0792
Table 2: Table for Simulation Results of the private federated linear regression
From Table 2, we observe a consistent result with our theory. Namely, for the esti-
mation error, the error becomes small as ϵ gets larger as we require less level of privacy.
24Also, moredatapointsoneachmachine, morenumberofmachines, smallersparsitylevel
leadtobetterestimationaccuracy. Forconfidenceintervals, weobservethatthecoverage
is close to 0.95 for cov, cov , and cov , is and stable in different settings. To further
S Sc
illustrate our claim, we pick the setting of (n,m,d,s,s ,ϵ) = (4000,15,800,15,8,0.8)
0
and plot the confidence intervals versus the true value among 50 replications in Figure 3.
We randomly select 60 out of 800 coordinates.
Fig 3: Confidence intervals for β for each coordinate k randomly selected from 800
k
coordinates. vertical axis stands for the value of β . Red points stand for the true β
k k
while black points stand for the estimated β . We mention that the result averaged over
k
50 iterations.
We also summarize our results in Figure 6.1, where we plot the estimation error
against the change in the number of samples, sparsity, and number of machines. For
the figure, we fixed m = 15, d = 800, s∗ = 16, s = 8, for the middle figure, we fixed
0
n = 4000, m = 15, d = 800, ϵ = 0.5, and for the right figure, we fixed d = 800, s∗ = 16,
s = 8, ϵ = 0.5. The error is averaged over 200 replications.
0
25Fig 4: Plot for the estimation results. Left: Log estimation error with different number
of samples n, Middle: Log estimation error with different sparsity s∗, Right: Log
estimation error with different number of machines m.
From the left figure in Figure 6.1, we observe the decreasing error when we increase
n. When the privacy parameter ϵ is large, we have better estimation error. From the
middle figure, we observe that as the sparsity level s grows, the estimation error also
increases. Also, when the sparsity for the shared signal s becomes large, the estimation
0
error also becomes large. In the right figure, we observe a consistent decrease of error
when we increase the number of machines. All these figures support Theorem 7.
6.2 Simultaneous Inference
In this subsection, we investigate our proposed algorithms for simultaneous inference
problems. We aim to build a simultaneous confidence interval when α = 0.05 under
three settings: G = {1,2,...,d}, G = S, and G = Sc. For each setting, we repeat 50
simulations and report the coverage and length of the confidence intervals. The results
are shown in Table 5.
From simulation results, we can observe that our proposed simultaneous confidence
interval mostly exhibit over-coverage for G = Sc, and under-coverage for G = S. This
pattern has also been observed in previous works addressing simultaneous inference [38,
42]. Therefore, this could be attributed to the inherent nature of simultaneous inference
rather than to algorithmic reasons.
7 Discussions and Future Work
In this paper, we study the high-dimensional estimation and inference problems within
the context of federated learning. In scenarios involving an untrusted central server, our
findings reveal that accurate estimation is infeasible, as the rate of convergence is ad-
versely proportional to the dimension d. Conversely, in the trusted central server setting,
we developed algorithms that achieve an optimal rate of convergence. We also explored
26Simulation Results for Simultaneous Inference
(n,m,d,s∗,s ,ϵ) cov cov cov len(cov) len(cov ) len(cov )
0 S Sc S Sc
(3000,15,800,15,8,0.8) 0.981 0.883 0.983 0.091 0.066 0.091
(4000,15,800,15,8,0.8) 0.985 0.910 0.987 0.079 0.057 0.079
(5000,15,800,15,8,0.8) 0.987 0.875 0.990 0.071 0.051 0.071
(4000,10,800,15,8,0.8) 0.989 0.894 0.991 0.079 0.057 0.079
(4000,20,800,15,8,0.8) 0.983 0.898 0.986 0.079 0.057 0.079
(4000,15,600,15,8,0.8) 0.993 0.878 0.995 0.077 0.057 0.077
(4000,15,1000,15,8,0.8) 0.994 0.878 0.997 0.080 0.057 0.080
(4000,15,800,15,4,0.8) 0.983 0.772 0.993 0.079 0.057 0.079
(4000,15,800,15,12,0.8) 0.975 0.957 0.974 0.079 0.058 0.079
(4000,15,800,10,8,0.8) 0.986 0.976 0.985 0.079 0.055 0.079
(4000,15,800,20,8,0.8) 0.974 0.850 0.982 0.078 0.059 0.078
(4000,15,800,15,8,0.5) 0.940 0.882 0.940 0.103 0.083 0.102
(4000,15,800,15,8,0.3) 0.953 0.789 0.975 0.127 0.097 0.126
Table 5: Simulation results of the private simultaneous inference in different settings.
27inferencechallenges, detailingmethodologiesforbothpoint-wiseconfidenceintervalsand
simultaneous inference.
Thereareseveralextensionsforfurtherresearch. Currently, ourmodelspresumethat
each machine operates under a linear regression framework. We can possibly expand
our algorithm to accomodate more complex models, such as generalized linear models,
classification models, or broader machine learning models. Moreover, an interesting
extension would be to refine our understanding of model similarity across machines.
Although Section 5 currently bases model similarity on L norms, reflecting non-sparse
0
patterns,futurestudiescouldexploreL norm-basedsimilarities,particularlyfocusingon
p
L and L norms, to enhance our approach to heterogeneous federated learning settings.
1 2
References
[1] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov,
Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings
of the 2016 ACM SIGSAC conference on computer and communications security,
pages 308–318, 2016.
[2] Jayadev Acharya, Clément L Canonne, and Himanshu Tyagi. General lower bounds
for interactive high-dimensional estimation under information constraints. arXiv
preprint arXiv:2010.06562, 2020.
[3] NamanAgarwal, AnandaTheerthaSuresh, FelixYu, SanjivKumar, andHBrendan
Mcmahan. cpsgd: Communication-efficient and differentially-private distributed
sgd. arXiv preprint arXiv:1805.10559, 2018.
[4] Leighton Pate Barnes, Wei-Ning Chen, and Ayfer Özgür. Fisher information under
local differential privacy. IEEE Journal on Selected Areas in Information Theory,
1(3):645–659, 2020.
[5] Leighton Pate Barnes, Yanjun Han, and Ayfer Ozgur. Lower bounds for learning
distributions under communication constraints via fisher information. Journal of
Machine Learning Research, 21(236):1–30, 2020.
[6] Andrea Bittau, Úlfar Erlingsson, Petros Maniatis, Ilya Mironov, Ananth Raghu-
nathan, David Lie, Mitch Rudominer, Ushasree Kode, Julien Tinnes, and Bernhard
Seefeld. Prochlo: Strong privacy for analytics in the crowd. In Proceedings of the
26th symposium on operating systems principles, pages 441–459, 2017.
[7] Mark Braverman, Ankit Garg, Tengyu Ma, Huy L Nguyen, and David P Woodruff.
Communication lower bounds for statistical estimation problems via a distributed
data processing inequality. In Proceedings of the forty-eighth annual ACM sympo-
sium on Theory of Computing, pages 1011–1020, 2016.
28[8] T Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates
of convergence for parameter estimation with differential privacy. arXiv preprint
arXiv:1902.04495, 2019.
[9] T Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy in gen-
eralized linear models: Algorithms and minimax lower bounds. arXiv preprint
arXiv:2011.03900, 2020.
[10] Victor Chernozhukov, Denis Chetverikov, and Kengo Kato. Gaussian approxima-
tions and multiplier bootstrap for maxima of sums of high-dimensional random
vectors. The Annals of Statistics, 41(6):2786–2819, 2013.
[11] John Duchi and Ryan Rogers. Lower bounds for locally private estimation via
communication complexity. In Conference on Learning Theory, pages 1161–1191.
PMLR, 2019.
[12] Cynthia Dwork and Vitaly Feldman. Privacy-preserving prediction. In Conference
On Learning Theory, pages 1693–1702. PMLR, 2018.
[13] CynthiaDwork,FrankMcSherry,KobbiNissim,andAdamSmith. Calibratingnoise
to sensitivity in private data analysis. In Theory of cryptography conference, pages
265–284. Springer, 2006.
[14] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential
privacy. Foundations and Trends in Theoretical Computer Science, 9(3-4):211–407,
2014.
[15] Cynthia Dwork, Adam Smith, Thomas Steinke, and Jonathan Ullman. Exposed! a
survey of attacks on private data. Annual Review of Statistics and Its Application,
4:61–84, 2017.
[16] Cynthia Dwork, Weijie J Su, and Li Zhang. Differentially private false discovery
rate control. arXiv preprint arXiv:1807.04209, 2018.
[17] Úlfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Shuang
Song, Kunal Talwar, and Abhradeep Thakurta. Encode, shuffle, analyze privacy re-
visited: Formalizations and empirical evaluation. arXiv preprint arXiv:2001.03618,
2020.
[18] Ankit Garg, Tengyu Ma, and Huy Nguyen. On communication cost of distributed
statistical estimation and dimensionality. Advances in Neural Information Process-
ing Systems, 27:2726–2734, 2014.
[19] RobinCGeyer, TassiloKlein, andMoinNabi. Differentiallyprivatefederatedlearn-
ing: A client level perspective. arXiv preprint arXiv:1712.07557, 2017.
29[20] Antonious Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and
Ananda Theertha Suresh. Shuffled model of differential privacy in federated learn-
ing. InInternational Conference on Artificial Intelligence and Statistics,pages2521–
2529. PMLR, 2021.
[21] Yanjun Han, Ayfer Özgür, and Tsachy Weissman. Geometric lower bounds for
distributed parameter estimation under communication constraints. In Conference
On Learning Theory, pages 3163–3188. PMLR, 2018.
[22] Torsten Hothorn, Frank Bretz, and Peter Westfall. Simultaneous inference in gen-
eral parametric models. Biometrical Journal: Journal of Mathematical Methods in
Biosciences, 50(3):346–363, 2008.
[23] Rui Hu, Yuanxiong Guo, Hongning Li, Qingqi Pei, and Yanmin Gong. Personal-
ized federated learning with differential privacy. IEEE Internet of Things Journal,
7(10):9530–9539, 2020.
[24] Adel Javanmard and Andrea Montanari. Confidence intervals and hypothesis test-
ing for high-dimensional regression. The Journal of Machine Learning Research,
15(1):2869–2909, 2014.
[25] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Ben-
nis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode,
Rachel Cummings, et al. Advances and open problems in federated learning. Foun-
dations and Trends® in Machine Learning, 14(1–2):1–210, 2021.
[26] JakubKonecy,HBrendanMcMahan,FelixXYu,PeterRichtárik,AnandaTheertha
Suresh, and Dave Bacon. Federated learning: Strategies for improving communica-
tion efficiency. arXiv preprint arXiv:1610.05492, 2016.
[27] Jason D Lee, Qiang Liu, Yuekai Sun, and Jonathan E Taylor. Communication-
efficient sparse regression. The Journal of Machine Learning Research, 18(1):115–
144, 2017.
[28] Mengchu Li, Ye Tian, Yang Feng, and Yi Yu. Federated transfer learning with
differential privacy. arXiv preprint arXiv:2403.11343, 2024.
[29] Sai Li, T Tony Cai, and Hongzhe Li. Transfer learning for high-dimensional lin-
ear regression: Prediction, estimation, and minimax optimality. arXiv preprint
arXiv:2006.10593, 2020.
[30] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learn-
ing: Challenges, methods, and future directions. IEEE signal processing magazine,
37(3):50–60, 2020.
[31] AndrewLowyandMeisamRazaviyayn. Privatefederatedlearningwithoutatrusted
server: Optimalalgorithmsforconvexlosses.arXivpreprintarXiv:2106.09779,2021.
30[32] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Aguera y Arcas. Communication-efficient learning of deep networks from
decentralized data. In Artificial intelligence and statistics, pages 1273–1282. PMLR,
2017.
[33] Brendan McMahan and Abhradeep Thakurta. Federated learning with formal dif-
ferential privacy guarantees. Google AI Blog, 2022.
[34] H Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning
differentially private recurrent language models. arXiv preprint arXiv:1710.06963,
2017.
[35] Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially pri-
vate selection. In 2017 IEEE 58th Annual Symposium on Foundations of Computer
Science (FOCS), pages 552–563. IEEE, 2017.
[36] KunalTalwar, AbhradeepThakurta, andLiZhang. Nearly-optimalprivatelasso. In
Proceedings of the 28th International Conference on Neural Information Processing
Systems-Volume 2, pages 3025–3033, 2015.
[37] Stacey Truex, Ling Liu, Ka-Ho Chow, Mehmet Emre Gursoy, and Wenqi Wei. Ldp-
fed: Federated learning with local differential privacy. In Proceedings of the Third
ACM International Workshop on Edge Systems, Analytics and Networking, pages
61–66, 2020.
[38] SaraVandeGeer, PeterBühlmann, Ya’acovRitov, andRubenDezeure. Onasymp-
totically optimal confidence regions and tests for high-dimensional models. 2014.
[39] KangWei, JunLi, MingDing, ChuanMa, HowardHYang, FarhadFarokhi, ShiJin,
Tony QS Quek, and H Vincent Poor. Federated learning with differential privacy:
Algorithms and performance analysis. IEEE Transactions on Information Forensics
and Security, 15:3454–3469, 2020.
[40] Manuel Wiesenfarth, Tatyana Krivobokova, Stephan Klasen, and Stefan Sperlich.
Direct simultaneous inference in additive models and its application to model un-
dernutrition. Journal of the American Statistical Association, 107(500):1286–1296,
2012.
[41] Yang Yu, Shih-Kang Chao, and Guang Cheng. Distributed bootstrap for simulta-
neous inference under high dimensionality. Journal of Machine Learning Research,
23(195):1–77, 2022.
[42] Xianyang Zhang and Guang Cheng. Simultaneous inference for high-dimensional
linear models. Journal of the American Statistical Association, 112(518):757–768,
2017.
31[43] Yuchen Zhang, John C Duchi, Michael I Jordan, and Martin J Wainwright.
Information-theoretic lower bounds for distributed statistical estimation with com-
munication constraints. In NIPS, pages 2328–2336. Citeseer, 2013.
[44] Yuchen Zhang, Martin J Wainwright, and John C Duchi. Communication-efficient
algorithms for statistical optimization. Advances in neural information processing
systems, 25, 2012.
[45] Zhe Zhang. Differential privacy in statistical learning. ProQuest Dissertations and
Theses, page 156, 2023.
[46] Zhe Zhang and Linjun Zhang. High-dimensional differentially-private em algorithm:
Methods and near-optimal statistical guarantees. arXiv preprint arXiv:2104.00245,
2021.
32A Proof of main results
A.1 Proof of Theorem 1
We show the proof of the lower bound of the estimation. The main idea of the proof is
as follows, we will first assume that in the general case where each data point on each
machine follows a general distribution p , then we will further assume some conditions
θ
of this distribution, and prove that the lower bound of the mean estimation could be
attained under these conditions. Finally, we will show that under the assumptions that
thedatapointsfollowthenormaldistribution, thespecificconditionshold, thuswecould
finish the proof.
To start this proof, we first introduce the perturbation space A = {−1,1}k, where
k is a pre-chosen constant and associate each parameter θ with a ∈ A and refer the
distribution p as p . We characterize the distance between two parameters θ and θ′ by
θ a
the hamming distance of z and z′, such approach will be compatible with the Assouad’s
method, as will be shown later in the proof. We note that when the hamming distance of
a and a′ get smaller, it indicts that the distance between θ and θ′ becomes closer. Also,
for each a ∈ A, we further denote a⊕i ∈ A as the vector which flips the sign of the i-th
coordinate of a. Then, we state below conditions:
Condition 1 For every a ∈ A and i ∈ [k], it holds that p ≪ p . Further, there exist
a⊕i a
q and measurable functions ϕ : X → R such that |q | ≤ α, which q is a constant
a,i a,i a,i
and:
dp
a⊕i
= 1+q ϕ .
a,i a,i
dp
a
Condition 2 For all a ∈ A and i,j ∈ [k], E [ϕ ϕ ] = 1 .
pa a,i a,j i=j
Condition 3 There exists some σ ≥ 0 such that, for all a ∈ A, the random vector
ϕ (X) = (ϕ (X)) ∈ Rk is σ2-sub-Gaussian for X ∼ p with independent coordi-
a a,i i∈[k] a
nates.
The above conditions characterize the distribution p , we will later verify that the Gaus-
a
sian distribution could satisfy the above conditions in the later proof. Then, we state
our first claim.
Corollary 1 For each coordinate of the A, for any i = 1,2,...,k, fix τ = P(A =
i
1) ∈ (0,1/2]. Let X ,...,X be the inputs on the local servers, i.i.d. with common
1 m
distribution p⊗n. Let Zm be the information sent from all the local servers to the central
A
machine generated through the channel W. Then, if the condition 1 satisfies, there exists
a constant c, we have:
(cid:32) 1 (cid:88)k
d
(pZm ,pZm )(cid:33)2
≤
c q2mn2max(cid:88)k (cid:90) E p⊗ an[ϕ a,i(X)W(z|X)]2
dµ,
k
i=1
TV +i −i k a∈A
i=1
Y E p⊗ an[W(z|X)]
where pZm = E[pZm|A = +1], pZm = E[pZm|A = −1].
+i A i −i A i
33The proof of the above corollary is in appendix B.1. The above corollary characterizes
the difference between the distribution of pZm and pZm, which is the difference between
+i −i
the distribution of the information about the each coordinate of A, which could be seen
as the information between Y and A, namely, the information between the information
and the parameters.
In the precious corollary, we just assumed a general channel W, in the following
corollary, we could further specifies the above corollary when the channel W, be a ϵ-
differentially private constraint channel Wpriv and we could further simplify the upper
bound in Corollary 1.
Corollary 2 IfWpriv beaprivacyconstraintchannelandforanyfamilyofdistributions
{p ,a ∈ {−1,1}k} satisfying condition 1 and condition 2. With the same notations as
a
Corollary 1 we have:
(cid:32) k (cid:33)2
1 (cid:88)
d
(pZm ,pZm
) ≤
7 mn2q2(enϵ2
−1)
k TV +i −i k
i=1
TheproofoftheabovecorollarycouldbefoundinappendixB.2. Theabovecorollary
focusontheupperboundof 1 (cid:80)k d (pZm,pZm),inthenextcorollary,wewillfocuson
k i=1 TV +i −i
the lower bound, which is an Assouad-type bound. We first introduce another condition:
Condition 4 Fix p ∈ [1,∞). Let ρ be the ℓ loss between the true parameter and the
p
estimation. Then, for every a,a′ ∈ A ∈ {−1,+1}k, the below inequalities hold:
(cid:18)
d
(a,a′)(cid:19)1/p
Ham
l (θ ,θ ) ≥ 4ρ ,
p a a′
τk
whered (a,a′)denotestheHammingdistancewithdefinitiond (a,a′) = (cid:80)k 1(a ̸= a′),
Ham Ham i=1 i i
and τ = P(a = 1) ∈ (0,1/2] for each coordinate a .
i i
The above condition characterizes the connection between θ with the perturba-
tion space. With the above assumption, we could further obtain the lower bound of
1 (cid:80)k d (pZm,pZm):
k i=1 TV +i −i
Corollary 3 Let p ≥ 1 and assume that {p ,a ∈ A}, τ ∈ [0,1/2] satisfy Condition 4.
a
Let A be a random variable on {−1,1}k with distribution Rad(τ)⊗k. Suppose that θˆ
constitutes an (n,ρ)-estimator of the true parameter θ∗ under l loss and P[p ∈ P ] ≥
p A Θ
1−τ/4. Then the below inequality holds:
k
1 (cid:88)
d
(pZm ,pZm
) ≥
n
,
k TV +i −i 4
i=1
where pZm = E[pZm|A = +1], pZm = E[pZm|A = −1].
+i A i −i A i
34The proof of the above corollary could be found in appendix B.3. In the following
proof, we are going to verify that the Gaussian distribution satisfies all the above con-
ditions, thus the result in Corollary 2 and Corollary 3 holds. Then, according to these
two corollaries, we will present the lower bound for the mean estimation in the high-
dimensional federated learning setting.
For the parameters, we could fix p = 2, k = d, A = {−1,+1}d. For the probability
where τ = P(a ) = 1, we fix τ = s . Let φ denote the probability density function
i 2d
of the standard Gaussian distribution N(0,I). We first suppose that, for some ρ ∈
(0,1/8], there exists an (n,ρ)-estimator for the true parameter µ under ℓ loss. Then,
p
if we have ρ2 ≥ s/n, then we could finish the proof. Otherwise, we fix a parameter
γ = √4ρ ∈ (0,1/2], this is possible with a choice of s, the sparsity level. We could
s/2
design the parameter, the mean of the Gaussian distribution µ and A by the formula:
µ = γ(a+1 ), where a ∈ A. Then, we could verify that P[∥µ ∥ ≤ 2τd] ≥ 1−τ/4,
a d a 0
where ∥µ ∥ = (cid:80)d 1 = ∥a∥ . From the definition of Gaussian density, for a ∈ A,
a 0 i=1 ai=1 +
we have:
p a(x) = e−γ2∥µa∥2 2/2·eγ⟨x,a+1 d⟩·φ(x).
Therefore, for a ∈ A and i ∈ [d], we have
p (x) =
e−2γxiaie2γ2ai
·p (x) = (1+q·ϕ (x))·p (x),
a⊕i a a,i a
where q =
(cid:112)
e4γ2 −1 and ϕ (x) =
1−e−√2γxiaie2γ2ai.
By using the Gaussian moment-
a,i
e4γ2−1
generating function, we could verify that, for i ̸= j,
E [ϕ (X)] = 0, E [ϕ (X)2] = 1, and E [ϕ (X)ϕ (X)] = 0,
pa a,i pa a,i pa a,i a,j
so that the condition 1 and condition 2 are satisfied. Here, notice that in the proof
of Corollary 1, we require that |q · ϕ (x)| = C/n where C is a constant, we could
verify that since ρ ≤ c·(cid:112) s/n, then γa,i ≤ c√ n from the definition of γ, Then we have
|q·ϕ (x)| ≤ c |γ2−γx | ≤ c /n, which could verify the condition for corollary 1. Also,
z,i 0 i 0
by the choice of γ and ρ, it is easy to verify that condition 4 also holds with:
(cid:114)
d (a,a′)
ham
ℓ (µ(p ),µ(p )) = 4ρ· .
2 a a′
τd
Thus, all the conditions mentioned above have been verified. Then, we could finish
the proof of our lower bound. Combining the result of corollary 2 and corollary 3, we get
the result below:
n2d ≤ cmn2q2(enϵ2 −1),
where c is a constant. Also, notice that q2 = e4γ2 −1 ≤ 8γ2 holds since γ ≤ 1/2, we
could find a constant c , it follows that
0
s·d
ρ2 ≥ c · ,
0 mnϵ2
35(cid:113)
From the choice of ρ, we could claim that ρ ≥ Ω( sd ∧1), then we could obtain our
mnϵ2
lower bound, which finished the proof. □
A.2 Proof of Theorem 2
In the proof of Theorem 2, we will design a mechanism to get an estimation of the
parameter and then we obtain the upper bound of ∥µ−µˆ∥2. The overall mechanism is
2
designedasfollows: wefirstcalculatethemeanforndatapointsoneachmachine. Then,
wetransformtheGaussianmeantoBernoullimeanaccordingtothesignoftheGaussian
meanmotivatedbytheAlgorithm2discussedin[2], l-bitprotocolforestimatingproduct
of Bernoulli family.
Then, we could use the ϵ-local differentially private mechanism to achieve mean es-
timation for the product of Bernoulli family in the federated learning setting. After
obtaining the estimation, we could convert the estimated Bernoulli mean back to Gaus-
sian mean estimation.
First, for each data point on the machine, it follows the distribution of N(µ,I ) .
d
Then for the mean on i-th machine, the mean X¯ follows a distribution of N(µ,1/nI).
i
Then, we could convert it to a Bernoulli variable Z, where Z = 1 when X¯ > 0 and
i ij
Z = −1 when X¯ ≤ 0. Then the mean of Z, which denote as v is:
i ij
√
(cid:18) (cid:19)
nµ
v = 2P(X > 0)−1 = Erf √ i ,
i i
2
for each coordinate of v. Suppose the estimation of v is denoted by vˆ, then suppose the
√
estimation µˆ is given by µˆ i = √ n2erf−1(vˆ i), we could find such relationship:
d d d
(cid:88) 2 (cid:88) 1 (cid:88)
∥µ−µˆ∥2 = |µ −µˆ |2 = · |Erf−1(v )−Erf−1(vˆ)|2 ≤ c· · |v −vˆ|2,
2 i i n i i n i i
i=1 i=1 i=1
(A.1)
where c is a constant. The last inequality comes from the Lipschitz condition of a Erf
function. Then, we could get the upper bound for the Bonoulli mean estimation directly
from Theorem 3 in [2], where
d·s
∥v−vˆ∥2 ≤ c· ,
2 mϵ2
where ϵ is the privacy parameter, m is the number of machines. Combining the last
two inequalities (A.1) and (A.2), we could get the upper bound for the mean Gaussian
estimation:
s·d
∥µ−µˆ∥2 ≤ c· ,
2 mnϵ2
which finished the proof. □
36A.3 Proof of Theorem 3
It is not difficult to observe that the convergence rate would be the same as in the
non-federated learning setting. We denote L as the sample loss function and L be the
n
population level. In the estimation of β, L(β) = ∥Y − Xβ∥2 and L is the sample
2 n
version. In the estimation of Θ , L(Θ ) = 1Θ⊤ΣΘ − ⟨e ,Θ ⟩. We start from the
k k 2 k k j k
estimation of β and the estimation of Θ is the same. In this proof, we use n to refer
0
the total number of samples n = m·n. Then, it holds that:
0
Lemma A.1 Under assumptions of Theorem 5, it holds that:
8ν ∥βt−βˆ∥2 ≤ ⟨∇L (βt)−∇L (βˆ),βt−βˆ⟩ ≤ 8µ ∥βt−βˆ∥2. (A.2)
s 2 n n s 2
Proof: From direct calculation, we could obtain that:
⟨∇L (βt)−∇L (βˆ),βt−βˆ⟩ = 2(βt−βˆ)TΣˆ(βt−βˆ) ≤ 2µ ∥βt−βˆ∥2 ≤ 2µ ∥βt−βˆ∥2
n n s+s∗ 2 2s 2
The last inequality is according to the choice of s such that s∗ ≤ s. Then, we also have
µ ≤ 4µ . Thus we have obtained the right hand side of the inequality. By a similar
2s s
approach, we could also obtain the left hand side.
Lemma A.2 Under assumptions of Theorem 5, it holds that there exists an absolute
constant ρ such that
 
(cid:18) (cid:19)
L n(βt+1)−L n(βˆ) ≤ 1− 24ν µs (cid:16) L n(βt)−L n(βˆ)(cid:17) +c 3(cid:88) ∥w it∥2 ∞+∥w˜ St t+1∥2 2,
s
i∈[s]
(A.3)
where c is a constant number such that c = max(µ (72·8µ +13),68µ +2/3)
3 3 s s s
Notice that w ,w are injected from the NoisyHT algorithm. The proof of the above
i
lemma follows from the result in Lemma 8.3 from [8]. Then, we could start the proof by
(cid:16) (cid:17)
iterating (A.3) over t. Denote W = c (cid:80) ∥wt∥2 +∥w˜t ∥2 to obtain
t 3 i∈[s] i ∞ St+1 2
L (βT)−L (βˆ) ≤
(cid:18)
1−
ν
s
(cid:19)T
(cid:16)
L (β0)−L
(βˆ)(cid:17)
+T (cid:88)−1(cid:18)
1−
1
(cid:19)T−k−1
W
n0 n0 24µ n0 n0 ρL2 k
s
k=0
≤
(cid:18)
1−
ν
s
(cid:19)T 4µc2+T (cid:88)−1(cid:18)
1−
ν
s
(cid:19)T−k−1
W . (A.4)
24µ 0 24µ k
s s
k=0
Thesecondinequalityisaconsequenceoftheupperinequalityin(A.2)andtheℓ bounds
2
of β0 and βˆ. We can also bound L (βT)−L (βˆ) from below by the lower inequality
n0 n0
in (A.2):
L (βT)−L (βˆ) ≥ L (βT)−L (β∗) ≥ 4ν ∥βT −β∗∥2−⟨∇L (β∗),β∗−βT⟩.
n0 n0 n0 n0 s 2 n0
(A.5)
37Now (A.4) and (A.5) imply that, with T = (ρL2)log(cid:0) 8c2Ln (cid:1),
0 0
4ν ∥βT −β∗∥2 ≤ ∥∇L (β∗)∥
√
s+s∗∥β∗−βT∥ +
1 +T (cid:88)−1(cid:18)
1−
ν
s
(cid:19)T−k−1
W .
s 2 n0 ∞ 2 n 24µ k
0 s
k=0
(A.6)
√ 1 24µ
≤ ∥∇L (β∗)∥ s+s∗∥β∗−βT∥ + + s maxW . (A.7)
n0 ∞ 2
n 0 ν s k
k
Thus,
s∗logd µ
∥βT −β∗∥2 ≤ k· + s maxW .
2 n 0 ν s2 k k
In the above inequality, k is a constant. Then, we could calculate the upper bound of
W . From the result of tail bound of Laplace random variables, we could find that with
k
high probability that W ≤ c s2log2dlog(1/δ)logn3/n2ϵ2), where c = max(µ (9µ +
k 4 4 s s
1/4),17/16µ +1/96). Then, we have with high probability:
s
slogd 6c µ
∥βT −β∗∥2 ≤ k· + 4 s s2log2dlog(1/δ)logn3/n2ϵ2.
2 n ν2 0 0
0 s
Similarly, we could obtain the same result for the estimation of Θˆ , which finishes the
k
proof.
A.4 Proof of Theorem 4
Thestructureoftheproofconsistofthreepart,thefirstpartistoshowthatouralgorithm
provides an (ϵ,δ)-differentially private confidence interval. In the second part, we will
show that βˆ is a consistent estimator of true β , which is unbiased. In the last part, we
k k
will show that the (1−α) confidence interval is asymptotically valid. Before we start the
first part, let us first analyze c :
x
According to the assumptions of the theorem, we have learnt that for each row of X,
xΣ−1/2 is sub-Gaussian with κ = ∥Σ−1/2x∥ . Then according to the properties of
ψ2
(cid:112)
sub-Gaussian random variables, we have: ∥xΣ−1/2∥ ≤ 3 2κ2logd with probability
∞
1−d−2. Then for each element of x , i = 1,2,...,d, we have:
i
x = e⊤x = e⊤Σ1/2Σ−1/2x
i j j
Thus,
x ≤ ∥e⊤Σ1/2∥ ∥Σ−1/2x∥ ≤ ∥Σ1/2∥ ∥Σ−1/2x∥
i j 1 ∞ 2 ∞
(cid:112)
Then, with probability 1−d−2, we have x ≤ 3 2Lκ2logd. By a union bound, we could
i
(cid:112)
havewithprobability1−d−1, ∥x∥ ≤ 3 2Lκ2logd. Bythechoiceofc inthetheorem,
∞ x
we have ∥x∥ ≤ c with a high probability.
∞ x
Then, we could verify that the confidence interval is (ϵ,δ)-differentially private. From
[8], we could obtain that the output βˆu is (ϵ,δ)-DP. In a similar manner, we could also
38verify that the output Θˆ is also (ϵ,δ)-DP. Thus, for two adjacent data sets (X,Y) and
k
(X′,Y′) which differ by one data (x ,y ) and (x′ ,y′ ), we have:
ij ij ij ij
1 1 1
| (Θˆ⊤x Π (y )−Θˆ⊤x x⊤βˆu)| ≤ |Θˆ⊤x Π (y )|+ |Θˆ⊤x x⊤βˆu|
n k ij R ij k ij ij n k ij R ij n k ij ij
0 0 0
1 1
≤ |Θˆ⊤x ||Π (y )|+ |Θˆ⊤x ||x⊤βˆu|
n k ij R ij n k ij ij
0 0
1 √ 1
≤ sc c R+ sc c c2
n 1 x n 0 1 x
0 0
Thus,
1 1
| (Θˆ⊤x Π (y )−Θˆ⊤x x⊤βˆu)− (Θˆ⊤x′ Π (y′ )−Θˆ⊤x′ x′⊤βˆu)|
n k ij R ij k ij ij n k ij R ij k ij ij
0 0
1 1
= | (Θˆ⊤x Π (y )−Θˆ⊤x x⊤βˆu)|+| (Θˆ⊤x′ Π (y′ )−Θˆ⊤x′ x′⊤βˆu)|
n k ij R ij k ij ij n k ij R ij k ij ij
0 0
2 √ 2
≤ sc c R+ sc c c2
n 1 x n 0 1 x
0
√
Denote ∆ = sc c R+sc c c2. Thus, if E follows N(0,8∆2/n2ϵ2log(1.25/δ)), βˆ is
1 1 x 0 1 x k 1 0 j
(ϵ,δ)-DP. For the term Θˆ⊤ΣˆΘˆ , we could obtain that:
k k
n n
1 (cid:88) 1 (cid:88)
Θˆ⊤ΣˆΘˆ = Θˆ⊤x x⊤Θˆ = (Θˆ⊤x )2
k k n k ij ij k n k ij
0 0
i=1 i=1
Thus, for two adjacent data sets X and X′ differ by one data x and x′ , we have:
ij ij
1 1
|Θˆ⊤ΣˆΘˆ −Θˆ⊤Σˆ′Θˆ | ≤ (Θˆ⊤x )2+ (Θˆ⊤x′ )2
k k k k n k ij n k ij
0 0
√
By Holder inequality and Cauchy inequality, we have |Θˆ⊤x | ≤ sc c , thus we have:
k ij 1 x
2 √ 2
|Θˆ⊤ΣˆΘˆ −Θˆ⊤Σˆ′Θˆ | ≤ ( sc c )2 = sc2c2
k k k k n 1 x n 1 x
0 0
Denote∆ = sc2c2. Then,letE′followsaGaussiandistributionofN(0,8∆2/n2m2ϵ2log(1.25/δ)).
2 1 x 2
We could claim that Θˆ⊤ΣˆΘˆ +E′ is (ϵ,δ)-differentially private.
k k
We start the second part of the proof. First, with probability 1−k exp(−k n ), we have
0 1 0
Π (y ) = y foreachi = 1,2,...,d, sowecoulddecomposeβˆ bythefollowingapproach:
R i i k
1
βˆ = βˆu+ Θˆ⊤X⊤(Xβ+W −Xβˆu)+E
k k n k k
0
1 1
= βˆu+ Θˆ⊤X⊤X(β−βˆu)+ Θˆ⊤X⊤W +E
k n k n k k
0 0
1
= β +(Θˆ⊤Σˆ −e )(β−βˆu)+ Θˆ⊤X⊤W +E
k k k n k k
0
39Thus, we have:
√ √ 1 √
n (βˆ −β ) = n (Θˆ⊤Σˆ −e⊤)(β−βˆu)+ √ Θˆ⊤X⊤W + n E (A.8)
0 j j 0 k k n k 0 k
(cid:124) (cid:123)(cid:122) (cid:125) 0 (cid:124) (cid:123)(cid:122) (cid:125)
A.8.1 (cid:124) (cid:123)(cid:122) (cid:125) A.8.3
A.8.2
We will analyze the three terms in (A.8) one by one. For the first term, we could further
decompose this term as:
√ √
n (Θˆ⊤Σˆ −e⊤)(β−βˆu) = n (Θˆ⊤Σˆ −Θ⊤Σˆ +Θ⊤Σˆ −e⊤)(β−βˆu)
0 k k 0 k k k k
√ √
= n (Θˆ⊤Σˆ −Θ⊤Σˆ)(β−βˆu)+ n (Θ⊤Σˆ −e⊤)(β−βˆu)
0 k k 0 k k
(A.9)
Forthefirsttermin(A.9),wecouldfurtherdecomposethistermfromΣˆ = 1 (cid:80)m (cid:80)n x x⊤:
mn i=1 j=1 ij ij
√ √
n (Θˆ⊤Σˆ −Θ⊤Σˆ)(β−βˆu) = n (Θˆ⊤−Θ⊤)Σˆ(β−βˆu)
0 k k 0 k k
√
≤ n λ (Σˆ)∥Θˆ −Θ ∥ |β−βˆu∥ (A.10)
0 s k k 2 2
In the last inequality, we use λ to denote the largest s-restricted eigenvalue of the
s
covariance matrix Σˆ. From Theorem 3, we could obtain that there exists a constant c
such that:
(cid:18) s∗logd (s∗logd)2log(1/δ)log3n (cid:19)
∥β−βˆu∥2 ≤ c·σ2 + 0
2 n n2ε2
0 0
Also, for the output Θˆ , we could have the similar result:
k
(cid:18) s∗logd (s∗logd)2log(1/δ)log3n (cid:19)
∥Θˆ −Θ ∥2 ≤ c·σ2 + 0
k k 2 n n2ε2
0 0
Combining (A.4) and (A.4), we could obtain that
√
(cid:18) s∗logd(cid:19)
n (Θˆ⊤Σˆ −Θ⊤Σˆ)(β−βˆu) = o √ = o(1)
0 k k n
0
Then, we could focus on the second term of (A.9). We first introduce the following
lemma:
Lemma A.3 (Lemma 6.2 in [24]) For the vector Θ⊤Σˆ −e . Denote κ = ∥Σ−1/2X ∥ ,
k k 1 ϕ2
then with probability 1−2d1−a2/24e2κ4L2, we have:
(cid:114)
logd
∥Θ⊤Σˆ −e ∥ ≤ a
k k ∞ n
0
Thus, for the second term of (A.9), we have:
√ √
n (Θ⊤Σˆ −e⊤)(β−βˆu) ≤ n ∥Θ⊤Σˆ −e⊤∥ ∥β−βˆu∥
0 k j 0 k k ∞ 1
40√ (cid:114) logd√
≤ k n s∗∥β−βˆu∥
0 2
n
0
(cid:114)
(cid:112) s∗logd
≤ k· s∗logd· = o(1) (A.11)
n
0
Combine the result from (A.4), (A.11) to (A.9), we could obtain that the first term of
√
(A.8)iso(1). Wecouldalsoanalyzethethirdtermof(A.8), n E ∼ N(0,8∆2log(1.25/δ)/n ϵ2).
0 k 1 0
Then, by the definition of ∆ , we have 8∆2log(1.25/δ)/n ϵ2 ∼ s∗2log2dlog(1.25/δ) = o(1)
1 1 0 n0ϵ2
from the assumption. Also, we notice that E′ = N(0,c · s∗2log2dlog(1.25/δ) ). By the
n2ϵ2
0
concentration of Gaussian distribution, we also have that E′ = o(1).
Finally, we analyze the term √1 Θˆ⊤X⊤W. From our definition, W is sub-Gaussian
n0 j
random noise. Then, from the central limit theorem, we could conclude that:
1
√ Θˆ⊤X⊤W → N(0,σ2Θˆ⊤ΣˆΘˆ )
n j j j
0
√ √
Thus, n 0(βˆ j−β j) = √1 n0Θˆ⊤
j
X⊤W + n 0E
k
∼ N(0,σ2Θˆ⊤
j
ΣˆΘˆ j+o(1)). Also, from
lemma 4.1, we could claim that under our assumptions, σˆ2 = σ2 +o(1). We could get
√
the result where with high probability, √n0(βˆ j−βj) → N(0,1).
σˆ wˆj⊤Σˆwˆj
(cid:113)
Therefore, we could claim that [βˆ
j
− Φ−1(1 − α/2)√σˆ
n0
Θˆ⊤
j
ΣˆΘˆ j,βˆ
j
+ Φ−1(1 −
(cid:113)
α/2)√σˆ
n0
Θˆ⊤
j
ΣˆΘˆ j] is asymptotically 1 − α confidence interval for β j. Therefore, we
have finished the proof of theorem. □
A.5 Proof of Theorem 5
The proof is similar to the proof of Theorem 4, the difference is that we need to consider
the case where the privacy cost is not dominated by the statistical error. Then, for the
proof of Theorem 5, we follow the proof of Theorem 4 until (A.8). The analysis for the
second term and the third term for (A.8) stays the same. On the other hand, for the
first term of (A.8), we have: We will analyze the three terms in (A.8) one by one. For
the first term, in the same manner, we could decompose this term as:
√ √
n (Θˆ⊤Σˆ −e⊤)(β−βˆu) = n (Θˆ⊤Σˆ −Θ⊤Σˆ +Θ⊤Σˆ −e⊤)(β−βˆu)
0 k k 0 k k k k
√ √
= n (Θˆ⊤Σˆ −Θ⊤Σˆ)(β−βˆu)+ n(Θ⊤Σˆ −e⊤)(β−βˆu)
0 k k k k
(A.12)
Forthefirsttermin(A.12),wecouldfurtherdecomposethistermfromΣˆ = 1 (cid:80)n x x⊤:
n i=1 i i
√ √
n (Θˆ⊤Σˆ −Θ⊤Σˆ)(β−βˆu) = n (Θˆ⊤−Θ⊤)Σˆ(β−βˆu)
0 k k 0 k k
√
≤ n λ (Σˆ)∥Θˆ −Θ ∥ |β−βˆu∥
0 s k k 2 2
kµ2
≤ ss2log2dlog(1/δ)log3n /n3/2 ϵ2 (A.13)
ν2 0 0
s
41Thus, for the second term of (A.12), by Lemma A.3, we have:
√ √
n (Θ⊤Σˆ −e⊤)(β−βˆu) ≤ n ∥Θ⊤Σˆ −e⊤∥ ∥β−βˆu∥
0 k k 0 k k ∞ 1
√ (cid:114) logd√
≤ k n s∗∥β−βˆu∥
0 2
n
0
≤ k·(cid:112) s∗logd·∥β−βˆu∥ (A.14)
2
√
When the privacy cost is not dominated by the statistical error and also s∗logd/ n =
o(1), we can observe that the equation (A.14) has smaller convergence rate that (A.13).
Then, combining (A.13) and (A.14), there exists a constant k , such that:
1
√ γµ2s2log2dlog(1/δ)log3n
n(Θˆ⊤Σˆ −e⊤)(β−βˆu) ≤ s 0
k j ν s2 n3/2 ϵ2
0
Then, insert the result into (A.8), we have:
(cid:32) (cid:33)
√ µ2s2log2dlog(1/δ)log3n 1 √
n (βˆ −β ) = O − s 0 + √ Θˆ⊤X⊤W + n E (A.15)
0 j j ν s2 n3/2 ϵ2 n 0 k 0 k
0
Notice that for the first term on the right hand, the constant could be set to 1 because
it comes from the tail bound of Laplace random variable. From the result in (A.15), we
could also apply the central limit theorem to show that the second term is asymptoti-
cally Gaussian, notice that in the right hand side, the second term and the third term
asymptotically follows a distribution of N(0,σ2Θˆ⊤ΣˆΘˆ +8∆2 1log(1/δ) ). Also, by the con-
k k n0ϵ2
centrationofGaussiandistribution,wehavewithhighprobability,E′ ≤ 8∆2 1log(1/δ).Thus,
the privacy conditions are satisfied. Therefore, we have:
n0ϵ2
(cid:115)
√ √ 8∆2log(1/δ)
n [βˆ −β − n (Θ⊤Σˆ −e⊤)(β−βˆu)]/ σ2Θˆ⊤ΣˆΘˆ + 1 ∼ N(0,1)
0 j j 0 k k k k n ϵ2
0
Then, also by our assumptions and the result in Lemma 4.1, we could claim that σ2 =
sigˆma2 +o(1). Thus, finally, the confidence interval is given by:
(cid:115)
(cid:20) γµˆ2s2log2dlog(1/δ)log3n σ 8∆2log(1/δ)
J (α) = βˆ − s 0 )−Φ−1(1−α/2)√ Θˆ⊤ΣˆΘˆ + 1 ,
j j νˆ2 n2ϵ2 n k k n ϵ2
s 0 0 0
(cid:115)
γµˆ2s2log2dlog(1/δ)log3n σ 8∆2log(1/δ)(cid:21)
βˆ + s 0 )+Φ−1(1−α/2)√ Θˆ⊤ΣˆΘˆ + 1
j νˆ2 n2ϵ2 n k k n ϵ2
s 0 0 0
which finishes our proof.
42A.6 Proof of Theorem 6
Let us first show that our algorithm is ϵ,δ private. The major proof lies in the choice of
noise level B . To decompose, we can find:
3
1 (cid:88)m √ 1 (cid:88)m √ √ n(cid:32) (cid:88)m (cid:33)
Θˆ √ e n(g −g¯) = Θˆ √ e ng −Θˆ √ e g¯
i i i i i
m m m
i=1 i=1 i=1
Then, suppose in an adjacent data set, the different data in denoted as (x ,y ) and
ij ij
(x′ ,y′ ). Then, we calculate:
ij ij
(cid:13) (cid:13) 1 (cid:88)m √ √ n(cid:32) (cid:88)m (cid:33) 1 (cid:88)m √ √ n(cid:32) (cid:88)m (cid:33) (cid:13) (cid:13)
(cid:13)(Θˆ √ e ng −Θˆ √ e g¯)−(Θˆ √ e ng′ −Θˆ √ e g¯′)(cid:13)
(cid:13) m i i m i m i i m i (cid:13)
(cid:13) (cid:13)
i=1 i=1 i=1 i=1 ∞
(cid:13) √ √ (cid:32) m (cid:33) (cid:13)
(cid:13) n n (cid:88) (cid:13)
≤ (cid:13)Θˆ √ e (g −g′)−Θˆ √ e (g¯−g¯′)(cid:13)
(cid:13) m i i i m i (cid:13)
(cid:13) (cid:13)
i=1 ∞
(cid:13)√ √ (cid:32) m (cid:33) (cid:13)
(cid:13) (cid:13) (cid:13) n n (cid:88) (cid:13)
≤ (cid:13)Θˆ(cid:13) (cid:13)√ e (g −g′)− √ e (g¯−g¯′)(cid:13)
(cid:13) (cid:13) max(cid:13)
(cid:13)
m i i i m i (cid:13)
(cid:13)
i=1 ∞
(cid:13)√ √ (cid:32) m (cid:33) (cid:13)
(cid:13) (cid:13) (cid:13) n n (cid:88) (cid:13)
≤ ((cid:13)Θˆ −Θ(cid:13) +∥Θ∥ )(cid:13)√ e (g −g′)− √ e (g¯−g¯′)(cid:13)
(cid:13) (cid:13) max max (cid:13) (cid:13) m i i i m i (cid:13) (cid:13)
i=1 ∞
(cid:13)√ (cid:13) (cid:13)√ (cid:32) m (cid:33) (cid:13)
≤ ((cid:13) (cid:13) (cid:13)Θˆ −Θ(cid:13) (cid:13) (cid:13)
1
√+∥Θ∥ 2)(cid:13) (cid:13) (cid:13)√ mn e i(g i−g i′)(cid:13) (cid:13)
(cid:13) ∞
√+(cid:13) (cid:13) (cid:13) (cid:13)√ mn (cid:88) i=1e i (g¯−g¯′)(cid:13) (cid:13) (cid:13)
(cid:13)
∞)
≤ (o(1)+L)√
mn(cid:112) logm(cid:13)
(cid:13)(g i−g
i′)(cid:13)
(cid:13) ∞+ √
mn m(cid:112) logm(cid:13) (cid:13)g¯−g¯′(cid:13)
(cid:13) ∞)
√
4 logm(cid:13) (cid:13)
≤ L √ (cid:13)x (π (y )−x βˆ)(cid:13)
mn (cid:13) ij R ij ij (cid:13) ∞
√
4 logm √
≤ L √ c (R+c c s∗)
x 0 x
mn
Thus, the privacy could be guaranteed. Then, let us start the proof of consistency.
Throughout the proof, we define n = m · n, (X,Y) be the whole data set where
0 √
X ∈ Rn0∗d and Y ∈ Rd. U′ = max k∈GΘˆ √1
m
(cid:80)m i=1e
i
n(g
i
−g¯). Let us define another
multiplier bootstrap statistic:
m n
1 (cid:88)(cid:88)
U∗ = max Σ−1x (y −x β)e ,
ij ij ij ij
k∈G mn
i=1 j=1
where e are all standard Gaussian variables. At the same time, we also define:
ij
m n
1 (cid:88)(cid:88)
M = max Σ−1x (y −x β)
0 ij ij ij
k∈G mn
i=1 j=1
43Theproofconsiststhreemajorsteps,westartfromthefirststepandmeasuresup |P(M ≤
α∈(0,1) 0
C (α))−α|. This measurement is quite straightforward, we could apply Theorem 3.1
U∗
from [10]. However, we need to verify Corollary 2.1 from [10]. Notice that for any
k, E[ΘTx (y − x β)]2 = σ2ΘTΣΘ ≥ σ2/L. Also, it is not difficult to verify that
k ij ij ij k k
ΘTx (y −x β) is sub-exponential. Since from assumption D1, we have x is sub-
k ij ij ij ij
Gaussian and from the linear model, we know that (y −x β) is also, sub-Gaussian.
ij ij
Then, the condition could be verified. Thus, by applying Theorem 3.1 and also under
the condition where there exists a constant k,k ,k such that log7(dmn)/mn ≤ 1 we
0 1 (mn)k
could have:
1
sup |P(T ≤ C (α))−α| ≤ k · +k v1/3(max(1,log(d/v)))2/3+P(∆ > v)
α∈(0,1)
0 U∗ 0 (mn)k1 2
≤ k v1/3(max(1,log(d/v)))2/3+P(□ > v)+o(1), (A.16)
2
where □ represents the maximum element between the two matrix Ω and Ω , denote as
1 2
∥Ω −Ω ∥ , where Ω and Ω are defined as:
1 2 max 1 2
m n
1 (cid:88)(cid:88)
[Ω ] = Θ⊤x (y −xTβ)Θ
1 k,l mn k ij ij ij l
i=1 j=1
and
Ω = σ2Θ
2
Then, from Corollary 3.1 in [10] and Lemma E.2 in [41], we could verify that ∥Ω −
1
(cid:113)
Ω ∥ = O( logd+log2(dn0)logd ). Withaproperchoiceofv,e.g,thereexistsaconstant
2 max n0 n0
(cid:113)
κ and let v = ( logd + log2(dn0)logd )1−κ, we have k v1/3(max(1,log(d/v)))2/3 +P(□ >
n0 n0 2
v) = o(1). Next, we would like to associate M with M . Similarly, from Theorem 3.2 in
0
[10] and (A.16), we could have:
(cid:112)
sup |P(M ≤ C (α))−α| ≤ o(1)+v max(1,log(d/v ))+P(∥M −M ∥ > v ),
U∗ 1 1 0 1
α∈(0,1)
From the definition of M and M , we have:
0
√ n (M −M ) = max √1 |(Θˆ ⊤ −Θ⊤)X⊤W|
0 0 1≤k≤d n 0 k k
Then, for any k in 1,...,d, by Holder inequality and Cauchy–Schwarz inequality, we
have:
1 1 √ 1
√ |(wˆ ⊤−w⊤)X⊤W| ≤ ∥wˆ ⊤−w⊤∥ ∥√ X⊤W∥ ≤ s∗∥wˆ ⊤−w⊤∥ ∥√ X⊤W∥
n k k k k 1 n ∞ k k 2 n ∞
0 0 0
(cid:113)
On one hand, from previous proof, we obtain that ∥wˆ ⊤−w⊤∥ = c· s∗logd when the
k k 2 mn
privacy cost is dominated by statistical error uniformly for k. On the other hand, by the
44fact that Σ have bounded maximum eigenvalue and traditional linear regression model,
(cid:113)
we could apply Bernstein inequality and also obtain that ∥√1 n0X⊤W∥
∞
is O( lo ng 0d).
Combine these two results, we could claim that there exist constants k such that:
0
√1 |(Θˆ ⊤ −Θ⊤)X⊤W| = k ·(s∗logd/√ n )
n k k 0 0
0
uniformlyforallk,thenwecanchoosev properlysuchthatsup |P(M ≤ C (α))−
1 α∈(0,1) U∗
α| = o(1). At last, we need to relate U∗ with U. Our major goal is to prove that C (α)
U
and C are close to each other for any α ∈ (0,1). We first associate U with U′. From
U∗
the design of private max algorithm, from Lemma 3.4 in [8], suppose l is the element
1
chosen from U′ and l is from U without noise injection, we use w to represent the noise
2
injected when we pick the largest value privately, we find that, for any c > 0:
l2 ≤ l2 ≤ (1+c)l2+4(1+1/c)∥w∥2
2 1 2 ∞
From Lemma A.1 in [8], we can verify that there exists constant k ,k such that ∥w∥2 ≤
0 1 ∞
k · s∗log4dlogm. When we choose c = o(1), e.g, c = k s∗logd, then from the conditions,
w0 e couldn c0laim that l = l +o(1), also notice that the1 scan l0e of noise we injected is small,
1 2
it is easy to verify that U = U′+o(1). The following discussions will be between U′ and
U∗. Denote ⊖ as the symmetric difference, then we have:
P(T ≤ C (α)⊖T ≤ C (α))
U U∗
≤ 2P(C (α−π(u)) < T ≤ C (α+π(u)))+P(C (α−π(u)) > C (α))+P(C (α+π(u)) < C (α))
U∗ U∗ U∗ U U∗ U
(A.17)
For the first term in (A.17), define π(u) = u1/3max(1,log(d/u))2/3, then exist a constant
k , such that:
0
P(C (α−π(u)) < M ≤ C (α+π(u))) ≤ P(M ≤ C (α+π(u)))−P(M ≤ C (α−π(u))) ≤ k·π(u)+o(1)
U∗ U∗ U∗ U∗
Then, for the second term and third term in (A.17), from Lemma 3.2 in [10], we have:
P(C (α−π(u)) > C (α))+P(C (α+π(u)) < C (α)) ≤ 2P(∥Ω −Ω ∥ > u),
U∗ U U∗ U 1 3 max
where Ω is defined as:
3
m
1 (cid:88)
[Ω ] = nΘˆ (g −g¯)(g −g¯)⊤Θˆ ,
3 k,l k i i l
m
i=1
and Ω is defined the same as we defined before. Then, our major focus is to analyze
1
∥Ω −Ω ∥ , by triangle inequality, we have ∥Ω −Ω ∥ ≤ ∥Ω −Ω ∥ +∥Ω −
1 3 max 1 3 max 1 2 max 3
Ω ∥ . Since we have analyzed ∥Ω −Ω ∥ before, we will focus on ∥Ω −Ω ∥ .
2 max 1 2 max 3 2 max
(cid:13) (cid:13)
m
(cid:13) 1 (cid:88) (cid:13)
∥Ω −Ω ∥ ≤ (cid:13) nΘˆ(g −g¯)(g −g¯)⊤Θˆ −σ2ΘˆΣΘˆ(cid:13) +∥σ2ΘˆΣΘˆ −σ2Θ∥
3 2 max (cid:13)m i i (cid:13) max
(cid:13) (cid:13)
i=1 max
(A.18)
45We will analyze the two terms separately. We start from the second term in (A.18), we
have:
∥ΘˆΣΘˆ −Θ∥
max
≤ ∥(Θˆ −Θ+Θ)Σ(Θˆ −Θ+Θ)−Θ∥
max
≤ ∥Θˆ −Θ∥2∥Σ∥ +2∥Θˆ −Θ∥
1 max 1
s∗2logd (cid:114) logd
≤ k +k s∗
0 1
n n
0 0
On the other hand, for the first term in (A.18),notice that:
m m
1 (cid:88) 1 (cid:88)
nΘˆ(g −g¯)(g −g¯)⊤Θˆ = nΘˆg g⊤Θˆ −nΘˆg¯g¯⊤Θˆ⊤ (A.19)
m i i m i i
i=1 i=1
Denote the data set on the i-th local machine as (X ,Y ) and in the linear model, the
i i
random noise as W . Also, we can further decompose the first term by:
i
m
1 (cid:88)
ng g⊤
m i i
i=1
=
1 (cid:88)m n[X i⊤W i+X i⊤(β−βˆ) ][X i⊤W i+X i⊤(β−βˆ)
]⊤
m n n
i=1
=
1 (cid:88)m n[X i⊤W
i
][X i⊤W
i ]⊤+
1 (cid:88)m n[X i⊤(β−βˆ) ][X i⊤(β−βˆ)
]⊤+
2 (cid:88)m n[X i⊤(β−βˆ) ][X i⊤W
i ]⊤
m n n m n n m n n
i=1 i=1 i=1
(A.20)
Then, for the equation (A.19), we have:
m
1 (cid:88)
∥ nΘˆ(g −g¯)(g −g¯)⊤Θˆ −σ2ΘˆΣΘˆ∥
i i max
m
i=1
m
1 (cid:88)
≤ ∥Θˆ∥ ∥ n(g −g¯)(g −g¯)⊤Θˆ −σ2ΣΘˆ∥
max i i max
m
i=1
m
1 (cid:88)
≤ ∥Θˆ∥2 ∥ n(g −g¯)(g −g¯)⊤−σ2Σ∥ (A.21)
max m i i max
i=1
And, we could insert (A.20) into (A.21),
m
1 (cid:88)
∥ n(g −g¯)(g −g¯)⊤−σ2Σ∥
i i max
m
i=1
≤ ∥
1 (cid:88)m n[X i⊤W
i
][X i⊤W
i ]⊤−σ2Σ∥ +n∥g¯g¯⊤∥ +∥
1 (cid:88)m n[X i⊤(β−βˆ) ][X i⊤(β−βˆ)
]⊤∥
max max max
m n n m n n
i=1 i=1
46+∥
2 (cid:88)m n[X i⊤(β−βˆ) ][X i⊤W
i ]⊤∥ (A.22)
max
m n n
i=1
We will analyze the four terms in (A.22) one by one. For the first term, it is quite simple,
(cid:113)
from the proof of Lemma F.2 in [41], we have the first term is O ( logd + log2(dm)logd ).
p m m
For the second term, we have:
1
n∥g¯g¯⊤∥ ≤ n∥g¯∥2 = n∥ X⊤(Y −Xβˆ)∥2
max ∞ n ∞
0
Also, we have:
1
∥ X⊤(Y −Xβˆ)∥
∞
n
0
1 1
≤ ∥ X⊤(Y −Xβ)∥ +∥ X⊤X(βˆ−β)∥
∞ ∞
n n
0 0
1
≤ ∥ X⊤W∥ +∥(Σˆ −Σ)(βˆ−β)∥ +∥Σ∥ ∥βˆ−β∥
∞ ∞ max 1
n
0
(cid:114) (cid:114)
logd logd
≤ k ( )+k ( )∥βˆ−β∥ +∥βˆ−β∥
0 1 1 1
n n
0 0
(cid:114) (cid:114)
logd s∗logd logd
≤ k +k +k s∗ (A.23)
0 1 2
n n n
0 0 0
Thus,forthesecondterm,wecanobtainthatn∥g¯g¯⊤∥ ≤ k s∗2logd/m+k s∗2log2d/m2n.
max 0 1
For the third term, we have:
∥
1 (cid:88)m n[X i⊤X i(β−βˆ) ][X i⊤X i(β−βˆ)
]⊤∥
max
m n n
i=1
≤
1 (cid:88)m n∥[X i⊤X i(β−βˆ) ][X i⊤X i(β−βˆ)
]⊤∥
max
m n n
i=1
≤
1 (cid:88)m n∥[X i⊤X i(β−βˆ)
]∥2
m n ∞
i=1
m
1 (cid:88)
≤ n(∥Σˆ −Σ∥ +∥Σ∥ )2∥β−βˆ∥2
m i max max 1
i=1
m
1 (cid:88)
≤ 2n(∥Σˆ −Σ∥2 +∥Σ∥2 )∥β−βˆ∥2
m i max max 1
i=1
m (cid:114)
1 (cid:88) logd
≤ 2n(O( )+O(1))∥β−βˆ∥2
m n 1
i=1
logd
≤ k s∗2 (A.24)
0
m
47For the fourth term, we could apply Cauchy-Schwarz inequality, which give us the result:
∥
2 (cid:88)m n[X i⊤X i(β−βˆ) ][X i⊤W
i ]⊤∥
max
m n n
i=1
≤
2 (cid:88)m n∥[X i⊤X i(β−βˆ) ][X i⊤W
i ]⊤∥
max
m n n
i=1
≤
2 (cid:88)m n∥X i⊤X i(β−βˆ)
∥
∥X i⊤W
i
∥
∞ max
m n n
i=1
≤
2 (cid:88)m n∥X i⊤X
i ∥ ∥β−βˆ∥
∥X i⊤W
i ∥
max 1 ∞
m n n
i=1
s∗logd
≤ k n·
0
n
0
s∗logd
≤ k (A.25)
0
m
We could combine the result in (A.23), (A.24), (A.25) and insert into (A.22) and into
(cid:113)
(A.21). We could finally get the first term of (A.18) has an order of O( logd + s∗logd +
n0 n0
s∗2logd). Insert this result into (A.17), when u is chosen properly, we could verify that
m
sup |P(T ≤ C (α))−α| = o(1), which finishes the proof.
α∈(0,1) U
A.7 Proof of Theorem 7
The proof of theorem 7 is quite straight forward. We could decompose true β = u+v .
i i
Then, βˆ = uˆ +vˆ. Thus, from the result of estimation, we could get the result that:
i
s logd s 2logd2log(1/δ)log3mn
∥u−uˆ∥2 ≤ c 0 +c 0 ,
2 0 mn 2 m2n2ϵ2
and
s logd s 2logd2log(1/δ)log3n
∥vˆ −v ∥2 ≤ c 1 +c 1
i i 2 1 n 3 n2ϵ2
Also, combing the above two results with the inequality that ∥βˆ −β ∥ ≤ ∥vˆ −v ∥ +
i i 2 i i 2
∥u−uˆ∥ gives the proof of theorem 7. □
2
A.8 Proof of Theorem 8
The proof of Theorem 8 follows the proof of and Theorem 4 and Theorem 5. We follow
the proof of Theorem 4 until (A.8). The analysis for the second term and the third term
for (A.8) stays the same. We will analyze the three terms in (A.8) one by one. For the
first term, in the same manner, we could decompose this term as:
√ √
n(Θˆ⊤Σˆ −e⊤)(β−βˆu) = n(Θˆ⊤Σˆ −Θ⊤Σˆ +Θ⊤Σˆ −e⊤)(β−βˆu)
j j j j j j
48√ √
= n(Θˆ⊤Σˆ −Θ⊤Σˆ)(β−βˆu)+ n(Θ⊤Σˆ −e⊤)(β−βˆu)
j j j j
(A.26)
Forthefirsttermin(A.26),wecouldfurtherdecomposethistermfromΣˆ = 1 (cid:80)n x x⊤:
n i=1 i i
√ √
n(Θˆ⊤Σˆ −Θ⊤Σˆ)(β−βˆu) = n(Θˆ⊤−Θ⊤)Σˆ(β−βˆu)
j j j j
√
≤ nλ (Σˆ)∥Θˆ −Θ ∥ |β−βˆu∥
s j j 2 2
γµ2s2log2dlog(1/δ)log3mn γµ2s2log2dlog(1/δ)log3n
≤ o(1)+ s 1 + s 0
ν2 m2n3/2ϵ2 ν2 n3/2ϵ2
s s
(A.27)
Thus, for the second term of (A.26), by Lemma A.3, we have:
√ √
n(Θ⊤Σˆ −e⊤)(β−βˆu) ≤ n∥Θ⊤Σˆ −e⊤∥ ∥β−βˆu∥
j j j j ∞ 1
(cid:114)
√ logd√
≤ k n s∥β−βˆu∥
2
mn
(cid:114)
√ slogd
≤ k· n ·∥β−βˆu∥
2
mn
γµ2s2log2dlog(1/δ)log3mn γµ2s2log2dlog(1/δ)log3n
≤ o(1)+ s 1 + s 0
ν2 m2n3/2ϵ2 ν2 n3/2ϵ2
s s
(A.28)
Then, combining (A.27) and (A.28), we have that:
√ 2γµ2s2log2dlog(1/δ)log3mn 2γµ2s2log2dlog(1/δ)log3n
n(Θˆ⊤Σˆ −e⊤)(β−βˆu) ≤ s 1 + s 0
j j ν2 m2n3/2ϵ2 ν2 n3/2ϵ2
s s
Then, insert the result into (A.8), we have:
√ (cid:18) 2γµ2s2log2dlog(1/δ)log3mn 2γµ2s2log2dlog(1/δ)log3n(cid:19) 1 √
n βˆ −β − s 1 − s 0 = √ Θˆ⊤X⊤W + nE
j j ν2 m2n2ϵ2 ν2 n2ϵ2 n j 3
s s
(A.29)
From the result in (A.29), notice that the right hand side asymptotically follows a dis-
tribution of N(0,σ2Θˆ⊤ΣˆΘˆ + 8∆2 1log(1/δ) ). Also, by the concentration of Gaussian dis-
j j nϵ2
tribution, we have with high probability, E ≤ 8∆2 1log(1/δ) ). Thus, we have:
2 nϵ2
√ (cid:18) 2γµ2s2log2dlog(1/δ) 2γµ2s2log2dlog(1/δ)(cid:19) (cid:114) 8∆2log(1/δ)
n βˆ −β − s 1 − s 0 / σ2Θˆ⊤ΣˆΘˆ + 1 ∼ N(0,1)
j j ν2 m2n2ϵ2 ν2 n2ϵ2 j j nϵ2
s s
Then, we could replace µ ,ν with the estimation µˆ ,νˆ introduced in Algorithm 5, the
s s s s
constantcouldbescaledtoonegiventhetailboundofLaplacerandomvariable. Also,for
the estimation of σ, according to the assumption, we have σˆ = σ+o(1). For simplicity,
49we denote a = 2kµˆ2 s s2 1log2dlog(1/δ)log3mn +2kµˆ2 s s2 0log2dlog(1/δ)log3n, the confidence is given
νˆ2 m2n2ϵ2 νˆ2 n2ϵ2
by: s s
J (α) =
j
(cid:114) (cid:114)
σΦ−1(1−α/2) 8∆2log(1/δ) σΦ−1(1−α/2) 8∆2log(1/δ)
[βˆ −a− √ Θˆ⊤ΣˆΘˆ + 1 ,βˆ +a+ √ Θˆ⊤ΣˆΘˆ + 1 ]
j n j j nϵ2 j n j j nϵ2
A.9 Proof of Theorem 9
In this proof, we first need to show that our algorithm is (ϵ,δ) private. We assume in two
data sets, the adjacent data set is different in (x ,y ) and (x′ ,y′ ). Then, we have:
ij ij ij ij
1 1 2
∥√ Θˆx e − √ Θˆx′ e ∥ ≤ √ ∥Θˆx e ∥
n ij j n ij j ∞ n ij j ∞
2
≤ √ ∥Θˆx ∥ ∥e ∥
ij ∞ j ∞
n
√
2 logn
≤ √ ∥Θˆ∥ ∥x ∥
1 ij ∞
n
(cid:114)
logn √
≤ 2 c sc
x 1
n
According to the choice of B , the privacy could be guaranteed. Then, let us start the
5
proof of consistency. In this proof specifically, we define U′ = max k∈GΘˆT
k
√1
n
(cid:80)n i=1x ije
j
and also, we define:
n
1 (cid:88)
M = max √ ξ ,
0 jk
k∈G n
j=1
whereξ followsaGaussianDistributionN(0,Θ⊤ΣΘ σ2). Also, wedefinetheα-quantile
j k k
of M as U (α). Then, we could start the proof.
0 M0
We are aiming at proving sup |P(M ≤ C (α)) − α| = o(1). First, we could
α∈(0,1) U
prove that C (α) and C are close to each other for any α ∈ (0,1). From the design of
U U′
private max algorithm, from Lemma 3.4 in [8], suppose l is the element chosen from U′
1
and l is from U without noise injection, we use w to represent the noise injected when
2
we pick the largest value privately, we find that, for any c > 0:
l2 ≤ l2 ≤ (1+c)l2+4(1+1/c)∥w∥2
2 1 2 ∞
From Lemma A.1 in [8], we can verify that there exists constant k ,k such that ∥w∥2 ≤
0 1 ∞
k · s∗log4dlogn. When we choose c = o(1), e.g, c = k s∗logd, then from the conditions,
0 n 1 n
we could claim that l = l +o(1), also notice that the scale of noise we injected is small,
1 2
it is easy to verify that U = U′+o(1). The following discussions will be between U′ and
U .
T0
Motivated by the proof of Theorem 3.1 and Theorem 3.2 in [10], our proof will be
divided into two major parts, to measure the closeness between U′ and U and measure
M0
50the closeness between T and T . We start from the measurement between M and M .
0 √ 0
From the definition that M(βˆ(i)) = max n(βˆ(i) −β(i) ), we notice that for each k in
k∈G k k
1,2,...,d, we have:
√ 1 √
n(βˆ(i)−β(i)) = √ ΘˆX⊤W +(ΘˆΣ−I)(βˆ−β)+ nE
n i i
Then,
1 1 (cid:88)n √
|M −M | ≤ (∥√ ΘˆX⊤W ∥ −∥√ ξ ∥ )+∥(ΘˆΣ−I)(βˆ−β)+ nE∥
0 n i i ∞ n j ∞ ∞
j=1
(A.30)
We analyze the two parts in (A.30) separately. For the first term in (A.30). First, from
Lemma 1.1 in [42], we could obtain the result that for any z, sup z|P(∥√1 nΘX i⊤W i∥
∞
≤
z)−P(M ≤ z)| ≤ c · 1 , where c and c are constants. Also,
0 0 nc1 0 1
1 1 1
∥√ ΘˆX⊤W ∥ −∥√ ΘX⊤W ∥ ≤ √ ∥ΘˆX⊤W −ΘX⊤W ∥
n i i ∞ n i i ∞ n i i i i ∞
1
≤ ∥Θˆ −Θ∥ ·∥√ X⊤W ∥
1 n i i ∞
(cid:114) (cid:114)
logd(cid:112) 1
≤ c·s∗ logd ≤ c·s∗logd = o(1)
n n
On the other hand, we also notice that for the second term in (A.30), following the proof
in Theorem 4, we also know that the second part is o(1), hence finishes the first part of
the proof. In the second part of the proof. By the arguments in the proof of Theorem
3.2 in [10], we have for any v:
1
sup |P(T ≤ C (α))−α| ≤ c +c v1/3(1∨log(d/v))2/3+P(□ > v),
α∈(0,1)
U′ 0 nc1 2
where □ = max Θˆ⊤ΣˆΘˆ −Θ⊤ΣΘ .Then, we have:
k,l k l k l
∥Θˆ⊤ΣˆΘˆ −Θ⊤ΣΘ∥
max
≤ ∥Θˆ⊤ΣˆΘˆ −Θˆ⊤ΣΘˆ∥ +∥ΘˆΣΘˆ −Θ∥
max max
≤ ∥Θˆ∥ ∥Σˆ −Σ∥ ∥Θˆ∥ +∥(Θˆ −Θ+Θ)Σ(Θˆ −Θ+Θ)−Θ∥
∞ max 1 max
(cid:114)
logd
≤ L2 +∥Θˆ −Θ∥2∥Σ∥ +2∥Θˆ −Θ∥
n 1 max 1
0
s∗2logd (cid:114) logd
≤ k +k s∗ ,
0 1
n n
0 0
where k ,k are constants. Then, with a proper choice of v, we could claim that
0 1
sup |P(T ≤ C (α))−α| = o(1), which finishes the proof.
α∈(0,1) U′
51B Appendix
In this section, we will give proofs of the corollary in the main proof. We will introduce
them one by one:
B.1 Proof of corollary 1
FollowingtheproofofTheorem1in[2],wecangaintheupperboundof(cid:80)k d (pZm,pZm),
i=1 TV +i −i
when we consider the central DP:
k1(cid:32) (cid:88)k d TV(pZ +m i ,pZ −m i )(cid:33)2 ≤ 7(cid:88)m E A (cid:88)k (cid:90) (E p⊗ an[W(z E| X) [W]− (zE p |⊗ a X⊕n i )[ ]W(z | X))]2 dµ 
i=1 t=1 i=1
Z pa
Also notice that:
(cid:34) (cid:35)
dp⊗n
E [W(z | X))] = E a⊕iW(z | X)) = E (1+q ϕ (X))n·W(z | X)
p⊗ a⊕n
i
p⊗ an dp⊗ an pa a,i a,i
The last equation is from the definition of condition 1. Also, by the inequality that we
can find constants c , c that when x > 0 and x ≍ 1/n, (1 + x)n ≤ 1 + c · nx and
0 1 0
(1−x)n ≤ 1−c ·nx. If we have |q ϕ (X)| ≍ 1/n. we could find a constant c , such
0 a,i a,i 2
that:
k m (cid:34) k (cid:90) E [ϕ (X)W(z | X)]2 (cid:35)
1 ((cid:88) d (cid:0) pZm ,pZm(cid:1) )2 ≤ c q2n2(cid:88) E (cid:88) p⊗ An a,i dµ
k TV +i −i 2 A E [W(z | X)]
i=1 t=1 i=1
Z p⊗ An
which finishes the proof of corollary 1.
B.2 Proof of Corollary 2
We continue to show the proof of Corollary 2. First, from Theorem 2 in [2], we get a
direct result when condition 2 is satisfied, given all the conditions in corollary 2 hold, we
have:
(cid:32) 1 (cid:88)k
d
(pZm ,pZm
)(cid:33)2
≤
7 q2n2(cid:88)m max(cid:90) Var pa[W(z | X)]
dµ
k
i=1
TV +i −i k
t=1
a∈A Z E pa[W(z | X)]
Then, the focus of the proof of this corollary is on the calculation of (cid:82) Varpa[W(z|X)] dµ
Z E pa[W(z|X)]
when the channel W is a privacy constraint channel Wpriv. For simplicity, we denote
L(z,X) = logWpriv(z|X), where z ∈ Rd and X ∈ Rn×d. Then, notice that Wpriv is
ϵ-differentially private constraint, for two adjacent dataset X and X′, we have:
|L(z,X)−L(z,X′)| ≤ ϵ
52√
By McDiarmid’s inequality, we could claim that L is nϵ- subGaussian. So we could
find a constant c, which satisfies that:
E[e2L] ≤ c·e2E[L]·e2nϵ2
Then, by Jensen inequality, we have:
E[e2L] ≤ c·(eE[L])2·e2nϵ2
Thus, we have:
Var[Wpriv(z|X)] E[Wpriv(z|X)2] E[e2L]
= −1 = −1 ≤
e2nϵ2
−1
E[Wpriv(z|X)]2 (E[Wpriv(z|X)])2 (E[eL])2
Thus, we have:
(cid:32) 1 (cid:88)k
d (pZm ,pZm
)(cid:33)2 ≤7 α2n2(cid:88)m max(cid:90) Var pa[W(z | X)]
·E [W(z | X)]dµ
k
i=1
TV +i −i k
t=1
a∈A Z E pa[W(z | X)]2 pa
m (cid:90)
≤7 α2n2(e2nϵ2 −1)(cid:88) max E [W(z | X)]dµ
k a∈A Z
pa
t=1
7
≤
q2mn2(e2nϵ2
−1)
k
which finishes the proof of corollary 2.
B.3 Proof of corollary 3
For an (n,ρ)-estimator θˆof the true parameter under ℓ loss, we define Aˆ for A as
p
Aˆ= argmin∥θ −θˆ∥ .
a p
a∈A
Then, by the triangle inequality, we have
(cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13)θ A−θ Aˆ(cid:13) (cid:13)
p
≤ (cid:13) (cid:13)θ A−θˆ(cid:13)
(cid:13)
+(cid:13) (cid:13)θ Aˆ−θˆ(cid:13)
(cid:13)
≤ 2(cid:13) (cid:13)θˆ−θ A(cid:13)
(cid:13)
.
p p p
Because θˆis an (n,ρ)-estimator under ℓ loss, we have,
p
E Z[E pZ[(cid:13) (cid:13)θ
Z
−θ Zˆ(cid:13) (cid:13)p p]] ≤ 2pρpP[p
Z
∈ P Θ]+m z̸=a zx
′
∥θ
z
−θ z′∥p pP[p
Z
∈/ P Θ] (B.1)
1 τ
≤ 2pρp+4pρp · (B.2)
τ 4
3
≤ 4pϵp, (B.3)
4
using the fact that P[p ∈ P ] ≥ 1−τ/4 and condition 4. Also, from condition 4, Next,
A Θ
combining condition 4 and B.3, we could have: 1 (cid:80)k P[A ̸= Aˆ ] ≤ 3. Also, since the
τk i=1 i i 4
53Markov relation A −Xm −Zm −Aˆ holds for all i, by the standard relation between
i i
total variation distance and hypothesis testing, and also the definition of τ to be less
than 1/2, we have:
P[A ̸= Aˆ ] ≥ τP[Aˆ = −1|A = 1]+(1−τ)P[Aˆ = 1|A = −1]
i i i i i i
≥ τ(P[Aˆ = −1|A = 1]+P[Aˆ = 1|A = −1])
i i i i
≥ τ(1−d
(pXm ,pXm
))
TV +i −i
≥ τ(1−1/n·d
(pZm ,pZm
))
TV +i −i
The last inequality uses the definition of total variation, because Zm is generated by Xm
from the privacy constraint channel Wpriv, so for each dataset X , i = 1,2,...,m on the
i
i-th machine, let X be the dataset which changes the order of X and X , then for
ijk ij ik
any z ∈ Z,Wpriv(z|X ) = Wpriv(z|X ). Thus, by the definition of total variation, we
i ijk
could verify that d (pXi,pXi) = 1/n·d (pZi,pZi). Summing over 1 ≤ i ≤ k and
TV +i −i TV +i −i
combining it with the previous bound, we obtain
k k
3 ≥ 1 (cid:88) P[A ̸= Aˆ ] ≥ 1− 1 (cid:88) d (pZn ,pZn )
4 τk i i nk TV +i −i
i=1 i=1
which finishes the proof of corollary 3.
B.4 Proof of Lemma 4.1
ProofofLemma4.1: First,wewouldliketoshowthatouralgorithmis(ϵ,δ)-differentially
private. For two adjacent data sets, we have:
1
|(π (y )−xTβˆ)2−(π (y′)−x′T βˆ)2|
mn R i i R i i
2
≤ (π (y )−xTβˆ)2
mn R i i
4 4
≤ (π (y )2+(xTβˆ)2) ≤ (R2+sc2c2)
mn R i i mn 0 x
From the definition of Gaussian Mechanism, we could claim that our algorithm is (ϵ,δ)-
differential private. Then, for the convergence rate of our estimated σ, from our algo-
rithm, first, we observe with the choice of R, we claim that with high prob, we have
π (Y) = Y. Therefore, we have:
R
1
|σ2−σˆ2| ≤ | ∥Xβ+W −Xβˆ∥2−σ2|+|E|
mn 2
1 1
≤ | WTW −σ2|+(β−βˆ)Σˆ(β−βˆ)+ (β−βˆ)XTW +|E|
mn mn
For the first term, we could obtain that | 1 WTW −σ2| = O(√1 ) Also, we have:
mn mn
(β−βˆ)Σˆ(β−βˆ) ≤ λ (Σ)∥β−βˆ∥2
s 2
54(cid:18)
slogd
s2log2dlog(1/δ)log3mn(cid:19)
≤ cL +
mn m2n2ϵ2
Then, from Bernstein inequality, we could obtain that:
(cid:114)
1 logd
∥ XTW∥ = c ·
∞ 1
mn mn
Therefore, we claim that:
1
(β−βˆ)XTW
mn
1
≤ ∥β−βˆ∥ ∥XTW∥
1 ∞
mn
√
s
≤ c ∥β−βˆ∥ ∥XTW∥
2 2 ∞
mn
√
(cid:32)(cid:114)
slogd
slogd(cid:112) log(1/δ)log3/2mn(cid:33)(cid:114)
logd
≤ c s +
3
mn mnϵ mn
(cid:32) slogd slogd(cid:112) log(1/δ)log3/2mn (cid:114) slogd(cid:33)
= O + ·
p
mn mnϵ mn
(cid:18)
slogd
s2log2dlog(1/δ)log3mn(cid:19)
= O +
p mn m2n2ϵ2
Also, from our algorithm, we have E ∼ N(0,2B2log(1.25/δ)/ϵ2). Then,
2
2B2log(1/δ) R4+s2c4c4log(1/δ) s2log2dlog(1/δ)log3mn
|E| = 2 |N(0,1)| = c 0 x = c · ,
ϵ2 4 m2n2ϵ2 5 m2n2ϵ2
√
by observing that c = O( logd). Combining above inequalities, we have reached our
x
conclusion. Therefore, we finish our proof.
B.5 Proof of Lemma 4.2
Proof of Lemma 4.2: It is not difficult to verify the privacy conditions. Then, from the
theory of covering number, we could find n vectors v ,v ,...,v , such that for each
1 1 2 n1
s-sparse unit vector v, we have ∥v−v ∥ ≤ 1/9. Thus, we have:
i
λ −λˆ = v∗Σˆv∗−v Σˆv
s s i i
≤ v∗Σˆ(v∗−v )+(v∗−v )Σˆv
i i i
2
≤ λ
2s
9
≤ 8/9λ
s
Note that the second last inequality is a direct result of Cauchy inequality and the last
inequality holds because let v∗′ be the corresponding eigenvector of λ , then we could
2s
55break this eigenvector to two s-sparse vectors v′ and v′ such that v∗′ = v′ +v′, then
1 2 1 2
λ = (v′ +v′)TΣˆ(v′ +v′) ≤ 4λ .
2s 1 2 1 2 s
Also, notice that for the noise ξ, by the concentration of Laplace distribution, we could
√
find a constant c such that ξ ≤ cslogd/ n = o(1) with high probability. By the
definition of λ , we conclude the proof. □
s
56