Differentially Private Federated Learning:
Servers Trustworthiness, Estimation, and Statistical
Inference
Zhe Zhang∗Ryumei Nakada†Linjun Zhang‡
April 26, 2024
Abstract
Differentially private federated learning is crucial for maintaining privacy in dis-
tributed environments. This paper investigates the challenges of high-dimensional
estimationandinferenceundertheconstraintsofdifferentialprivacy. First, westudy
scenarios involving an untrusted central server, demonstrating the inherent difficul-
ties of accurate estimation in high-dimensional problems. Our findings indicate that
the tight minimax rates depends on the high-dimensionality of the data even with
sparsity assumptions. Second, we consider a scenario with a trusted central server
and introduce a novel federated estimation algorithm tailored for linear regression
models. This algorithm effectively handles the slight variations among models dis-
tributed across different machines. We also propose methods for statistical infer-
ence, including coordinate-wise confidence intervals for individual parameters and
strategies for simultaneous inference. Extensive simulation experiments support our
theoretical advances, underscoring the efficacy and reliability of our approaches.
1 Introduction
1.1 Overview
Federated learning is an efficient approach for training machine learning models on dis-
tributed networks, such as smartphones and wearable devices, without moving data to a
central server [26, 25, 30]. Since its proposal in [32], federated learning has gained sig-
nificant attention in both practical and theoretical machine learning communities. One
of the key attractions of federated learning is its ability to provide a certain level of
data privacy by keeping raw data on local machines. However, without specific design
choices, there are no formal privacy guarantees. To fully exploit the benefits of federated
learning, researchers have introduced the concept of differential privacy [1, 12, 13, 14, 15]
∗Rutgers University. Email: zzres0131@gmail.com.
†Rutgers University. Email: rn375@stat.rutgers.edu.
‡Rutgers University. Email: lz412@stat.rutgers.edu.
1arXiv:2404.16287v1  [stat.ML]  25 Apr 2024to quantify the exact privacy level in federated learning. A series of research papers
have focused on federated learning with differential privacy, applying various algorithms
and methods [23, 37, 39]. Despite these efforts, there remains a significant gap between
practical usage and statistical guarantees, particularly in the high-dimensional setting
with sparsity assumptions, where theoretical results for the optimal rate of convergence
and statistical inference results are largely missing.
In this paper, we focus on studying the estimation and inference problems in the
federated learning setting under differential privacy, particularly in the high-dimensional
regime. In federated learning, there are several local machines containing data sets from
different sources, and a central server to coordinate all local machines to train learning
models collaboratively. We present our key results in two major settings for privacy and
federated learning. In the first setting, we consider an untrusted central server [31, 39, 23]
where each machine sends only privatized information to the central server. For example,
whenusingsmartphones, whereusersmaynotfullytrust theserverand donotwanttheir
personal information to be directly updated on the remote central server. In the second
setting, we consider a trusted central server where each machine sends raw information
without making it private. [33, 19, 34] For example, in different hospitals, patient data
may not be shared among hospitals to protect patient privacy, but they can all report
their data to a central server, such as a non-profit organization or an institute, to gain
more information and publish statistics on certain diseases.
In the first part of our paper, we demonstrate that under the assumption that
the central server is untrusted, the optimal rate of convergence for mean estimation
is O( sd/(mnϵ2)), where mis the number of local machines and each containing ndata
points, dis the parameter of interest, sis the sparsity level, and ϵis the privacy pa-
rameter. As commonly assumed in high-dimensional settings where the dimension is
comparable or even larger than the number of data, such an optimality result shows the
incompatibility of untrusted central server setting and high-dimensional statistics. As a
result, we can only hope to get a good estimation under the trusted central server setting
in the high-dimensional regime.
In the second part of the paper, we consider the case of a trusted central server and
design algorithms that allow for accurate estimations and obtain a near-optimal rate of
convergence up to logarithm factors. We also present statistical inference results, includ-
ing the construction of coordinate-wise confidence intervals with privacy guarantees, and
the solution to conduct simultaneous inference privately. This will assist in hypothesis
testing problems and construction of confidence intervals for a given subset of indices of
a vector simultaneously in high-dimensional settings. We emphasize that our algorithms
for estimation and inference are suited for practical purposes, considering its capacity
to (1) leverage data from multiple devices to improve machine learning models and (2)
draw accurate conclusions about a population from a sample while preserving individual
privacy. For instance, in healthcare, we could combine patient data from multiple hospi-
tals to develop more accurate models for disease diagnosis and treatment, while ensuring
that patient privacy is protected. We summarize our major contributions as follows:
•For the untrusted central server setting, we provably show that federated learning is
2not suited for high-dimensional mean estimation problems by providing the optimal
rate of convergence under the untrusted central server constraints. This suggests
us to consider a trusted central server setting to utilize federated learning for such
problems.
•For the trusted central server setting, we design novel algorithms to achieve private
estimation with federated learning. We first consider the estimation in homoge-
neous federated learning setting and then we extend it to a more complicated het-
erogeneous federated learning setting. We also provide a sharp rate of convergence
for our algorithm in both settings.
•In addition, we consider statistical inference problems in both homogeneous and
heterogeneous federated learning settings. We provide algorithms for coordinate-
wise and simultaneous confidence intervals, which are two common inference prob-
lems in high-dimensional statistics. It is worth mentioning that our proposed meth-
ods for high-dimensional differentially private inference problems are novel and
unique, which has not been developed even for the single-source and non-federated
learning setting. Theoretical results show that our proposed confidence intervals
are asymptotically valid, supported by simulations.
1.2 Related Work
In the literature, several works focused on designing private algorithms in federated
learning/distributed learning based on variants of stochastic gradient decent algorithms.
[3] proposed a communication efficient algorithm, CP-SGD algorithm for learning models
with local differential privacy (LDP). [17] proposed a distributed LDP gradient descent
algorithm by applying LDP on gradients with ESA framework [6]. [20] extended works
on LDP approach for federated learning and proposed a distributed communication-
efficient LDP stochastic gradient descent algorithm through shuffled model and analyzed
the upper bound of the convergence rate. However, the trade-off between statistical
accuracy and the privacy cost has not been considered in these works.
In the distributed settings, the trade-off between statistical accuracy and information
constraints has been discussed in various papers. Two common types of information
constraints are communication constraints and privacy constraints. We refer to [43, 7,
21, 5, 18] for more discussions on communication constraints, considering the situation
where the bits of the information during communication have constraints.
Aseriesofworkdiscussesthetrade-offbetweenaccuracyandprivacyinhigh-dimensional
and non-federated learning problems, including top- kselection [35], sparse mean estima-
tion [8], linear regression [8, 36], generalized linear models [9], latent variable models [46].
However, the discussion on privacy constraints in the distributed settings are still largely
lacking. Among the existing works, most of them focus on the local differential privacy
(LDP) constraint. In [4], the mean estimation under ℓ2loss for Gaussian and sparse
Bernoulli distributions are discussed. [11] discussed the lower bounds under LDP con-
straintsintheblackboardcommunicationmodelformeanestimationofproductBernoulli
3distributions and sparse Gaussian distributions. [2] proposed a more general approach
to combine both communication constraints and privacy constraints. Compared with
previous works, we focus on the problem where there are ndata points on each machine.
Our interest lies in the (ϵ, δ)-DP instead of LDP, which is a weaker constraint containing
broader settings. We further note that, compared with the blackboard communication
model [7, 18], in the federated learning setting, we assume that the existence of a central
server and that each server is only allowed to communicate with the central server. This
setting enables us to enhance more privacy.
When we are finalizing this paper1, we realized an independent and concurrent work
[28]. [28] also considers differentially private federated transfer learning under high-
dimensional sparse linear regression model. Namely, they proposed a notion of federated
differential privacy that allows multiple rounds of (ϵ, δ)-differentially private transmis-
sions between local machines and the central server, and provides algorithms to filter
out irrelevant sources, and exploit information from relevant sources to improve the per-
formance of estimation of target parameters. We differntiate our research with their
paper as follows: (1) While they consider differentially private federated learning under
untrusted server setting, we deal with both trusted and untrusted server settings. We
also highlight a fundamental difficulty of pure ϵ-differentially private estimation under
untrusted central server settings in federated learning by establishing a tight minimax
lower bound, and resort to trusted server settings for estimation and inference prob-
lems. (2) While their investigation centers on differentially private estimation within a
federated transfer learning framework—specifically focusing on parameter estimation for
a target distribution using similar source data—our work focuses on private estimation
andinference for parameters that are either common across all participating machines,
or vary across different machines.
We also cite papers that provided us inspirations for the design of our proposed
algorithms and methods. [24] introduces a de-biasing produce for the statistical inference
problems. [29]considersthetransferlearningprobleminhigh-dimensionalsettings,which
enables us to combine information from other sources to benefit the estimation problems.
Such idea could be adopted in the hetergeneous federated learning problems. For the
simultaneous inference problems, we refer to [42, 41], which discussed how to conduct
simultaneous inference for high-dimensional problems.
Notation. We introduce several notations used throughout the paper. Let v=
(v1, v2, . . . , v d)⊤∈Rdrepresent a vector. Given a set of indices S,vSrefers to the
components of vcorresponding to the indices in S. The ℓqnorm of v, for1≤q≤ ∞, is
given by ∥v∥q, whereas ∥v∥0represents the number of non-zero elements in v, also called
as its sparsity level.
We use mto indicate the number of machines, nfor the number of samples per
machine, dfor the dimensionality of vectors, and sfor their sparsity level. The total
number of samples across all machines is denoted by n0=m·n. Additionally, we define
the truncation function ΠT:Rd→Rd, which projects a vector onto the ℓ∞ball of radius
Tcentered at the origin.
1An initial draft of this paper was published as a Ph.D. dissertation in 2023 [45].
4Foramatrix Σ,max∥v∥2=1,∥v∥0≤sv⊤Σvandmin∥v∥2=1,∥v∥0≤sv⊤Σvdenotethelargest
and smallest s-restricted eigenvalues of Σ, denoted as µs(Σ)andνs(Σ), respectively.
For sequences anandbn,an=o(bn)implies an/bn→0asngrows, an=O(bn)
signifies that anis upper bounded by a constant multiple of bn, and an= Ω(bn)indicates
thatanis lower bounded by a constant multiple of bn, where constants are independent
ofn. The notation an≍bndenotes that anis both upper and lower bounded by constant
multiples of bn.
In this work, we often use symbols c0, c1, m0, m1, C, C′, K, K′to represent univer-
sal constants. Their specific values may vary depending on the context, but they are
independent from other tunable parameters.
2 Preliminaries
2.1 Differential Privacy
We start form the basic concepts and properties of differential privacy [13]. The intuition
behind differential privacy is that a randomized algorithm produces similar outputs even
whenanindividual’sinformationinthedatasetischangedorremoved, therebypreserving
the privacy of individual data. The formal definition of differential privacy is given below.
Definition 2.1 (Differential Privacy [13]) LetXbe the sample space for an individ-
ual data, a randomized algorithm M:Xn→Ris(ϵ, δ)-differentially private if and only
if for every pair of adjacent data sets X,X′∈ Xnand for any S⊆R, the inequality
below holds:
P(M(X)∈S)≤eε·P 
M(X′)∈S
+δ,
where we say that two data sets X={xi}n
i=1andX′={x′
i}n
i=1are adjacent if and only
if they differ by one individual datum.
In the above definition, the two parameters ϵ, δcontrol the privacy level. From the
definition, with smaller ϵandδ, the outcomes given adjacent XandX′become closer,
making it harder for an adversary to distinguish if the original dataset is XorX′,
indicating the privacy constraint becomes more stringent. Furthermore, when δ= 0, we
could use ϵ-differentially private as the abbreviation of (ϵ,0)-differentially private.
In the rest of this section, we introduce several useful properties of differential privacy
and how to create a differential private algorithm from non-private counterparts. One
common strategy is through noise injection. The scale of noise is characterized by the
sensitivity of the algorithm:
Definition 2.2 For any algorithm f:Xn→Rdand two adjacent data sets XandX′,
theℓp-sensitivity of fis defined as:
∆p(f) = sup
X,X′∈Xnadjacent∥f(X)−f(X′)∥p.
5We then introduce two mechanisms. For algorithms with finite ℓ1-sensitivity, we add
Laplace noises to achieve differential privacy, while for ℓ2-sensitivity, we inject Gaussian
noises.
Proposition 2.3 (The Laplace Mechanism [13, 14]) Letf:Xn→Rdbe a deter-
ministic algorithm with ∆1(f)<∞. For w∈Rdwith coordinates w1, w2,···, wdbe i.i.d
samples drawn from Laplace (∆1(f)/ϵ),f(X) +wis(ϵ,0)-differentially private.
Proposition 2.4 (The Gaussian Mechanism [13, 14]) Letf:Xn→Rdbe a de-
terministic algorithm with ∆2(f)<∞. For w∈Rdwith coordinates w1, w2,···, wdbe
i.i.d samples drawn from N(0,2(∆ 2(f)/ϵ)2log(1.25/δ)),f(X) +wis(ϵ, δ)-differentially
private.
The post-processing and composition properties are two key properties in differential
privacy, which enable us to design complicated differentially private algorithms by com-
bining simpler ones. Such properties are pivotal in the design of algorithms in later
chapters.
Proposition 2.5 (Post-processing Property [13]) LetMbe an (ϵ, δ)-differentially
private algorithm and gbe an arbitrary function which takes M(X)as input, then
g(M(X))is also (ϵ, δ)-differentially private.
Proposition 2.6 (Composition property [13]) Fori= 1,2, letMibe(εi, δi)-differentially
private algorithm, then (M1, M2)is(ϵ1+ϵ2, δ1+δ2)-differentially private algorithm.
We also mention NoisyHT algorithm (Algorithm 1) introduced by [16], which stands for
the noisy hard-thresholding algorithm. The algorithm aims to pursue both sparsity of
the output and privacy at the same time.
Algorithm 1: Noisy Hard Thresholding Algorithm (NoisyHT( v, s, λ, ϵ, δ)) [16]
1Input: vector-valued function v=v(X)∈Rdwith data X, sparsity s, privacy
parameters ε, δ, sensitivity λ.
2Initialization: S=∅.
3Foriin1tos:
4Generate wi∈Rdwith wi1, wi2,···, widi.i.d.∼Laplace
λ·2√
3slog(1 /δ)
ε
.
5Append j∗=argmaxj∈[d]\S(|vj|+wij)toS.
6End For
7Generate ˜wwith ˜w1,···,˜wdi.i.d.∼Laplace
λ·2√
3slog(1 /δ)
ε
.
8Output: PS(v+˜w).
In the last step, PS(u)denotes the operator that makes uSc= 0while preserving uS.
This algorithm could be seen as a private top-k selection algorithm, which helps build
our proposed algorithm in later section.
6Specifically, whenthesparsity sischosentobe 1, thealgorithmoutputsthemaximum
element chosen after a single iteration in the private manner. We refer this special case as
the Private Max algorithm, which is implemented in Algorithm 7 used for simultaneous
inference.
2.2 Federated Learning
Federated learning introduced in [32] is a technique designed to train a machine learning
algorithm across multiple devices, without exchanging data samples. A central server
coordinates the process, with each local machine sending model updates to be aggregated
centrally. Figure 1 illustrates the basic concept of federated learning
Figure 1: Federated Learning
One characteristic of federated learning is that the training of machine learning mod-
els occurs locally, and only parameters and updates are transferred to the central server
and shared by each node. Specifically, communication between local machines and the
server is bidirectional: machines send updates to the central server, and in return, they
receiveaggregatedinformationafterprocessing. Communicationamonglocalmachinesis
prohibited to prevent privacy leakage. Intuitively, federated learning inherently provides
a certain level of privacy.
Although without rigorous definitions, there are two main branches of central server
settings in federated learning: the untrusted central server setting and the trusted central
server setting [31, 39, 33, 19]. In the first setting, where the central server is untrusted,
each piece of information sent from the machine to the central server should be differ-
entially private. In the second setting, we assume a trusted central server exists. In
this scenario, it is safe to send raw information from the machine to the central server
without additional privacy measures. However, to prevent information leakage among
local machines, the information sent back from the server should also be differentially
private.
Another key aspect of federated learning is that the datasets on each local machine
are commonly not independent and identically distributed (i.i.d.). This allows federated
7learning to train on heterogeneous datasets, aligning with practical scenarios where the
datasets on different machines are typically diverse and their sizes may also vary. We
will demonstrate that federated learning can efficiently estimate the local model when
models on different local machines differ but share some similarities, a concept we refer
to as heterogeneous federated learning in Section 5.
2.3 Problem Formulation
In this paper, we assume that there exists a central server and mlocal machines. We de-
note the data on these machines by X1,X2,X3, . . . ,Xm, respectively, with Xi∈Rni×d.
On any machine i= 1,2, . . . , m, there are nidata points Xi= [Xi1,Xi2, . . . ,Xini]. For
simplicity, we assume that there are equal data points n=n1=n2=···=nifor each
machine. We note that the result could be easily generalized to cases where the sample
sizes on each machine differ.
We consider both untrusted and trusted central server settings. For the untrusted
setting, we require that the information sent from local machines to the server is pri-
vate. In this scenario, we show that in the high-dimensional setting, even with sparsity
assumptions, it is impossible to achieve small estimation error when the central server
is untrusted. In the trusted setting, we consider the high-dimensional linear regression
problem Y=Xβ+Wwith s-sparse β. We will first study the case where all machines
share the same β, (referred to homogeneous federation learning,) and then study a more
general case where models on different machines are not equal, but share certain simi-
larities (referred to heterogeneous federation learning.) We show that our algorithm can
adapt to such similarity—with larger similarity, the algorithm achieves a faster rate of
convergence.
3 An Impossibility Result in the Untrusted Central Server
setting
In this section, we study the untrusted server setting where the local machines need to
send privatized information to the central server to ensure privacy. We show an impos-
sibility result that in high-dimensional settings where the data dimension is comparable
to or greater than the sample size, accurate estimation is not feasible even if we consider
a simple sparse mean estimation problem.
As mentioned in Section 2.3, we consider a federated learning setting with mma-
chines, where each machine i∈[m]handles ndata points Xi:= [Xi1,Xi2, . . . ,Xin]∈
Rn×d. Let Dall={Xi}m
i=1. We assume that each data point Xij∈Rdfollows a Gaussian
distribution N(µ,Id), where µis a sparse d-dimensional vector with sparsity s. The goal
is to estimate µin the federated learning setting when the central server is untrusted. In
this section, we provide an optimal rate of convergence for this problem and show that
the untrusted central server setting is not suited for high-dimensional problems.
We begin by deriving the minimax lower bound, which characterizes the fundamental
difficulty of this estimation problem. In untrusted server setting, we additionally assume
8that each piece of information sent from the local machine to the central server follows
ϵ-differential privacy. To achieve this, we introduce the privacy channel Wϵ-priv:Xn→
Z, a function that is responsible for privatizing the information transmitted from the
local machines. Given the input X∈ Xnand the privacy channel Wϵ-priv,Z∈ Z
representing all the information (from multiple rounds) transmitted to the central server.
More precisely, we require privacy guarantees such that for any two adjacent datasets X
andX′∈ Xn, differing by only one data point on any local machine, and for an output
Z∈ Zrepresenting the information sent from the local machine to the central server,
differential privacy guarantee P(Wϵ-priv(X) =Z)≤eϵ·P(Wϵ-priv(X′) =Z)holds.
Weconsideranymechanism Minthefederatedlearningsettingwith mlocalmachines
and one central server, operated on the dataset Dall.Mserves as a procedure to estimate
µ, where each local machine collaborates exclusively with the central server without
direct interaction among themselves. On each machine i, the mechanism Muses the
privacy channel Wϵ-priv
iand data sample Xito generate Zi, which is then transmitted to
the central server. The central server receives the information from all machines. After
multi-rounds of collaboration between local machines and the central server, we obtain
the sparse and private estimator ˆµ∈Rd. We denote the class of all mechanisms that
satisfy the above constraints as Muntrust
m,ϵ (Dall). Under this setting we establish a lower
bound for the estimation error of the mean in Theorem 1.
Theorem 1 Suppose Dallis generated as above. Let µbe as-sparse d-dimensional mean
of Gaussian distribution satisfying ∥µ∥∞≤1. We consider the estimation of the mean
vector ˆµunder the untrusted central server federated learning setting with mlocal ma-
chines and ndata points in each machine. Then, there exists a constant c >0such
that
inf
M∈Muntrustm,ϵsup
µ∈Rd,∥µ∥∞≤1∥µ−M(Dall)∥2
2≥c·mins
n,sd
mnϵ2
.
Thelowerboundcontainstwoterms. Thefirstterm, oforder s/n, representstheminimax
risk of mean estimation using only the samples from a local machine. The second term, of
order sd/(mnϵ2), accounts for the error from federated learning across multiple machines
under privacy constraints. Theorem 1 suggests that we cannot perform better than either
choosing to estimate the mean using only the local machine or adopting the federated
learning approach and combining information from different machines. However, in the
latter approach, we must at least incur a rate of O(d/(mnϵ2)), which is linearly pro-
portional to the dimension d. This result suggests that privacy constraints significantly
impact the efficiency of federated learning in high-dimensional settings. Furthermore, as
the number of machines mincreases, we can possibly attain better performance, high-
lighting the merit of federated learning.
We also show the tightness of the lower bound in Theorem 1 by providing the upper
bound.
Theorem 2 Suppose that conditionsin Theorem1 hold. Then, there exists an ϵ-differentially
9private algorithm for the estimation of µasˆµ
∥µ−ˆµ∥2
2≤c·s·d
mnϵ2,
where c >0is some constant.
The proof follows by constructing an algorithm that transforms Gaussian mean to
Bernoulli mean according to the sign of the Gaussian mean, motivated by Algorithm 2
discussed in [2], where the authors discuss l-bit protocol for estimating the product of
Bernoulli family. More details of the algorithm are deferred to Section A.2. Based
on the results from Theorems 1 and 2, we obtain the optimal rate of convergence for
sparse mean estimation under differentially private federated learning setting. As a
result, when the central server is untrusted, it is impossible to find an approach to
achieve accurate estimation under the untrusted server assumption. This highlights the
necessity of the trusted server setting for statistical estimation and inference in high-
dimensionalfederated learning scenarios. In thefollowing sections, we develop estimation
and inference procedures under the trusted server settings.
4 Homogeneous Federated Learning Setting
4.1 Algorithms for Estimation Problems
In this section, we consider the setting of a trusted central server, where local machines
fully trust the central server and send unprivatized information to it without implement-
ing privacy measures. However, when the central server sends information back to the
local machines, it must ensure that this information is privatized to avoid any privacy
leakage across local machines.
In this subsection, we first focus on the statistical estimation problems in this setting
and then develop inference results in the next subsection. More specifically, our primary
focus is on the linear regression problem in a high-dimensional setting, where the ground
truth, denoted as β, is a sparse d-dimensional vector. We initially study the simpler
case in this section, where the underlying generative models for each local machine are
identical, which we refer to as the homogeneous federated learning setting. A more
complicated heterogeneous setting will be discussed in the following section. Specifically,
we consider the following high-dimensional linear regression model:
Y=Xβ+W,
where we assume Wis the error term whose coordinates are independent and following
sub-Gaussian distribution with variance proxy σ2, denoted by Wi∼subG (σ2).Xis
a random matrix whose rows are following sub-Gaussian distribution with a covariance
matrix Σ.
We first introduce the parameter estimation algorithm under differentially private
federated settings with a trusted central server.
10Algorithm 2: Differentially Private Sparse Linear Regression under Federated
Learning
Input : Dataset Dall={(Xi,Yi)}i∈[m], number of machines m, number of
samples on each machine n, step size η0, privacy parameters ε, δ, noise
scale B0, number of iterations T, truncation level R, feasibility
parameter C0, sparsity s, initial value β0.
1fortfrom 0toT−1do
2Step 1:
3On each local machine i= 1,2, . . . , m, calculate the local gradient
gi=1
nnX
j=1(X⊤
ijβt−ΠR(yij))Xij.
Send the gradient gito the central server.
4Step 2:
5Compute βt+0.5=βt−(η0/m)Pm
i=1giat the central server;
6Compute βt+1= Π C0
NoisyHT (βt+0.5, s,ε
T,δ
T,η0B0
mn)
at the central
server.
7Step 3: Send the output βt+1back to each local machine from the server.
8end
9Output: Return βT.
In Step 1 of Algorithm 2, the information computed on each local machine is trans-
mitted to the central server. The second step involves calculations performed at the
central server. Prior to sending the information back to the local machines, it undergoes
privacy preservation through the application of the NoisyHT algorithm, as introduced
in Algorithm 1. Subsequently, the local machine updates its estimation based on the
information received from the central server.
We compare Algorithm 2 with Algorithm 4.2 in [8], which addresses the private
estimation in linear regression under non-federated learning settings. Unlike the latter,
ouralgorithmdoesnottransmitalldatapointstothecentralserver. Instead, wecalculate
the gradient updates locally on each machine and send only these local gradients to the
server. This design enhances privacy protection, as the original data remains visible
only on the local machine and is not exposed externally. Furthermore, this approach of
gradient updates also reduces communication costs by transmitting only a d-dimensional
vector from each local machine for the gradient update. Previous research has also
considered non-private distributed methods for linear regression problems, such as [27,
44]. Our algorithm, however, ensures differential privacy. In practice, the sparsity level
scan be determined using a private version of cross-validation, while other parameters
may be pre-chosen based on our theoretical analysis.
114.2 Algorithms for Inference Problems
In this subsection, we focus on statistical inference problems in the homogeneous feder-
ated learning setting, such as constructing coordinate-wise confidence intervals for pa-
rameters and performing simultaneous inference. To begin, we develop a method for
constructing coordinate-wise confidence intervals, for example, for the k-th index of β,
βk. However, it is important to note that the output of Algorithm 2 is biased due to
hard thresholding. To overcome this bias, we employ a de-biasing procedure, a common
technique in high-dimensional statistics, as demonstrated in previous studies [24]. This
procedure involves approximating the k-th column of the precision matrix Θ=Σ−1
to construct confidence intervals for each βk. Subsequently, we focus on obtaining an
estimate of the precision matrix in a private manner.
Algorithm 3: Differentially Private Precision Matrix Estimation in Federated
Learning
Input : Number of machines m, number of data points in each machine n,
dataset Xi= (xi1, . . . ,xin)fori= 1, . . . , m, step size η1, privacy
parameters ε, δ, noise scale B1, number of iterations T, feasibility
parameter C1, sparsity s, initial value Θ0
k.
1fortfrom 0toT−1do
2Step 1: On each local machine i= 1,2, . . . , m, calculate local gradient
gi=1
nPn
j=1XijX⊤
ijΘt
k−ej. Send the gradients (g1,g2, . . . ,gm)to the
central server.
3Step 2:
4Compute Θt+0.5
k=Θt
k−(η0/m)Pm
i=1giat the central server;
5Compute Θt+1
k= Π C1
NoisyHT (wt+0.5
k, s,ε
T,δ
T,η1B1
mn)
at the central
server.
6Step 3: SendΘt+1
kback to each local machine from the server.
7end
8Output: Return ΘT
k.
The structure of Algorithm 3 is similar to Algorithm 2, as both adopt an iterative
communication between the central server and the local machines; the information is ini-
tially transmitted from the local machines to the server, then, the central server performs
calculations and use the NoisyHT algorithm (Algorithm 1) to ensure the privacy of the
information. Subsequently, eachlocalmachineupdatesthegradientandprogressestothe
next iteration. The primary distinction between two algorithms lies in the computation
of the gradient on each machine.
Denote the output of Algorithm 2 as ˆβand the output of Algorithm 3 as ˆΘk. Then
the de-biased differentially private estimator of βkis given by
ˆβu
k=ˆβk+1
mmX
i=1ˆΘ⊤
kgi+Ek, (4.1)
where gi= (1/n)Pn
j=1(X⊤
ijˆβ−ΠR(yij))Xij, and Ekis the injected random noise to
12ensure privacy, following a Gaussian distribution N(0,8∆2
1log(1.25/δ)/(n2m2ϵ2)), where
∆1=√sc1cxR+sc0c1c2
xwith some constants c0, c1, cxdefined later.
The debiased estimator in (4.1) enables us to construct a differentially private con-
fidence intervals. Although the variance σof the error term Win the linear regression
model is usually unknown, we can estimate σfrom the data in a private manner. The
estimation is based on the residual term between the response Yand the fitted value
Xˆβ. We summarize the method to estimate σin the private federated learning setting
in Algorithm 4.
Algorithm 4: Differentially Private Variance Estimation in Federated Learning
Input : Dataset (Xi,Yi)[i=1,2,...,m ], privacy parameters ε, noise scale B2,
truncation level R, estimated parameter ˆβfrom Algorithm 2.
1Step 1: On each machine i= 1,2, . . . , m, compute ˆWi=∥ΠR(Yi)−Xiˆβ∥2
2/n
and send ˆWito the central server.
2Step 2: Generate a random variable Evar, where Evar∼
N(0,2B2
2log(1.25/δ)/ϵ2)
3Step 3: Compute ˆσ2such that ˆσ2=Pm
i=1ˆWi/m+Evarat the central server
Output: Estimated variance ˆσ2.
When examining the convergence rates of ˆβand ˆΘkin Theorem 3, we observe the
crucialrolesofthelargestandsmallestrestrictedeigenvaluesof Σ. Sincetheseeigenvalues
directly influence the construction of confidence intervals and cannot be directly obtained
from the data, their private estimation becomes essential. Below, we outline an algorithm
to estimate the largest restricted eigenvalue, µs(Σ). To estimate the smallest restricted
eigenvalue, νs(Σ), the same algorithm can be used by modifying Step 4 from “argmax”
to “argmin”.
Algorithm 5: Differentially Private Restricted Eigenvalue Estimation in Fed-
erated Learning
Input : Number of machines m, dataset (Xi)[i=1,...,m ], number of data points
in each machine n, privacy parameters ε, noise scale B3, number of
vectors n1.
1Step 1: Sample n1d-dimensional, s-sparse unit vectors v1,v2, . . . ,vn1.
2Step 2: On each machine, compute ti,k= (vT
kXT
iXivk)/nwhere
k= 1,2. . . , n 1and send them on to the central server.
3Step 3: Sample ξ1, . . . , ξ n1∼Laplace (2B3/ϵ).
4Step 4: Compute kmaxsuch that kmax= arg maxkPm
i=1ti,k/m+ξk.
Output: µs(ˆΣ) =Pm
i=1ti,kmax/m+ξ, where ξ∼Laplace(2 B3/ϵ)independently.
Based on Algorithms 4 and 5, we provide a constuction for coordinate-wise confidence
intervals in Algorithm 6.
13Algorithm 6: Differentially Private Coordinate-wise Confidence interval for βk
in Federated Learning
Input : Number of machines m, dataset (Xi,Yi)[i=1,...,m ], number of data
points in each machine n, privacy parameters ε, δ, truncation level R,
sparsity s, estimators of parameters ˆβ,ˆΘkfrom Algorithms 2 and 3,
constants ∆1, γ.
1Step 1: On each local machine i= 1,2, . . . , m, calculate local gradient
gi=1
nPn
j=1(X⊤
ijˆβ−ΠR(yij))Xij. Send the gradient (g1,g2, . . . ,gm)to the
central server.
2Step 2: Generate a random variable Efrom the Gaussian distribution
N(0,8∆2
1log(1.25/δ)/n2m2ϵ2).
3Step 3: Calculate de-biased estimation, ˆβu
k=ˆβk+1
mPm
i=1ˆΘ⊤
kgi+E
4Step 4: Estimate ˆσfrom Algorithm 4 and ˆµs,ˆνsfrom Algorithm 5.
5Step 5: Calculate the confidence interval Jk(α).
Jk(α) =
ˆβu
k−γˆµ2
s
ˆν2ss2log2dlog(1/δ) log3mn
m2n2ϵ2−Φ−1(1−α/2)σ√mnr
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
mnϵ2,
ˆβu
k+γˆµ2
s
ˆν2ss2log2dlog(1/δ) log3mn
m2n2ϵ2+ Φ−1(1−α/2)σ√mnr
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
mnϵ2
6
Output: Return the final result Jk(α).
So far we focused on constructing confidence intervals for individual coordinates of
the parameter vector β. However, in high-dimensional settings, we are often interested
in group inference problem, where we test hypotheses involving multiple coordinates
simultaneously. Specifically, we consider the problem of testing the null hypothesis given
by
H0:ˆβk=βk, for all k∈G
against the alternative hypothesis,
H1:ˆβk̸=βk,
for at least one k∈G, where Gis a subset of all coordinates {1,2, . . . , d }and we allow
|G|to be the same order as d. Additionally, we also construct simultaneous confidence
intervals for all coordinates in G. Note that the problem discussed above are common in
high-dimensionaldataanalysis, withapplicationssuchasmulti-factoranalysisofvariance
[22], additive modeling [40]. Previous research works have discussed similar problems in
the non-private setting, including [10, 42, 41].
Toaddresstheproblem, simultaneousinferencecanbeconductedusingateststatistic
max
k∈G|ˆβu
k−βk|.
Major challenges of simultaneous inference in a private federated learning setting
include: (1) minimizing the communication cost from local machines to the server while
14retaining all data on the local machines, and (2) ensuring the privacy of the procedure,
which necessitates a tailored privacy-preserving mechanism at each step of the algorithm.
In our framework, we propose an algorithm based on the bootstrap method. As previ-
ously mentioned, to build confidence intervals, our interest lies in the statistic computed
by the maximum coordinate of ˆβu
k−βkoverG. By decomposing this statistic, we obtain
a termσ√mnPm
i=1Pn
j=1ˆΘXij(yij−XT
ijβ). To determine the distribution of this term,
we bootstrap the residuals yij−XT
ijβ.
We outline the algorithm as follows: we first estimate ˆβand ˆΘkusing Algorithm 2
and 3, respectively. Accordingly, by stacking ˆΘkfor all k, we get an estimator of the
precision matrix ˆΘ. The details are provided in Algorithm 7.
Algorithm 7: Private Bootstrap Method for Simultaneous Inference in Feder-
ated Learning
Input : number of machines m, dataset (Xi,Yi)[i=1,2,...m], number of data on
each machine n, privacy parameters ε, δ, estimators of parameters ˆβ,
ˆΘfrom Algorithms 2 and 3, number of iterations for bootstrap q,
quantile α, noise level B4, subset of coordinates G.
1fortfrom 0toqdo
2Step 1: For each local machine i= 1, . . . , m, generate nindependent
standard Gaussian random variables ei1, . . . , e in. Calculate
ui=1√nPn
j=1ˆΘXijeij.
3Step 2: Send (ui)[i=1,2,...,m ]from local machines to the central server.
4Step 3: Calculate Ut=Privatemax ([(1/√m)Pm
i=1ui]G, ϵ, δ, B 4)at the
central server.
5end
6Output: Compute the α-quantile CU(α)of(|U1|,|U2|, . . .|Uq|)forα∈(0,1).
On line 4 of Algorithm 7, we employ the Private Max algorithm, which we mentioned
earlier as a variation of NoisyHT algorithm (Algorithm 1) by directly picking s= 1, to
obtain the maximum element in a vector in a private manner. It is also important to
note that the Private Max algorithm is applied to a subset of G. After presenting the
algorithm, we denote Mas:
M(ˆβ) = max
k∈G|√mn(ˆβu
k−βk)|.
Mis used as the statistic for inference problems later.
As previously mentioned, we can easily construct a simultaneous confidence interval
for each k∈Gby:
ˆβu
k−ˆσ√mnCU(α),ˆβu
k+ˆσ√mnCU(α)
,
where CU(α)is obtained from our algorithm with prespecified α. We can similarly
perform hypothesis testing; first calculate the test statistic and obtain CU(α)from our
algorithm with prespecified α, then reject if the statistic lies in the rejection region.
154.3 Theoretical Results
In this subsection, we provide theoretical guarantee for the algorithms and methods
discussed in the previous subsections. Before proceeding, we outline key assumptions
concerning the design matrix X, precision matrix Θ, and the true parameter βof the
linear regression model, which are essential for our subsequent analyses.
(P1) Parameter Sparsity: The true parameter vector βsatisfies ∥β∥2< c 0for some
constant 0< c0<∞and∥β∥0≤s∗
0=o(n).
(P2) Precision matrix sparsity: For each column of the precision matrix Θk,k=
1,2, . . . , d, it satisfies that ∥Θk∥2< c 1for some constant 0< c 1<∞and
∥Θk∥0≤s∗
1=o(n).
(D1) Design Matrix: for each row of the design matrix X, denote by x,xΣ−1/2is
sub-Gaussian with sub-Gaussian norm κ:=∥Σ−1/2x∥ψ2.
(D2) Bounded Eigenvalues of the covariance matrix: For the covariance matrix Σ=
Exx⊤, there exists a constant 0< L < ∞such that 0<1/L < λ min(Σ)≤
λmax(Σ)< L.
The above assumptions (P1) and (P2) bounds the ℓ2norm and ℓ0norm of the parameters
βandΘk, and assumption (D1) guarantees that each row of Xfollows a sub-Gaussian
distribution, and assumption (D2) requires the covariance matrix has bounded eigen-
values. These assumptions are commonly used for theoretical analysis of differentially
private algorithms and debiased estimators [9, 8, 24].
With assumptions (P1)-(D2), we analyze the algorithms we presented. We begin with
the estimation problem and provide a rate of convergence of ˆβandˆΘk.
Theorem 3 Let{(yij,Xij)}i∈[m],j∈[n]be an i.i.d. samples from the high-dimensional
linear model. Suppose that assumptions (P1), (P2), (D1), (D2) are satisfied. Addition-
ally,
•we choose parameters as follows: let s∗=max(s∗
0, s∗
1),R=σ√2 logmn,C0=c0,
C1=c1,cx= 3p
2Lκ2logd,B0= 2( R+√sc0cx)cx,B1= 2√sc1c2
x,∆1=√sc1cxR+sc0c1c2
xandγ= max( µs(9µs+ 1/4),17/16µs+ 1/96), where µs, νsare
the largest and smallest s-restricted eigenvalues of ˆΣ.
•we set β0=0andΘ0
k=0as the initialization used in Algorithm 2 and Algorithm 3.
Then there exists some absolute constant ρ >0such that, if s=ρL4s∗,η0=η1=s/6L,
T=ρL2log 
8c2
0Ln
andn≥KR(s∗)3/2logdp
log(1/δ) logn/εfor a sufficiently large
constant K > 0, then, for the output from Algorithm 2 and Algorithm 3,
∥ˆβ−β∥2
2≤σ2
k0·slogd
mn+6γµs
ν2s·s2log2dlog(1/δ) log3mn
m2n2ϵ2
,(4.2)
16and
∥ˆΘk−Θk∥2
2≤σ2
k1·slogd
mn+6γµs
ν2ss2log2dlog(1/δ) log3mn
m2n2ϵ2
,(4.3)
hold with probability 1−exp(−Ω(log( d/slogd) + log n)).
The upper bound of Algorithm 3 in (4.3) can be interpreted as follows. The first
term represents the statistical error, while the second term accounts for the privacy cost.
Furthermore, the result is comparable to that of Theorem 4.4 in [8], which addresses
private linear regression in a non-federated setting. This comparison suggests that the
federated learning approach does not affect the convergence rate adversely; instead, it
allows us to leverage the benefits of federated learning. We also note that the advantages
of federated learning will be further explored in the heterogeneous federated learning
setting, which will be discussed in the next chapter.
The remainder of this subsection presents the theoretical results for the inference
problem. We begin with the construction of coordinate-wise confidence intervals. As
mentionedbefore, σisusually unknownandweestimate σina private manner, presented
in Algorithm 4. Lemma 4.1 states the statistical guarantee of our algorithm.
Lemma 4.1 Letˆσ2be the output from Algorithm 4 by choosing R=O(√2 logmn),
B2=4
mn(R2+s2c2
0c2
x)and ˆβas the output from Algorithm 2. Then, Algorithm 4 is
(ϵ, δ)-differentially private, and it follows that
|σ2−ˆσ2| ≤c·1√mn+slogd
mn+s2log2dlog(1/δ) log3mn
m2n2ϵ2
,
where c >0is a universal constant.
Next, we consider a simplified version of the confidence interval, where the privacy
cost is dominated by the statistical error. In this scenario, we assume that the privacy
level is relatively low and the privacy constraints are loose, meaning that the privacy
parameters ϵandδare relatively large, allowing for nearly cost-free estimation. We
present our result in the following theorem.
Theorem 4 Suppose that the conditions in Theorem 3 hold. Assume thats∗logd√mn=o(1)
ands∗2log2dlog(1 .25/δ) log3mn
mnϵ2 =o(1). Also assume that the privacy cost is dominated
by statistical error, i.e., there exists a constant k0such thats∗2log2dlog(1 /δ) log3mn
m2n2ϵ2 ≤
k0·s∗logd
mn. Then, given the de-biased estimator ˆβu
kdefined in (4.1), the confidence interval
is asymptotically valid:
lim
mn→∞P(βk∈Jk(α)) = 1 −α,
where
Jk(α) =
ˆβu
k−Φ−1(1−α/2)ˆσ√mnq
ˆΘ⊤
kˆΣˆΘk,ˆβk+ Φ−1(1−α/2)ˆσ√mnq
ˆΘ⊤
kˆΣˆΘk
Also, the confidence interval Jk(α)is(ϵ, δ)-differentially private.
17Theorem 4 assumes that the privacy cost is dominated by the statistical error. How-
ever, when the privacy constraint is more stringent with small privacy parameters ϵand
δ, the privacy cost may be larger than the statistical error. In this scenario, we general-
ize Theorem 4 to analyze Algorithm 6. We note that the largest and smallest restricted
eigenvalues of ˆΣalso need to be estimated by Algorithm 5. Lemma 4.2 quantifies the
estimation error of the largest restricted eigenvalue of ˆΣ.
Lemma 4.2 Ifn1=cdsandB3= 2sc2
x/nfor some constant c >0, then the output
from Algorithm 5 is (ϵ,0)-differentially private. Moreover, (1/9)λs≤ˆλs≤λsholds where
λsis the largest restricted eigenvalue of ˆΣ.
We then present a theoretical result for the confidence interval in a more general case
in Theorem 5.
Theorem 5 Assume the conditions in Theorem 3 hold. Suppose thats∗logd√mn=o(1)
ands∗2log2dlog(1 .25/δ) log3mn
m2n2ϵ2 =o(1), then, given the de-biased estimator ˆβu
kdefined in
(4.1)and the estimated restricted eigenvalues ˆµsandˆνsfrom Algorithm 5, the confidence
interval constructed by Algorithm 6 is asympotically valid:
lim
mn→∞P(βk∈Jk(α)) = 1 −α,
where
Jk(α) =
ˆβu
k−γˆµ2
s
ˆν2ss2log2dlog(1/δ) log3mn
m2n2ϵ2−Φ−1(1−α/2)ˆσ√mnr
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
mnϵ2,
ˆβj+γˆµ2
s
ˆν2ss2log2dlog(1/δ) log3mn
m2n2ϵ2+ Φ−1(1−α/2)ˆσ√mnr
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
mnϵ2
.
Also, Jk(α)is(ϵ, δ)-differentially private.
Comparedtothenon-privatecounterpartin[24], weclaimthatourconfidenceinterval
has a similar form but with additional noise injected to ensure privacy. When the noise
level is low, the confidence interval closely approximates the non-private counterpart,
allowing us to nearly achieve privacy without incurring additional costs. Furthermore,
when the privacy level is high, the confidence interval has a larger length to attain the
same confidence level.
Finally, for the simultaneous inference problems, we demonstrate that α-quantile
of statistic Min (6) is close to the α-quantile of Ucalculated in Algorithm 7 for each
α∈(0,1)using the bootstrap method. The next theorem states the statistical properties
of Algorithm 7.
Theorem 6 Assume the conditions in Theorem 4 hold. Additionally, we assume that
s∗logd√mn=o(1)and the privacy cost is dominated by the statistical error, i.e., there exists
a constant c > 0such thats∗2log2dlog(1 /δ) log3mn
m2n2ϵ2 ≤c·s∗logd
mn. We also assume that
18there exists a constant k0such that log7(dmn)/mn≤1
(mn)k0, and that q=o(mn),
where qis the number of iterations for bootstrap q. The noise level is chosen as B4=
4L√logmcx(R+c0cx√
s∗)/√mn. Then, CU(α)computed in Algorithm 7 satisfies
sup
α∈(0,1)|P(M≤CU(α))−α|=o(1).
Theorem 6 has useful applications: we can obtain a good estimator of the α-quantile
ofUusing the bootstrap method and then use it to construct confidence intervals or
perform hypothesis testing. Numerical results will be presented in later chapters to
further support our claims.
5 Heterogeneous Federated Learning Setting
5.1 Methods and Algorithms
In this section, we consider a more general setting where the parameters of interest on
each machine are not identical, but they share some similarities. Specifically, we consider
the scenario where, on each machine i= 1,2, . . . , m, we assume a linear regression model:
Y=Xβ(i)+Wi,
where β(i)represents the true parameter on machine i. We assume that each Wiis
a vector whose coordinates follow a sub-Gaussian distribution: Wik∼subG (σ2),k=
1,2. . . , di.i.d. We also assume that each row of Xfollows a sub-Gaussian distribution
i.i.d. with mean zero and covariance matrix Σ. We further quantify the similarity of
eachβ(i)by assuming that that there exists a subset S ∈ { 1,2, . . . , d }with|S|=s0
satisfying β(i1)
S=β(i2)
Sfor any i1, i2∈ {1,2, . . . , m }.
A naive approach would be estimating each β(i)locally, as in the non-private setting.
However, in the context of federated learning, we can improve the estimation with a
sharper rate of convergence by exploiting similarities of the model across machines. To
achieve this, we decompose β(i)into the sum of two vectors, β(i)=u+vi, where u
captures the signals common to all β(i), and vicaptures the signals unique to each
machine.
We employ a two-stage procedure to estimate each β(i): in the first stage, we esti-
mate uusing Algorithm 2 with a sparsity level of ∥u∥0=s0indicating the number of
shared signals. In the second stage, we estimate vion the individual machine. Our final
estimation of β(i)is given by ˆβ(i)=ˆvi+ˆu. The procedure is summarized in Algorithm 8.
Similar to the previous section, we next address inference problems. Our algorithms
consist of two parts: the construction of coordinate-wise confidence intervals and simul-
taneous inference. We begin by describing the algorithm for coordinate-wise confidence
intervals in Algorithm 9.
In Algorithm 9, ˆΘjis the (ϵ, δ)-differentially private estimator of the j-th row of the
precision matrix of covariance matrix ˆΣ = 1 /(mn)Pm
i=1Pn
j=1XijX⊤
ij. We define the
19Algorithm 8: Differentially Private Sparse Linear Regression in Heterogeneous
Federated Learning Setting
Input : Number of machines m, dataset (yi,Xi)[i=1,...,m ], number of data on
each machine n, step size η0, privacy parameters ε, δ, noise scale B5,
number of iterations T, truncation level R, feasibility parameter C0,
initial value v0
i, sparsity level of similar vector s0, sparsity level s.
1Step 1: Estimate a s0sparse vector uusing Algorithm 2.
2Step 2: Estimate a s1:=s−s0sparse vector viwith samples (yi,Xi)on
machine iwith the following iterations from line 3-6.
3fortfrom 0toT−1do
4 Compute vt+0.5
i =vt
i−(η0/n)Pn
i=1(x⊤
ivt
i−ΠR(yi−x⊤
iu))xi;
5 vt+1
i= Π C0 
NoisyHT (vt+0.5
i,(yi,Xi), s, ε/T, δ/T, η0B5/n)
.
6end
7Step 3: Estimate β(i)byˆβ(i):=ˆvi+ˆu.
Output: ˆβ(i).
Algorithm 9: Differentially Private Coordinate-wise Confidence interval for βk
in Heterogeneous Federated Learning
Input : Number of machines m, dataset (Xi,Yi)[i=1,...,m ], number of data
points in each machine n, privacy parameters ε, δ, truncation level R,
sparsity s, estimated parameters ˆβ(i),ˆΘkfrom Algorithms 8 and 3,
and estimated eigenvalues ˆµs,ˆνsfrom Algorithm 5, constants ∆1, γ.
1Step 1: Generate a random variable E3from a Gaussian distribution
N(0,8∆2
1log(1.25/δ)/(n2ϵ2)).
2Step 2: Calculate de-biased estimation,
ˆβ(i,u)
k=ˆβ(i)
k+1
nPn
j=1(ˆΘ⊤
kXijΠR(yij)−ˆΘ⊤
kXijX⊤
ijˆβ(i)
k) +E3.
3Step 3: Calculate the confidence interval Jk(α).
Jk(α) =
ˆβ(i,u)
k−a−σΦ−1(1−α/2)√nr
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
nϵ2,
ˆβ(i,u)
k+a+σΦ−1(1−α/2)√nr
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
nϵ2
,
where ais defined in (5.1).
4Output: Return the final result Jk(α).
variable ain step 3 by
a:=2γˆµ2
s
ˆν2ss2
1log2dlog(1/δ) log3mn
m2n2ϵ2+2γˆµ2
s
ˆν2ss2
0log2dlog(1/δ) log3n
n2ϵ2.(5.1)
We then provide Algorithm 10 for the simultaneous inference problem. Similar to the
20previous chapter, we can perform simultaneous inference for each β(i)to build simulta-
neous confidence interval and hypothesis testing.
Algorithm 10: Private Bootstrap Method for Simultaneous Inference in Het-
erogeneous Federated Learning for Machine i∈ {1, . . . , m }
Input : Dataset (yi,Xi), number of data n, privacy parameters ε, δ, estimators
of parameters ˆβ(i),ˆΘfrom Algorithms 8 and 3, number of iterations
for Bootstrap q, quantile α, noise level B6. (RN: σ?)
1fortfrom 0toqdo
2Generate nindependent standard Gaussian random variables e1, . . . , e n.
3Calculate Ut=∥Privatemax ([σ√nPn
j=1ˆΘXijej]G, ϵ, δ, B 6)∥∞
4end
5Output: Compute the α-quantile CU(α)of(|U1|,|U2|, . . . ,|Uq|)forα∈(0,1).
Compared with Algorithm 7 introduced for simultaneous inference in homogeneous
federated learning, bootstrap algorithm in Algorithm 10 runs within the local machine
of interest. Using the output from Algorithm 10, we build a simultaneous confidence
interval for each β(i)
k(k∈G) using CU(α)by

ˆβ(i,u)
k−1√nCU(α),ˆβ(i,u)
k+1√nCU(α)
.
5.2 Theoretical Results
Inthissubsection, weprovidetheoreticalanalysisforthealgorithmsinheterogeneousfed-
erated learning settings. We begin our theoretical analysis with the estimation problem,
which resembles Theorem 3.
Intuitively, when β(i)are similar but not identical, federated learning can be used to
estimate their common elements and the remaining parameters can be estimated indi-
vidually on each machine. This results in a sharper rate of convergence as the estimation
of the common component ucan exploit the information from more data points. We
summarize the result in Theorem 7.
Theorem 7 Assume that the conditions in Theorem 5 hold. Further assume that for
Algorithm 8, ∥vi∥0=s1=s−s0for all i= 1, . . . , m,∥u∥0=s0,∥u∥2≤c0/2, and
∥vi∥2≤c0/2. Let B5=cx(2R+√s1c0cx). Then, for the output ˆβ(i)from Algorithm 8,
we have
∥ˆβ(i)−β(i)∥2
2≤c0s0logd
mn+c1s02logd2log(1/δ) log3mn
m2n2ϵ2+c2s1logd
n+c3s12logd2log(1/δ) log3n
n2ϵ2,
(5.2)
where c0, c1, c2, c3>0are some constants.
In the case where s0≪s1, i.e., the models are largely different across machines, the third
and fourth term on the right hand side of (5.2) dominates the estimation error, and the
estimation accuracy of β(i)via federated learning becomes closer to that with a single
21machine ( m= 1). In high level, this is because the information from other machines
is not helpful in the estimation when there exists a large dissimilarity of models across
machines. However, with a large s0≫s1, federated learning can leverage the similarity
of models to improve estimation accuracy. As a result, the rate in (5.2) becomes closer
to the rate in 4.2 for homogeneous federated learning setting when s0/s1→0.
We next present our results for the inference problems. To start we verify that the
output from Algorithm 9 is a asymptotic 1−αconfidence interval for β(i)
k.
Theorem 8 Assume the conditions in Theorem 3 hold and assume thats∗logd√n=o(1)
andmax(2γˆµ2
s
ˆν2ss2
1log2dlog(1 /δ) log3mn
m2n2ϵ2 ,2γˆµ2
s
ˆν2ss2
0log2dlog(1 /δ) log3n
n2ϵ2 ) =o(1). Let abe the variable
defined in (5.1). Then, for the de-biased estimator ˆβ(i,u)
kdefined in (4.1), the constructed
confidence interval is asympotically valid:
lim
n→∞P(β(i)
k∈Jk(α)) = 1 −α,
where
Jk(α) =
ˆβ(i,u)
k−a−ˆσΦ−1(1−α/2)√nr
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
nϵ2,
ˆβ(i,u)
k+a+ˆσΦ−1(1−α/2)√nr
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
nϵ2
Also, Jk(α)is(ϵ, δ)-differentially private.
Finally, we provide a statistical guarantee for Algorithm 10. Similar to the previous
section, we define Mas:
M=M(ˆβ(i,u)) = max
k∈G|√n(ˆβ(i,u)
k−β(i)
k)|.
Theorem 9 Assume that the conditions in Theorem 4 hold. We additionally assume that
s∗logd√n=o(1)and the privacy cost is dominated by the statistical error, i.e., there exists a
constant csuch thats∗2log2dlog(1 /δ) log3mn
m2n2ϵ2 ≤c·s∗logd
mnands∗2log2dlog(1 /δ) log3n
n2ϵ2 ≤c·s∗logd
n.
We also assume that there exists a constant k0such that log7(dn)/n≤1
nk0. The noise
level is chosen as B6= 2q
slogn
ncxc1. Then,
sup
α∈(0,1)|P(M≤CU(α))−α|=o(1).
Theorem 9 states that α-quantile of Mis asymptotically close to CU(α), which vali-
dates the 1−αsimultaneous confidence intervals based on CU(α)obtained by the boot-
strap method. This result allows us to perform simultaneous inference such as the con-
fidence intervals and hypothesis testing based on CU(α).
226 Simulations
In this section, we conduct simulations to investigate the performance of our proposed
algorithm as discussed in the preceding sections. Specifically, we explore the more com-
plex heterogeneous federated learning setting, where each machine operates on different
models yet exhibits similarities. Our simulations are divided into three main parts.
In Section 6.1, we present the simulation results for the coordinate-wise estimation
problem within a private federated setting, discussing the differences between the esti-
mated ˆβand the true β∗across various scenarios. We also examine the coverage of our
proposed confidence intervals. Section 6.2 extends the settings to simultaneous inference.
We generate simulateion simulation datasets as follows. First, we sample the data Xi,
fori= 1,2, . . . , m, where each Xifollows a Gaussian distribution with mean zero and
covariance matrix Σ. We set Σsuch that for each j, j′∈ {1,2, . . . , d },Σj,j′= 0.5|j−j′|.
On each machine, we assume a s∗-sparse unit vector β(i)with s∗=s0+s1, where s0is
the number of non-zero shared signals. For each β(i), we set the first s0shared elements
to1/√
s∗and additionally select machine-specific s1entries from the remaining d−s0
indices to be 1/√
s∗. We then compute Yi=Xiβ(i)+Wi, where each Wifollows a
Gaussian distribution N(0, σ2I)with σ= 0.5.
6.1 Estimation and Confidence Interval
In this subsection, we investigate the estimation accuracy and confidence interval cov-
erage of our algorithm for coordinate-wise inference. Namely, we consider the following
scenarios:
•Fix number of machines m= 15,ϵ= 0.8,δ= 1/(2mn),d= 800,s∗= 15
ands0= 6. Set the number of samples on each machine to be 4000,5000,6000,
respectively.
•Fix number of samples on each machine n= 4000,ϵ= 0.8,δ= 1/(2mn),d= 800,
s∗= 15ands0= 6. Set the number of machines mto be 5,10,15,
•Fix number of machines m= 15, number of samples on each machine n= 4000,
ϵ= 0.8,δ= 1/(2mn),d= 800. Set, s∗= 15, s0= 6,s∗= 10, s0= 4,s∗= 20, s0=
8, respectively.
•Fix number of machines m= 15, number of samples on each machine n= 4000,
ϵ= 0.8,δ= 1/(2mn),d= 800,s∗= 15. Set s0= 6,8,10, respectively.
•Fix number of machines m= 15, number of samples on each machine n= 4000,
δ= 1/(2mn),d= 800,s∗= 15ands0= 6. Set ϵ= 0.3,0.5,0.8respectively.
•Fix number of machines m= 15, number of samples on each machine n= 4000,
ϵ= 0.8,δ= 1/(2mn),s∗= 15ands0= 6. Set d= 600 ,800,1000, respectively.
For each setting, we report the average estimation error ∥ˆβ−β∗∥2
2among 50 replications.
Also, in each setting, we calculate the confidence interval with α= 0.95for each index
23ofβ∗using our proposed algorithm. To evaluate the quality of confidence interval, we
define covas the coverage of the confidence interval:
cov := d−1dX
i=1P[β∗
i∈Ji(α)].
We also define the coverage for non-zero and zero entries of β∗bycovSandcovSc,
respectively, where Sis the set of non-zero indices in β∗.
covS=|S|−1X
i∈SP[β∗
i∈Ji(α)],covSc=|Sc|−1X
i∈ScP[β∗
i∈Ji(α)].
We report the estimation error, coverage of true parameter and length of confidence
interval for each configuration listed above in Table 2:
Simulation Results
(n, m, d, s∗, s0, ϵ) Estimation Error
(Sd)cov covS covSclength
(3000,15,800,15,8,0.8) 0.0213 (0.0028) 0.940 0.929 0.940 0.0532
(4000,15,800,15,8,0.8) 0.0170 (0.0032) 0.945 0.960 0.944 0.0437
(5000,15,800,15,8,0.8) 0.0141 (0.0021) 0.940 0.945 0.940 0.0378
(4000,10,800,15,8,0.8) 0.0218 (0.0047) 0.945 0.945 0.945 0.0437
(4000,20,800,15,8,0.8) 0.0126 (0.0025) 0.944 0.941 0.944 0.0437
(4000,15,600,15,8,0.8) 0.0162 (0.0031) 0.946 0.933 0.946 0.0436
(4000,15,1000,15,8,0.8) 0.0191 (0.0027) 0.940 0.933 0.940 0.0439
(4000,15,800,15,4,0.8) 0.0188 (0.0032) 0.952 0.945 0.953 0.0420
(4000,15,800,15,12,0.8) 0.0137 (0.0016) 0.944 0.937 0.944 0.0462
(4000,15,800,10,8,0.8) 0.0105 (0.0017) 0.946 0.947 0.946 0.0389
(4000,15,800,20,8,0.8) 0.0243 (0.0036) 0.941 0.932 0.941 0.0497
(4000,15,800,15,8,0.5) 0.0240 (0.0038) 0.940 0.949 0.940 0.0550
(4000,15,800,15,8,0.3) 0.0943 (0.0281) 0.928 0.941 0.928 0.0792
Table 2: Table for Simulation Results of the private federated linear regression
From Table 2, we observe a consistent result with our theory. Namely, for the esti-
mation error, the error becomes small as ϵgets larger as we require less level of privacy.
24Also, more data points on each machine, more number of machines, smaller sparsity level
lead to better estimation accuracy. For confidence intervals, we observe that the coverage
is close to 0.95forcov,covS, and covSc, is and stable in different settings. To further
illustrate our claim, we pick the setting of (n, m, d, s, s 0, ϵ) = (4000 ,15,800,15,8,0.8)
and plot the confidence intervals versus the true value among 50 replications in Figure 3.
We randomly select 60 out of 800coordinates.
Fig 3: Confidence intervals for βkfor each coordinate krandomly selected from 800
coordinates. vertical axis stands for the value of βk. Red points stand for the true βk
while black points stand for the estimated βk. We mention that the result averaged over
50 iterations.
We also summarize our results in Figure 6.1, where we plot the estimation error
against the change in the number of samples, sparsity, and number of machines. For
the figure, we fixed m= 15,d= 800,s∗= 16,s0= 8, for the middle figure, we fixed
n= 4000,m= 15,d= 800,ϵ= 0.5, and for the right figure, we fixed d= 800,s∗= 16,
s0= 8,ϵ= 0.5. The error is averaged over 200replications.
25Fig 4: Plot for the estimation results. Left:Log estimation error with different number
of samples n,Middle: Log estimation error with different sparsity s∗,Right: Log
estimation error with different number of machines m.
From the left figure in Figure 6.1, we observe the decreasing error when we increase
n. When the privacy parameter ϵis large, we have better estimation error. From the
middle figure, we observe that as the sparsity level sgrows, the estimation error also
increases. Also, when the sparsity for the shared signal s0becomes large, the estimation
error also becomes large. In the right figure, we observe a consistent decrease of error
when we increase the number of machines. All these figures support Theorem 7.
6.2 Simultaneous Inference
In this subsection, we investigate our proposed algorithms for simultaneous inference
problems. We aim to build a simultaneous confidence interval when α= 0.05under
three settings: G={1,2, . . . , d },G=S, and G=Sc. For each setting, we repeat 50
simulations and report the coverage and length of the confidence intervals. The results
are shown in Table 5.
From simulation results, we can observe that our proposed simultaneous confidence
interval mostly exhibit over-coverage for G=Sc, and under-coverage for G=S. This
pattern has also been observed in previous works addressing simultaneous inference [38,
42]. Therefore, this could be attributed to the inherent nature of simultaneous inference
rather than to algorithmic reasons.
7 Discussions and Future Work
In this paper, we study the high-dimensional estimation and inference problems within
the context of federated learning. In scenarios involving an untrusted central server, our
findings reveal that accurate estimation is infeasible, as the rate of convergence is ad-
versely proportional to the dimension d. Conversely, in the trusted central server setting,
we developed algorithms that achieve an optimal rate of convergence. We also explored
26Simulation Results for Simultaneous Inference
(n, m, d, s∗, s0, ϵ) cov covS covSclen(cov)len(covS)len(covSc)
(3000,15,800,15,8,0.8) 0.981 0.883 0.983 0.091 0.066 0.091
(4000,15,800,15,8,0.8) 0.985 0.910 0.987 0.079 0.057 0.079
(5000,15,800,15,8,0.8) 0.987 0.875 0.990 0.071 0.051 0.071
(4000,10,800,15,8,0.8) 0.989 0.894 0.991 0.079 0.057 0.079
(4000,20,800,15,8,0.8) 0.983 0.898 0.986 0.079 0.057 0.079
(4000,15,600,15,8,0.8) 0.993 0.878 0.995 0.077 0.057 0.077
(4000,15,1000,15,8,0.8) 0.994 0.878 0.997 0.080 0.057 0.080
(4000,15,800,15,4,0.8) 0.983 0.772 0.993 0.079 0.057 0.079
(4000,15,800,15,12,0.8) 0.975 0.957 0.974 0.079 0.058 0.079
(4000,15,800,10,8,0.8) 0.986 0.976 0.985 0.079 0.055 0.079
(4000,15,800,20,8,0.8) 0.974 0.850 0.982 0.078 0.059 0.078
(4000,15,800,15,8,0.5) 0.940 0.882 0.940 0.103 0.083 0.102
(4000,15,800,15,8,0.3) 0.953 0.789 0.975 0.127 0.097 0.126
Table 5: Simulation results of the private simultaneous inference in different settings.
27inference challenges, detailing methodologies for both point-wise confidence intervals and
simultaneous inference.
There are several extensions for further research. Currently, our models presume that
each machine operates under a linear regression framework. We can possibly expand
our algorithm to accomodate more complex models, such as generalized linear models,
classification models, or broader machine learning models. Moreover, an interesting
extension would be to refine our understanding of model similarity across machines.
Although Section 5 currently bases model similarity on L0norms, reflecting non-sparse
patterns, futurestudiescouldexplore Lpnorm-basedsimilarities, particularlyfocusingon
L1andL2norms, to enhance our approach to heterogeneous federated learning settings.
References
[1] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov,
Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings
of the 2016 ACM SIGSAC conference on computer and communications security ,
pages 308–318, 2016.
[2] Jayadev Acharya, Clément L Canonne, and Himanshu Tyagi. General lower bounds
for interactive high-dimensional estimation under information constraints. arXiv
preprint arXiv:2010.06562 , 2020.
[3] Naman Agarwal, Ananda Theertha Suresh, Felix Yu, Sanjiv Kumar, and H Brendan
Mcmahan. cpsgd: Communication-efficient and differentially-private distributed
sgd.arXiv preprint arXiv:1805.10559 , 2018.
[4] Leighton Pate Barnes, Wei-Ning Chen, and Ayfer Özgür. Fisher information under
local differential privacy. IEEE Journal on Selected Areas in Information Theory ,
1(3):645–659, 2020.
[5] Leighton Pate Barnes, Yanjun Han, and Ayfer Ozgur. Lower bounds for learning
distributions under communication constraints via fisher information. Journal of
Machine Learning Research , 21(236):1–30, 2020.
[6] Andrea Bittau, Úlfar Erlingsson, Petros Maniatis, Ilya Mironov, Ananth Raghu-
nathan, David Lie, Mitch Rudominer, Ushasree Kode, Julien Tinnes, and Bernhard
Seefeld. Prochlo: Strong privacy for analytics in the crowd. In Proceedings of the
26th symposium on operating systems principles , pages 441–459, 2017.
[7] Mark Braverman, Ankit Garg, Tengyu Ma, Huy L Nguyen, and David P Woodruff.
Communication lower bounds for statistical estimation problems via a distributed
data processing inequality. In Proceedings of the forty-eighth annual ACM sympo-
sium on Theory of Computing , pages 1011–1020, 2016.
28[8] T Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates
of convergence for parameter estimation with differential privacy. arXiv preprint
arXiv:1902.04495 , 2019.
[9] T Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy in gen-
eralized linear models: Algorithms and minimax lower bounds. arXiv preprint
arXiv:2011.03900 , 2020.
[10] Victor Chernozhukov, Denis Chetverikov, and Kengo Kato. Gaussian approxima-
tions and multiplier bootstrap for maxima of sums of high-dimensional random
vectors.The Annals of Statistics , 41(6):2786–2819, 2013.
[11] John Duchi and Ryan Rogers. Lower bounds for locally private estimation via
communication complexity. In Conference on Learning Theory , pages 1161–1191.
PMLR, 2019.
[12] Cynthia Dwork and Vitaly Feldman. Privacy-preserving prediction. In Conference
On Learning Theory , pages 1693–1702. PMLR, 2018.
[13] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise
to sensitivity in private data analysis. In Theory of cryptography conference , pages
265–284. Springer, 2006.
[14] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential
privacy. Foundations and Trends in Theoretical Computer Science , 9(3-4):211–407,
2014.
[15] Cynthia Dwork, Adam Smith, Thomas Steinke, and Jonathan Ullman. Exposed! a
survey of attacks on private data. Annual Review of Statistics and Its Application ,
4:61–84, 2017.
[16] Cynthia Dwork, Weijie J Su, and Li Zhang. Differentially private false discovery
rate control. arXiv preprint arXiv:1807.04209 , 2018.
[17] Úlfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Shuang
Song, Kunal Talwar, and Abhradeep Thakurta. Encode, shuffle, analyze privacy re-
visited: Formalizations and empirical evaluation. arXiv preprint arXiv:2001.03618 ,
2020.
[18] Ankit Garg, Tengyu Ma, and Huy Nguyen. On communication cost of distributed
statistical estimation and dimensionality. Advances in Neural Information Process-
ing Systems , 27:2726–2734, 2014.
[19] Robin C Geyer, Tassilo Klein, and Moin Nabi. Differentially private federated learn-
ing: A client level perspective. arXiv preprint arXiv:1712.07557 , 2017.
29[20] Antonious Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and
Ananda Theertha Suresh. Shuffled model of differential privacy in federated learn-
ing. InInternational Conference on Artificial Intelligence and Statistics , pages2521–
2529. PMLR, 2021.
[21] Yanjun Han, Ayfer Özgür, and Tsachy Weissman. Geometric lower bounds for
distributed parameter estimation under communication constraints. In Conference
On Learning Theory , pages 3163–3188. PMLR, 2018.
[22] Torsten Hothorn, Frank Bretz, and Peter Westfall. Simultaneous inference in gen-
eral parametric models. Biometrical Journal: Journal of Mathematical Methods in
Biosciences , 50(3):346–363, 2008.
[23] Rui Hu, Yuanxiong Guo, Hongning Li, Qingqi Pei, and Yanmin Gong. Personal-
ized federated learning with differential privacy. IEEE Internet of Things Journal ,
7(10):9530–9539, 2020.
[24] Adel Javanmard and Andrea Montanari. Confidence intervals and hypothesis test-
ing for high-dimensional regression. The Journal of Machine Learning Research ,
15(1):2869–2909, 2014.
[25] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Ben-
nis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode,
Rachel Cummings, et al. Advances and open problems in federated learning. Foun-
dations and Trends ®in Machine Learning , 14(1–2):1–210, 2021.
[26] JakubKonecy, HBrendanMcMahan, FelixXYu, PeterRichtárik, AnandaTheertha
Suresh, and Dave Bacon. Federated learning: Strategies for improving communica-
tion efficiency. arXiv preprint arXiv:1610.05492 , 2016.
[27] Jason D Lee, Qiang Liu, Yuekai Sun, and Jonathan E Taylor. Communication-
efficient sparse regression. The Journal of Machine Learning Research , 18(1):115–
144, 2017.
[28] Mengchu Li, Ye Tian, Yang Feng, and Yi Yu. Federated transfer learning with
differential privacy. arXiv preprint arXiv:2403.11343 , 2024.
[29] Sai Li, T Tony Cai, and Hongzhe Li. Transfer learning for high-dimensional lin-
ear regression: Prediction, estimation, and minimax optimality. arXiv preprint
arXiv:2006.10593 , 2020.
[30] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learn-
ing: Challenges, methods, and future directions. IEEE signal processing magazine ,
37(3):50–60, 2020.
[31] Andrew Lowy and Meisam Razaviyayn. Private federated learning without a trusted
server: Optimalalgorithmsforconvexlosses. arXiv preprint arXiv:2106.09779 , 2021.
30[32] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Aguera y Arcas. Communication-efficient learning of deep networks from
decentralized data. In Artificial intelligence and statistics , pages 1273–1282. PMLR,
2017.
[33] Brendan McMahan and Abhradeep Thakurta. Federated learning with formal dif-
ferential privacy guarantees. Google AI Blog , 2022.
[34] H Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning
differentially private recurrent language models. arXiv preprint arXiv:1710.06963 ,
2017.
[35] Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially pri-
vate selection. In 2017 IEEE 58th Annual Symposium on Foundations of Computer
Science (FOCS) , pages 552–563. IEEE, 2017.
[36] Kunal Talwar, Abhradeep Thakurta, and Li Zhang. Nearly-optimal private lasso. In
Proceedings of the 28th International Conference on Neural Information Processing
Systems-Volume 2 , pages 3025–3033, 2015.
[37] Stacey Truex, Ling Liu, Ka-Ho Chow, Mehmet Emre Gursoy, and Wenqi Wei. Ldp-
fed: Federated learning with local differential privacy. In Proceedings of the Third
ACM International Workshop on Edge Systems, Analytics and Networking , pages
61–66, 2020.
[38] Sara Van de Geer, Peter Bühlmann, Ya’acov Ritov, and Ruben Dezeure. On asymp-
totically optimal confidence regions and tests for high-dimensional models. 2014.
[39] Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin,
Tony QS Quek, and H Vincent Poor. Federated learning with differential privacy:
Algorithms and performance analysis. IEEE Transactions on Information Forensics
and Security , 15:3454–3469, 2020.
[40] Manuel Wiesenfarth, Tatyana Krivobokova, Stephan Klasen, and Stefan Sperlich.
Direct simultaneous inference in additive models and its application to model un-
dernutrition. Journal of the American Statistical Association , 107(500):1286–1296,
2012.
[41] Yang Yu, Shih-Kang Chao, and Guang Cheng. Distributed bootstrap for simulta-
neous inference under high dimensionality. Journal of Machine Learning Research ,
23(195):1–77, 2022.
[42] Xianyang Zhang and Guang Cheng. Simultaneous inference for high-dimensional
linear models. Journal of the American Statistical Association , 112(518):757–768,
2017.
31[43] Yuchen Zhang, John C Duchi, Michael I Jordan, and Martin J Wainwright.
Information-theoretic lower bounds for distributed statistical estimation with com-
munication constraints. In NIPS, pages 2328–2336. Citeseer, 2013.
[44] Yuchen Zhang, Martin J Wainwright, and John C Duchi. Communication-efficient
algorithms for statistical optimization. Advances in neural information processing
systems, 25, 2012.
[45] Zhe Zhang. Differential privacy in statistical learning. ProQuest Dissertations and
Theses, page 156, 2023.
[46] Zhe Zhang and Linjun Zhang. High-dimensional differentially-private em algorithm:
Methods and near-optimal statistical guarantees. arXiv preprint arXiv:2104.00245 ,
2021.
32A Proof of main results
A.1 Proof of Theorem 1
We show the proof of the lower bound of the estimation. The main idea of the proof is
as follows, we will first assume that in the general case where each data point on each
machine follows a general distribution pθ, then we will further assume some conditions
of this distribution, and prove that the lower bound of the mean estimation could be
attained under these conditions. Finally, we will show that under the assumptions that
the data points follow the normal distribution, the specific conditions hold, thus we could
finish the proof.
To start this proof, we first introduce the perturbation space A={−1,1}k, where
kis a pre-chosen constant and associate each parameter θwith a∈ Aand refer the
distribution pθaspa. We characterize the distance between two parameters θandθ′by
the hamming distance of zandz′, such approach will be compatible with the Assouad’s
method, as will be shown later in the proof. We note that when the hamming distance of
aanda′get smaller, it indicts that the distance between θandθ′becomes closer. Also,
for each a∈ A, we further denote a⊕i∈ Aas the vector which flips the sign of the i-th
coordinate of a. Then, we state below conditions:
Condition 1 For every a∈ Aandi∈[k], it holds that pa⊕i≪pa. Further, there exist
qa,iand measurable functions ϕa,i:X → Rsuch that |qa,i| ≤α, which qis a constant
and:dpa⊕i
dpa= 1 + qa,iϕa,i.
Condition 2 For all a∈ Aandi, j∈[k],Epa[ϕa,iϕa,j] =1i=j.
Condition 3 There exists some σ≥0such that, for all a∈ A, the random vector
ϕa(X) = ( ϕa,i(X))i∈[k]∈Rkisσ2-sub-Gaussian for X∼pawith independent coordi-
nates.
The above conditions characterize the distribution pa, we will later verify that the Gaus-
sian distribution could satisfy the above conditions in the later proof. Then, we state
our first claim.
Corollary 1 For each coordinate of the A, for any i= 1,2, . . . , k, fix τ=P(Ai=
1)∈(0,1/2]. Let X1, . . . , X mbe the inputs on the local servers, i.i.d. with common
distribution p⊗n
A. Let Zmbe the information sent from all the local servers to the central
machine generated through the channel W. Then, if the condition 1 satisfies, there exists
a constant c, we have:
 
1
kkX
i=1dTV(pZm
+i,pZm
−i)!2
≤c
kq2mn2max
a∈AkX
i=1Z
YEp⊗n
a[ϕa,i(X)W(z|X)]2
Ep⊗n
a[W(z|X)]dµ,
where pZm
+i=E[pZm
A|Ai= +1],pZm
−i=E[pZm
A|Ai=−1].
33The proof of the above corollary is in appendix B.1. The above corollary characterizes
the difference between the distribution of pZm
+iandpZm
−i, which is the difference between
the distribution of the information about the each coordinate of A, which could be seen
as the information between YandA, namely, the information between the information
and the parameters.
In the precious corollary, we just assumed a general channel W, in the following
corollary, we could further specifies the above corollary when the channel W, be a ϵ-
differentially private constraint channel Wprivand we could further simplify the upper
bound in Corollary 1.
Corollary 2 IfWprivbe a privacy constraint channel and for any family of distributions
{pa, a∈ {− 1,1}k}satisfying condition 1 and condition 2. With the same notations as
Corollary 1 we have:
 
1
kkX
i=1dTV(pZm
+i,pZm
−i)!2
≤7
kmn2q2(enϵ2−1)
The proof of the above corollary could be found in appendix B.2. The above corollary
focusontheupperboundof1
kPk
i=1dTV(pZm
+i,pZm
−i),inthenextcorollary,wewillfocuson
the lower bound, which is an Assouad-type bound. We first introduce another condition:
Condition 4 Fixp∈[1,∞). Let ρbe the ℓploss between the true parameter and the
estimation. Then, for every a, a′∈ A ∈ {− 1,+1}k, the below inequalities hold:
lp(θa, θa′)≥4ρdHam(a, a′)
τk1/p
,
where dHam(a, a′)denotes theHamming distance withdefinition dHam(a, a′) =Pk
i=11(ai̸=a′
i),
andτ=P(ai= 1)∈(0,1/2]for each coordinate ai.
The above condition characterizes the connection between θwith the perturba-
tion space. With the above assumption, we could further obtain the lower bound of
1
kPk
i=1dTV(pZm
+i,pZm
−i):
Corollary 3 Letp≥1and assume that {pa, a∈ A},τ∈[0,1/2]satisfy Condition 4.
LetAbe a random variable on {−1,1}kwith distribution Rad(τ)⊗k. Suppose that ˆθ
constitutes an (n, ρ)-estimator of the true parameter θ∗under lploss and P[pA∈ PΘ]≥
1−τ/4. Then the below inequality holds:
1
kkX
i=1dTV(pZm
+i,pZm
−i)≥n
4,
where pZm
+i=E[pZm
A|Ai= +1],pZm
−i=E[pZm
A|Ai=−1].
34The proof of the above corollary could be found in appendix B.3. In the following
proof, we are going to verify that the Gaussian distribution satisfies all the above con-
ditions, thus the result in Corollary 2 and Corollary 3 holds. Then, according to these
two corollaries, we will present the lower bound for the mean estimation in the high-
dimensional federated learning setting.
For the parameters, we could fix p= 2,k=d,A={−1,+1}d. For the probability
where τ=P(ai) = 1, we fix τ=s
2d. Let φdenote the probability density function
of the standard Gaussian distribution N(0,I). We first suppose that, for some ρ∈
(0,1/8], there exists an (n, ρ)-estimator for the true parameter µunder ℓploss. Then,
if we have ρ2≥s/n, then we could finish the proof. Otherwise, we fix a parameter
γ=4ρ√
s/2∈(0,1/2], this is possible with a choice of s, the sparsity level. We could
design the parameter, the mean of the Gaussian distribution µandAby the formula:
µa=γ(a+1d), where a∈ A. Then, we could verify that P[∥µa∥0≤2τd]≥1−τ/4,
where ∥µa∥0=Pd
i=11ai=1=∥a∥+. From the definition of Gaussian density, for a∈ A,
we have:
pa(x) =e−γ2∥µa∥2
2/2·eγ⟨x,a+1d⟩·φ(x).
Therefore, for a∈ Aandi∈[d], we have
pa⊕i(x) =e−2γxiaie2γ2ai·pa(x) = (1 + q·ϕa,i(x))·pa(x),
where q=p
e4γ2−1andϕa,i(x) =1−e−2γxiaie2γ2ai√
e4γ2−1. By using the Gaussian moment-
generating function, we could verify that, for i̸=j,
Epa[ϕa,i(X)] = 0 ,Epa[ϕa,i(X)2] = 1,andEpa[ϕa,i(X)ϕa,j(X)] = 0 ,
so that the condition 1 and condition 2 are satisfied. Here, notice that in the proof
of Corollary 1, we require that |q·ϕa,i(x)|=C/nwhere Cis a constant, we could
verify that since ρ≤c·p
s/n, then γ≤c√nfrom the definition of γ, Then we have
|q·ϕz,i(x)| ≤c0|γ2−γxi| ≤c0/n, which could verify the condition for corollary 1. Also,
by the choice of γandρ, it is easy to verify that condition 4 also holds with:
ℓ2(µ(pa), µ(pa′)) = 4 ρ·r
dham(a, a′)
τd.
Thus, all the conditions mentioned above have been verified. Then, we could finish
the proof of our lower bound. Combining the result of corollary 2 and corollary 3, we get
the result below:
n2d≤cmn2q2(enϵ2−1),
where cis a constant. Also, notice that q2=e4γ2−1≤8γ2holds since γ≤1/2, we
could find a constant c0, it follows that
ρ2≥c0·s·d
mnϵ2,
35From the choice of ρ, we could claim that ρ≥Ω(q
sd
mnϵ2∧1), then we could obtain our
lower bound, which finished the proof. □
A.2 Proof of Theorem 2
In the proof of Theorem 2, we will design a mechanism to get an estimation of the
parameter and then we obtain the upper bound of ∥µ−ˆµ∥2
2. The overall mechanism is
designed as follows: we first calculate the mean for ndata points on each machine. Then,
we transform the Gaussian mean to Bernoulli mean according to the sign of the Gaussian
mean motivated by the Algorithm 2 discussed in [2], l-bit protocol for estimating product
of Bernoulli family.
Then, we could use the ϵ-local differentially private mechanism to achieve mean es-
timation for the product of Bernoulli family in the federated learning setting. After
obtaining the estimation, we could convert the estimated Bernoulli mean back to Gaus-
sian mean estimation.
First, for each data point on the machine, it follows the distribution of N(µ,Id).
Then for the mean on i-th machine, the mean ¯Xifollows a distribution of N(µ,1/nI).
Then, we could convert it to a Bernoulli variable Z, where Zi= 1when ¯Xij>0and
Zi=−1when ¯Xij≤0. Then the mean of Z, which denote as vis:
vi= 2P(Xi>0)−1 = Erf√nµi√
2
,
for each coordinate of v. Suppose the estimation of vis denoted by ˆv, then suppose the
estimation ˆµis given by ˆµi=√
2√nerf−1( ˆvi), we could find such relationship:
∥µ−ˆµ∥2
2=dX
i=1|µi−ˆµi|2=2
n·dX
i=1|Erf−1(vi)−Erf−1(ˆvi)|2≤c·1
n·dX
i=1|vi−ˆvi|2,
(A.1)
where cis a constant. The last inequality comes from the Lipschitz condition of a Erf
function. Then, we could get the upper bound for the Bonoulli mean estimation directly
from Theorem 3 in [2], where
∥v−ˆv∥2
2≤c·d·s
mϵ2,
where ϵis the privacy parameter, mis the number of machines. Combining the last
two inequalities (A.1) and (A.2), we could get the upper bound for the mean Gaussian
estimation:
∥µ−ˆµ∥2
2≤c·s·d
mnϵ2,
which finished the proof. □
36A.3 Proof of Theorem 3
It is not difficult to observe that the convergence rate would be the same as in the
non-federated learning setting. We denote Lnas the sample loss function and Lbe the
population level. In the estimation of β,L(β) =∥Y−Xβ∥2
2andLnis the sample
version. In the estimation of Θk,L(Θk) =1
2Θ⊤
kΣΘk− ⟨ej,Θk⟩. We start from the
estimation of βand the estimation of Θis the same. In this proof, we use n0to refer
the total number of samples n0=m·n. Then, it holds that:
Lemma A.1 Under assumptions of Theorem 5, it holds that:
8νs∥βt−ˆβ∥2
2≤ ⟨∇L n(βt)− ∇L n(ˆβ),βt−ˆβ⟩ ≤8µs∥βt−ˆβ∥2
2.(A.2)
Proof:From direct calculation, we could obtain that:
⟨∇L n(βt)−∇L n(ˆβ),βt−ˆβ⟩= 2(βt−ˆβ)TˆΣ(βt−ˆβ)≤2µs+s∗∥βt−ˆβ∥2
2≤2µ2s∥βt−ˆβ∥2
2
The last inequality is according to the choice of ssuch that s∗≤s. Then, we also have
µ2s≤4µs. Thus we have obtained the right hand side of the inequality. By a similar
approach, we could also obtain the left hand side.
Lemma A.2 Under assumptions of Theorem 5, it holds that there exists an absolute
constant ρsuch that
Ln(βt+1)− L n(ˆβ)≤
1−νs
24µs
Ln(βt)− L n(ˆβ)
+c3
X
i∈[s]∥wt
i∥2
∞+∥˜wt
St+1∥2
2
,
(A.3)
where c3is a constant number such that c3= max( µs(72·8µs+ 13) ,68µs+ 2/3)
Notice that wi, ware injected from the NoisyHT algorithm. The proof of the above
lemma follows from the result in Lemma 8.3 from [8]. Then, we could start the proof by
iterating (A.3) over t. Denote Wt=c3P
i∈[s]∥wt
i∥2
∞+∥˜wt
St+1∥2
2
to obtain
Ln0(βT)− L n0(ˆβ)≤
1−νs
24µsT
Ln0(β0)− L n0(ˆβ)
+T−1X
k=0
1−1
ρL2T−k−1
Wk
≤
1−νs
24µsT
4µc2
0+T−1X
k=0
1−νs
24µsT−k−1
Wk. (A.4)
The second inequality is a consequence of the upper inequality in (A.2) and the ℓ2bounds
ofβ0andˆβ. We can also bound Ln0(βT)− L n0(ˆβ)from below by the lower inequality
in (A.2):
Ln0(βT)− L n0(ˆβ)≥ L n0(βT)− L n0(β∗)≥4νs∥βT−β∗∥2
2− ⟨∇L n0(β∗),β∗−βT⟩.
(A.5)
37Now (A.4) and (A.5) imply that, with T= (ρL2) log 
8c2
0Ln0
,
4νs∥βT−β∗∥2
2≤ ∥∇L n0(β∗)∥∞√
s+s∗∥β∗−βT∥2+1
n0+T−1X
k=0
1−νs
24µsT−k−1
Wk.
(A.6)
≤ ∥∇L n0(β∗)∥∞√
s+s∗∥β∗−βT∥2+1
n0+24µs
νsmax
kWk.(A.7)
Thus,
∥βT−β∗∥2
2≤k·s∗logd
n0+µs
ν2smax
kWk.
In the above inequality, kis a constant. Then, we could calculate the upper bound of
Wk. From the result of tail bound of Laplace random variables, we could find that with
high probability that Wk≤c4s2log2dlog(1/δ) logn3/n2ϵ2), where c4= max( µs(9µs+
1/4),17/16µs+ 1/96). Then, we have with high probability:
∥βT−β∗∥2
2≤k·slogd
n0+6c4µs
ν2ss2log2dlog(1/δ) logn3
0/n2
0ϵ2.
Similarly, we could obtain the same result for the estimation of ˆΘk, which finishes the
proof.
A.4 Proof of Theorem 4
Thestructureoftheproofconsistofthreepart, thefirstpartistoshowthatouralgorithm
provides an (ϵ, δ)-differentially private confidence interval. In the second part, we will
show that ˆβkis a consistent estimator of true βk, which is unbiased. In the last part, we
will show that the (1−α)confidence interval is asymptotically valid. Before we start the
first part, let us first analyze cx:
According to the assumptions of the theorem, we have learnt that for each row of X,
xΣ−1/2is sub-Gaussian with κ=∥Σ−1/2x∥ψ2. Then according to the properties of
sub-Gaussian random variables, we have: ∥xΣ−1/2∥∞≤3p
2κ2logdwith probability
1−d−2. Then for each element of xi,i= 1,2, . . . , d, we have:
xi=e⊤
jx=e⊤
jΣ1/2Σ−1/2x
Thus,
xi≤ ∥e⊤
jΣ1/2∥1∥Σ−1/2x∥∞≤ ∥Σ1/2∥2∥Σ−1/2x∥∞
Then, with probability 1−d−2, we have xi≤3p
2Lκ2logd. By a union bound, we could
have with probability 1−d−1,∥x∥∞≤3p
2Lκ2logd. By the choice of cxin the theorem,
we have ∥x∥∞≤cxwith a high probability.
Then, we could verify that the confidence interval is (ϵ, δ)-differentially private. From
[8], we could obtain that the output ˆβuis(ϵ, δ)-DP. In a similar manner, we could also
38verify that the output ˆΘkis also (ϵ, δ)-DP. Thus, for two adjacent data sets (X,Y)and
(X′,Y′)which differ by one data (xij, yij)and(x′
ij, y′
ij), we have:
|1
n0(ˆΘ⊤
kxijΠR(yij)−ˆΘ⊤
kxijx⊤
ijˆβu)| ≤1
n0|ˆΘ⊤
kxijΠR(yij)|+1
n0|ˆΘ⊤
kxijx⊤
ijˆβu|
≤1
n0|ˆΘ⊤
kxij||ΠR(yij)|+1
n0|ˆΘ⊤
kxij||x⊤
ijˆβu|
≤1
n0√sc1cxR+1
n0sc0c1c2
x
Thus,
|1
n0(ˆΘ⊤
kxijΠR(yij)−ˆΘ⊤
kxijx⊤
ijˆβu)−1
n0(ˆΘ⊤
kx′
ijΠR(y′
ij)−ˆΘ⊤
kx′
ijx′⊤
ijˆβu)|
=|1
n0(ˆΘ⊤
kxijΠR(yij)−ˆΘ⊤
kxijx⊤
ijˆβu)|+|1
n0(ˆΘ⊤
kx′
ijΠR(y′
ij)−ˆΘ⊤
kx′
ijx′⊤
ijˆβu)|
≤2
n0√sc1cxR+2
nsc0c1c2
x
Denote ∆1=√sc1cxR+sc0c1c2
x. Thus, if Ekfollows N(0,8∆2
1/n2
0ϵ2log(1.25/δ)),ˆβjis
(ϵ, δ)-DP. For the term ˆΘ⊤
kˆΣˆΘk, we could obtain that:
ˆΘ⊤
kˆΣˆΘk=1
n0nX
i=1ˆΘ⊤
kxijx⊤
ijˆΘk=1
n0nX
i=1(ˆΘ⊤
kxij)2
Thus, for two adjacent data sets XandX′differ by one data xijandx′
ij, we have:
|ˆΘ⊤
kˆΣˆΘk−ˆΘ⊤
kˆΣ′ˆΘk| ≤1
n0(ˆΘ⊤
kxij)2+1
n0(ˆΘ⊤
kx′
ij)2
By Holder inequality and Cauchy inequality, we have |ˆΘ⊤
kxij| ≤√sc1cx, thus we have:
|ˆΘ⊤
kˆΣˆΘk−ˆΘ⊤
kˆΣ′ˆΘk| ≤2
n0(√sc1cx)2=2
n0sc2
1c2
x
Denote ∆2=sc2
1c2
x. Then,let E′followsaGaussiandistributionof N(0,8∆2
2/n2m2ϵ2log(1.25/δ)).
We could claim that ˆΘ⊤
kˆΣˆΘk+E′is(ϵ, δ)-differentially private.
We start the second part of the proof. First, with probability 1−k0exp(−k1n0), we have
ΠR(yi) =yifor each i= 1,2, . . . , d, so we could decompose ˆβkby the following approach:
ˆβk=ˆβu
k+1
n0ˆΘ⊤
kX⊤(Xβ+W−Xˆβu) +Ek
=ˆβu
k+1
n0ˆΘ⊤
kX⊤X(β−ˆβu) +1
n0ˆΘ⊤
kX⊤W+Ek
=βk+ (ˆΘ⊤
kˆΣ−ek)(β−ˆβu) +1
n0ˆΘ⊤
kX⊤W+Ek
39Thus, we have:
√n0(ˆβj−βj) =√n0(ˆΘ⊤
kˆΣ−e⊤
k)(β−ˆβu)| {z }
A.8.1+1√n0ˆΘ⊤
kX⊤W
|{z }
A.8.2+√n0Ek|{z}
A.8.3(A.8)
We will analyze the three terms in (A.8) one by one. For the first term, we could further
decompose this term as:
√n0(ˆΘ⊤
kˆΣ−e⊤
k)(β−ˆβu) =√n0(ˆΘ⊤
kˆΣ−Θ⊤
kˆΣ+Θ⊤
kˆΣ−e⊤
k)(β−ˆβu)
=√n0(ˆΘ⊤
kˆΣ−Θ⊤
kˆΣ)(β−ˆβu) +√n0(Θ⊤
kˆΣ−e⊤
k)(β−ˆβu)
(A.9)
Forthefirsttermin(A.9),wecouldfurtherdecomposethistermfrom ˆΣ=1
mnPm
i=1Pn
j=1xijx⊤
ij:
√n0(ˆΘ⊤
kˆΣ−Θ⊤
kˆΣ)(β−ˆβu) =√n0(ˆΘ⊤
k−Θ⊤
k)ˆΣ(β−ˆβu)
≤√n0λs(ˆΣ)∥ˆΘk−Θk∥2|β−ˆβu∥2 (A.10)
In the last inequality, we use λsto denote the largest s-restricted eigenvalue of the
covariance matrix ˆΣ. From Theorem 3, we could obtain that there exists a constant c
such that:
∥β−ˆβu∥2
2≤c·σ2s∗logd
n0+(s∗logd)2log(1/δ) log3n0
n2
0ε2
Also, for the output ˆΘk, we could have the similar result:
∥ˆΘk−Θk∥2
2≤c·σ2s∗logd
n0+(s∗logd)2log(1/δ) log3n0
n2
0ε2
Combining (A.4) and (A.4), we could obtain that
√n0(ˆΘ⊤
kˆΣ−Θ⊤
kˆΣ)(β−ˆβu) =os∗logd√n0
=o(1)
Then, we could focus on the second term of (A.9). We first introduce the following
lemma:
Lemma A.3 (Lemma 6.2 in [24]) For the vector Θ⊤
kˆΣ−ek. Denote κ=∥Σ−1/2X1∥ϕ2,
then with probability 1−2d1−a2/24e2κ4L2, we have:
∥Θ⊤
kˆΣ−ek∥∞≤ar
logd
n0
Thus, for the second term of (A.9), we have:
√n0(Θ⊤
kˆΣ−e⊤
j)(β−ˆβu)≤√n0∥Θ⊤
kˆΣ−e⊤
k∥∞∥β−ˆβu∥1
40≤k√n0r
logd
n0√
s∗∥β−ˆβu∥2
≤k·p
s∗logd·r
s∗logd
n0=o(1) (A.11)
Combine the result from (A.4), (A.11) to (A.9), we could obtain that the first term of
(A.8)is o(1). Wecouldalsoanalyzethethirdtermof(A.8),√n0Ek∼N(0,8∆2
1log(1.25/δ)/n0ϵ2).
Then, by the definition of ∆1, we have 8∆2
1log(1.25/δ)/n0ϵ2∼s∗2log2dlog(1 .25/δ)
n0ϵ2 =o(1)
from the assumption. Also, we notice that E′=N(0, c·s∗2log2dlog(1 .25/δ)
n2
0ϵ2 ). By the
concentration of Gaussian distribution, we also have that E′=o(1).
Finally, we analyze the term1√n0ˆΘ⊤
jX⊤W. From our definition, Wis sub-Gaussian
random noise. Then, from the central limit theorem, we could conclude that:
1√n0ˆΘ⊤
jX⊤W→N(0, σ2ˆΘ⊤
jˆΣˆΘj)
Thus,√n0(ˆβj−βj) =1√n0ˆΘ⊤
jX⊤W+√n0Ek∼N(0, σ2ˆΘ⊤
jˆΣˆΘj+o(1)). Also, from
lemma 4.1, we could claim that under our assumptions, ˆσ2=σ2+o(1). We could get
the result where with high probability,√n0(ˆβj−βj)
ˆσ√
ˆwj⊤ˆΣˆwj→N(0,1).
Therefore, we could claim that [ˆβj−Φ−1(1−α/2)ˆσ√n0q
ˆΘ⊤
jˆΣˆΘj,ˆβj+ Φ−1(1−
α/2)ˆσ√n0q
ˆΘ⊤
jˆΣˆΘj]is asymptotically 1−αconfidence interval for βj. Therefore, we
have finished the proof of theorem. □
A.5 Proof of Theorem 5
The proof is similar to the proof of Theorem 4, the difference is that we need to consider
the case where the privacy cost is not dominated by the statistical error. Then, for the
proof of Theorem 5, we follow the proof of Theorem 4 until (A.8). The analysis for the
second term and the third term for (A.8) stays the same. On the other hand, for the
first term of (A.8), we have: We will analyze the three terms in (A.8) one by one. For
the first term, in the same manner, we could decompose this term as:
√n0(ˆΘ⊤
kˆΣ−e⊤
k)(β−ˆβu) =√n0(ˆΘ⊤
kˆΣ−Θ⊤
kˆΣ+Θ⊤
kˆΣ−e⊤
k)(β−ˆβu)
=√n0(ˆΘ⊤
kˆΣ−Θ⊤
kˆΣ)(β−ˆβu) +√n(Θ⊤
kˆΣ−e⊤
k)(β−ˆβu)
(A.12)
Forthefirsttermin(A.12),wecouldfurtherdecomposethistermfrom ˆΣ=1
nPn
i=1xix⊤
i:
√n0(ˆΘ⊤
kˆΣ−Θ⊤
kˆΣ)(β−ˆβu) =√n0(ˆΘ⊤
k−Θ⊤
k)ˆΣ(β−ˆβu)
≤√n0λs(ˆΣ)∥ˆΘk−Θk∥2|β−ˆβu∥2
≤kµ2
s
ν2ss2log2dlog(1/δ) log3n0/n3/2
0ϵ2(A.13)
41Thus, for the second term of (A.12), by Lemma A.3, we have:
√n0(Θ⊤
kˆΣ−e⊤
k)(β−ˆβu)≤√n0∥Θ⊤
kˆΣ−e⊤
k∥∞∥β−ˆβu∥1
≤k√n0r
logd
n0√
s∗∥β−ˆβu∥2
≤k·p
s∗logd· ∥β−ˆβu∥2 (A.14)
When the privacy cost is not dominated by the statistical error and also s∗logd/√n=
o(1), we can observe that the equation (A.14) has smaller convergence rate that (A.13).
Then, combining (A.13) and (A.14), there exists a constant k1, such that:
√n(ˆΘ⊤
kˆΣ−e⊤
j)(β−ˆβu)≤γµ2
s
ν2ss2log2dlog(1/δ) log3n0
n3/2
0ϵ2
Then, insert the result into (A.8), we have:
√n0(ˆβj−βj) =O 
−µ2
s
ν2ss2log2dlog(1/δ) log3n0
n3/2
0ϵ2!
+1√n0ˆΘ⊤
kX⊤W+√n0Ek(A.15)
Notice that for the first term on the right hand, the constant could be set to 1 because
it comes from the tail bound of Laplace random variable. From the result in (A.15), we
could also apply the central limit theorem to show that the second term is asymptoti-
cally Gaussian, notice that in the right hand side, the second term and the third term
asymptotically follows a distribution of N(0, σ2ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1 /δ)
n0ϵ2). Also, by the con-
centrationofGaussiandistribution, wehavewithhighprobability, E′≤8∆2
1log(1 /δ)
n0ϵ2.Thus,
the privacy conditions are satisfied. Therefore, we have:
√n0[ˆβj−βj−√n0(Θ⊤
kˆΣ−e⊤
k)(β−ˆβu)]/s
σ2ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
n0ϵ2∼N(0,1)
Then, also by our assumptions and the result in Lemma 4.1, we could claim that σ2=
ˆsigma2+o(1). Thus, finally, the confidence interval is given by:
Jj(α) =
ˆβj−γˆµs2
ˆνs2s2log2dlog(1/δ) log3n0
n2
0ϵ2)−Φ−1(1−α/2)σ√n0s
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
n0ϵ2,
ˆβj+γˆµs2
ˆνs2s2log2dlog(1/δ) log3n0
n2
0ϵ2) + Φ−1(1−α/2)σ√n0s
ˆΘ⊤
kˆΣˆΘk+8∆2
1log(1/δ)
n0ϵ2
which finishes our proof.
42A.6 Proof of Theorem 6
Let us first show that our algorithm is ϵ, δprivate. The major proof lies in the choice of
noise level B3. To decompose, we can find:
ˆΘ1√mmX
i=1ei√n(gi−¯g) =ˆΘ1√mmX
i=1ei√ngi−ˆΘ√n√m mX
i=1ei!
¯g
Then, suppose in an adjacent data set, the different data in denoted as (xij, yij)and
(x′
ij, y′
ij). Then, we calculate:
(ˆΘ1√mmX
i=1ei√ngi−ˆΘ√n√m mX
i=1ei!
¯g)−(ˆΘ1√mmX
i=1ei√ng′
i−ˆΘ√n√m mX
i=1ei!
¯g′)
∞
≤ˆΘ√n√mei(gi−g′
i)−ˆΘ√n√m mX
i=1ei!
(¯g−¯g′)
∞
≤ˆΘ
max√n√mei(gi−g′
i)−√n√m mX
i=1ei!
(¯g−¯g′)
∞
≤(ˆΘ−Θ
max+∥Θ∥max)√n√mei(gi−g′
i)−√n√m mX
i=1ei!
(¯g−¯g′)
∞
≤(ˆΘ−Θ
1+∥Θ∥2)√n√mei(gi−g′
i)
∞+√n√m mX
i=1ei!
(¯g−¯g′)
∞)
≤(o(1) + L)√n√mp
logm(gi−g′
i)
∞+√n√mmp
logm¯g−¯g′
∞)
≤L4√logm√mnxij(πR(yij)−xijˆβ)
∞
≤L4√logm√mncx(R+c0cx√
s∗)
Thus, the privacy could be guaranteed. Then, let us start the proof of consistency.
Throughout the proof, we define n0=m·n,(X,Y)be the whole data set where
X∈Rn0∗dandY∈Rd.U′= max k∈GˆΘ1√mPm
i=1ei√n(gi−¯g). Let us define another
multiplier bootstrap statistic:
U∗= max
k∈G1
mnmX
i=1nX
j=1Σ−1xij(yij−xijβ)eij,
where eijare all standard Gaussian variables. At the same time, we also define:
M0= max
k∈G1
mnmX
i=1nX
j=1Σ−1xij(yij−xijβ)
43Theproofconsiststhreemajorsteps,westartfromthefirststepandmeasure supα∈(0,1)|P(M0≤
CU∗(α))−α|. This measurement is quite straightforward, we could apply Theorem 3.1
from [10]. However, we need to verify Corollary 2.1 from [10]. Notice that for any
k,E[ΘT
kxij(yij−xijβ)]2=σ2ΘT
kΣΘk≥σ2/L. Also, it is not difficult to verify that
ΘT
kxij(yij−xijβ)is sub-exponential. Since from assumption D1, we have xijis sub-
Gaussian and from the linear model, we know that (yij−xijβ)is also, sub-Gaussian.
Then, the condition could be verified. Thus, by applying Theorem 3.1 and also under
the condition where there exists a constant k, k0, k1such that log7(dmn)/mn≤1
(mn)kwe
could have:
sup
α∈(0,1)|P(T0≤CU∗(α))−α| ≤k0·1
(mn)k1+k2v1/3(max(1 ,log(d/v)))2/3+P(∆> v)
≤k2v1/3(max(1 ,log(d/v)))2/3+P(□> v) +o(1),(A.16)
where□represents the maximum element between the two matrix Ω1andΩ2, denote as
∥Ω1−Ω2∥max, where Ω1andΩ2are defined as:
[Ω1]k,l=1
mnmX
i=1nX
j=1Θ⊤
kxij(yij−xT
ijβ)Θl
and
Ω2=σ2Θ
Then, from Corollary 3.1 in [10] and Lemma E.2 in [41], we could verify that ∥Ω1−
Ω2∥max=O(q
logd
n0+log2(dn0) logd
n0). With a proper choice of v, e.g, there exists a constant
κand let v= (q
logd
n0+log2(dn0) logd
n0)1−κ, we have k2v1/3(max(1 ,log(d/v)))2/3+P(□>
v) =o(1). Next, we would like to associate Mwith M0. Similarly, from Theorem 3.2 in
[10] and (A.16), we could have:
sup
α∈(0,1)|P(M≤CU∗(α))−α| ≤o(1) + v1p
max(1,log(d/v1)) +P(∥M−M0∥> v1),
From the definition of MandM0, we have:
√n0(M−M0) = max
1≤k≤d1√n0|(ˆΘk⊤−Θ⊤
k)X⊤W|
Then, for any kin1, . . . , d, by Holder inequality and Cauchy–Schwarz inequality, we
have:
1√n0|(ˆwk⊤−w⊤
k)X⊤W| ≤ ∥ ˆwk⊤−w⊤
k∥1∥1√n0X⊤W∥∞≤√
s∗∥ˆwk⊤−w⊤
k∥2∥1√n0X⊤W∥∞
On one hand, from previous proof, we obtain that ∥ˆwk⊤−w⊤
k∥2=c·q
s∗logd
mnwhen the
privacy cost is dominated by statistical error uniformly for k. On the other hand, by the
44fact that Σhave bounded maximum eigenvalue and traditional linear regression model,
we could apply Bernstein inequality and also obtain that ∥1√n0X⊤W∥∞isO(q
logd
n0).
Combine these two results, we could claim that there exist constants k0such that:
1√n0|(ˆΘk⊤−Θ⊤
k)X⊤W|=k0·(s∗logd/√n0)
uniformlyforall k, thenwecanchoose v1properlysuchthat supα∈(0,1)|P(M≤CU∗(α))−
α|=o(1). At last, we need to relate U∗with U. Our major goal is to prove that CU(α)
andCU∗are close to each other for any α∈(0,1). We first associate Uwith U′. From
the design of private max algorithm, from Lemma 3.4 in [8], suppose l1is the element
chosen from U′andl2is from Uwithout noise injection, we use wto represent the noise
injected when we pick the largest value privately, we find that, for any c >0:
l2
2≤l2
1≤(1 +c)l2
2+ 4(1 + 1 /c)∥w∥2
∞
From Lemma A.1 in [8], we can verify that there exists constant k0, k1such that ∥w∥2
∞≤
k0·s∗log4dlogm
n0. When we choose c=o(1), e.g, c=k1s∗logd
n0, then from the conditions,
we could claim that l1=l2+o(1), also notice that the scale of noise we injected is small,
it is easy to verify that U=U′+o(1). The following discussions will be between U′and
U∗. Denote ⊖as the symmetric difference, then we have:
P(T≤CU(α)⊖T≤CU∗(α))
≤2P(CU∗(α−π(u))< T≤CU∗(α+π(u))) +P(CU∗(α−π(u))> C U(α)) +P(CU∗(α+π(u))< C U(α))
(A.17)
For the first term in (A.17), define π(u) =u1/3max(1 ,log(d/u))2/3, then exist a constant
k0, such that:
P(CU∗(α−π(u))< M≤CU∗(α+π(u)))≤P(M≤CU∗(α+π(u)))−P(M≤CU∗(α−π(u)))≤k·π(u)+o(1)
Then, for the second term and third term in (A.17), from Lemma 3.2 in [10], we have:
P(CU∗(α−π(u))> C U(α)) +P(CU∗(α+π(u))< C U(α))≤2P(∥Ω1−Ω3∥max> u),
where Ω3is defined as:
[Ω3]k,l=1
mmX
i=1nˆΘk(gi−¯g)(gi−¯g)⊤ˆΘl,
andΩ1is defined the same as we defined before. Then, our major focus is to analyze
∥Ω1−Ω3∥max, by triangle inequality, we have ∥Ω1−Ω3∥max≤ ∥Ω1−Ω2∥max+∥Ω3−
Ω2∥max. Since we have analyzed ∥Ω1−Ω2∥maxbefore, we will focus on ∥Ω3−Ω2∥max.
∥Ω3−Ω2∥max≤1
mmX
i=1nˆΘ(gi−¯g)(gi−¯g)⊤ˆΘ−σ2ˆΘΣˆΘ
max+∥σ2ˆΘΣˆΘ−σ2Θ∥max
(A.18)
45We will analyze the two terms separately. We start from the second term in (A.18), we
have:
∥ˆΘΣˆΘ−Θ∥max
≤ ∥(ˆΘ−Θ+Θ)Σ(ˆΘ−Θ+Θ)−Θ∥max
≤ ∥ˆΘ−Θ∥2
1∥Σ∥max+ 2∥ˆΘ−Θ∥1
≤k0s∗2logd
n0+k1s∗r
logd
n0
On the other hand, for the first term in (A.18),notice that:
1
mmX
i=1nˆΘ(gi−¯g)(gi−¯g)⊤ˆΘ=1
mmX
i=1nˆΘgig⊤
iˆΘ−nˆΘ¯g¯g⊤ˆΘ⊤(A.19)
Denote the data set on the i-th local machine as (Xi,Yi)and in the linear model, the
random noise as Wi. Also, we can further decompose the first term by:
1
mmX
i=1ngig⊤
i
=1
mmX
i=1n[X⊤
iWi+X⊤
i(β−ˆβ)
n][X⊤
iWi+X⊤
i(β−ˆβ)
n]⊤
=1
mmX
i=1n[X⊤
iWi
n][X⊤
iWi
n]⊤+1
mmX
i=1n[X⊤
i(β−ˆβ)
n][X⊤
i(β−ˆβ)
n]⊤+2
mmX
i=1n[X⊤
i(β−ˆβ)
n][X⊤
iWi
n]⊤
(A.20)
Then, for the equation (A.19), we have:
∥1
mmX
i=1nˆΘ(gi−¯g)(gi−¯g)⊤ˆΘ−σ2ˆΘΣˆΘ∥max
≤ ∥ˆΘ∥max∥1
mmX
i=1n(gi−¯g)(gi−¯g)⊤ˆΘ−σ2ΣˆΘ∥max
≤ ∥ˆΘ∥2
max∥1
mmX
i=1n(gi−¯g)(gi−¯g)⊤−σ2Σ∥max (A.21)
And, we could insert (A.20) into (A.21),
∥1
mmX
i=1n(gi−¯g)(gi−¯g)⊤−σ2Σ∥max
≤ ∥1
mmX
i=1n[X⊤
iWi
n][X⊤
iWi
n]⊤−σ2Σ∥max+n∥¯g¯g⊤∥max+∥1
mmX
i=1n[X⊤
i(β−ˆβ)
n][X⊤
i(β−ˆβ)
n]⊤∥max
46+∥2
mmX
i=1n[X⊤
i(β−ˆβ)
n][X⊤
iWi
n]⊤∥max (A.22)
We will analyze the four terms in (A.22) one by one. For the first term, it is quite simple,
from the proof of Lemma F.2 in [41], we have the first term is Op(q
logd
m+log2(dm) logd
m).
For the second term, we have:
n∥¯g¯g⊤∥max≤n∥¯g∥2
∞=n∥1
n0X⊤(Y−Xˆβ)∥2
∞
Also, we have:
∥1
n0X⊤(Y−Xˆβ)∥∞
≤ ∥1
n0X⊤(Y−Xβ)∥∞+∥1
n0X⊤X(ˆβ−β)∥∞
≤ ∥1
n0X⊤W∥∞+∥(ˆΣ−Σ)(ˆβ−β)∥∞+∥Σ∥max∥ˆβ−β∥1
≤k0(r
logd
n0) +k1(r
logd
n0)∥ˆβ−β∥1+∥ˆβ−β∥1
≤k0r
logd
n0+k1s∗logd
n0+k2s∗r
logd
n0(A.23)
Thus,forthesecondterm,wecanobtainthat n∥¯g¯g⊤∥max≤k0s∗2logd/m+k1s∗2log2d/m2n.
For the third term, we have:
∥1
mmX
i=1n[X⊤
iXi(β−ˆβ)
n][X⊤
iXi(β−ˆβ)
n]⊤∥max
≤1
mmX
i=1n∥[X⊤
iXi(β−ˆβ)
n][X⊤
iXi(β−ˆβ)
n]⊤∥max
≤1
mmX
i=1n∥[X⊤
iXi(β−ˆβ)
n]∥2
∞
≤1
mmX
i=1n(∥ˆΣi−Σ∥max+∥Σ∥max)2∥β−ˆβ∥2
1
≤1
mmX
i=12n(∥ˆΣi−Σ∥2
max+∥Σ∥2
max)∥β−ˆβ∥2
1
≤1
mmX
i=12n(O(r
logd
n) +O(1))∥β−ˆβ∥2
1
≤k0s∗2logd
m(A.24)
47For the fourth term, we could apply Cauchy-Schwarz inequality, which give us the result:
∥2
mmX
i=1n[X⊤
iXi(β−ˆβ)
n][X⊤
iWi
n]⊤∥max
≤2
mmX
i=1n∥[X⊤
iXi(β−ˆβ)
n][X⊤
iWi
n]⊤∥max
≤2
mmX
i=1n∥X⊤
iXi(β−ˆβ)
n∥∞∥X⊤
iWi
n∥max
≤2
mmX
i=1n∥X⊤
iXi
n∥max∥β−ˆβ∥1∥X⊤
iWi
n∥∞
≤k0n·s∗logd
n0
≤k0s∗logd
m(A.25)
We could combine the result in (A.23), (A.24), (A.25) and insert into (A.22) and into
(A.21). We could finally get the first term of (A.18) has an order of O(q
logd
n0+s∗logd
n0+
s∗2logd
m). Insert this result into (A.17), when uis chosen properly, we could verify that
supα∈(0,1)|P(T≤CU(α))−α|=o(1), which finishes the proof.
A.7 Proof of Theorem 7
The proof of theorem 7 is quite straight forward. We could decompose true βi=u+vi.
Then, ˆβ=ˆu+ˆvi. Thus, from the result of estimation, we could get the result that:
∥u−ˆu∥2
2≤c0s0logd
mn+c2s02logd2log(1/δ) log3mn
m2n2ϵ2,
and
∥ˆvi−vi∥2
2≤c1s1logd
n+c3s12logd2log(1/δ) log3n
n2ϵ2
Also, combing the above two results with the inequality that ∥ˆβi−βi∥2≤ ∥ˆvi−vi∥2+
∥u−ˆu∥2gives the proof of theorem 7. □
A.8 Proof of Theorem 8
The proof of Theorem 8 follows the proof of and Theorem 4 and Theorem 5. We follow
the proof of Theorem 4 until (A.8). The analysis for the second term and the third term
for (A.8) stays the same. We will analyze the three terms in (A.8) one by one. For the
first term, in the same manner, we could decompose this term as:
√n(ˆΘ⊤
jˆΣ−e⊤
j)(β−ˆβu) =√n(ˆΘ⊤
jˆΣ−Θ⊤
jˆΣ+Θ⊤
jˆΣ−e⊤
j)(β−ˆβu)
48=√n(ˆΘ⊤
jˆΣ−Θ⊤
jˆΣ)(β−ˆβu) +√n(Θ⊤
jˆΣ−e⊤
j)(β−ˆβu)
(A.26)
Forthefirsttermin(A.26),wecouldfurtherdecomposethistermfrom ˆΣ=1
nPn
i=1xix⊤
i:
√n(ˆΘ⊤
jˆΣ−Θ⊤
jˆΣ)(β−ˆβu) =√n(ˆΘ⊤
j−Θ⊤
j)ˆΣ(β−ˆβu)
≤√nλs(ˆΣ)∥ˆΘj−Θj∥2|β−ˆβu∥2
≤o(1) +γµ2
s
ν2ss2
1log2dlog(1/δ) log3mn
m2n3/2ϵ2+γµ2
s
ν2ss2
0log2dlog(1/δ) log3n
n3/2ϵ2
(A.27)
Thus, for the second term of (A.26), by Lemma A.3, we have:
√n(Θ⊤
jˆΣ−e⊤
j)(β−ˆβu)≤√n∥Θ⊤
jˆΣ−e⊤
j∥∞∥β−ˆβu∥1
≤k√nr
logd
mn√s∥β−ˆβu∥2
≤k·√nr
slogd
mn· ∥β−ˆβu∥2
≤o(1) +γµ2
s
ν2ss2
1log2dlog(1/δ) log3mn
m2n3/2ϵ2+γµ2
s
ν2ss2
0log2dlog(1/δ) log3n
n3/2ϵ2
(A.28)
Then, combining (A.27) and (A.28), we have that:
√n(ˆΘ⊤
jˆΣ−e⊤
j)(β−ˆβu)≤2γµ2
s
ν2ss2
1log2dlog(1/δ) log3mn
m2n3/2ϵ2+2γµ2
s
ν2ss2
0log2dlog(1/δ) log3n
n3/2ϵ2
Then, insert the result into (A.8), we have:
√n
ˆβj−βj−2γµ2
s
ν2ss2
1log2dlog(1/δ) log3mn
m2n2ϵ2−2γµ2
s
ν2ss2
0log2dlog(1/δ) log3n
n2ϵ2
=1√nˆΘ⊤
jX⊤W+√nE3
(A.29)
From the result in (A.29), notice that the right hand side asymptotically follows a dis-
tribution of N(0, σ2ˆΘ⊤
jˆΣˆΘj+8∆2
1log(1 /δ)
nϵ2). Also, by the concentration of Gaussian dis-
tribution, we have with high probability, E2≤8∆2
1log(1 /δ)
nϵ2). Thus, we have:
√n
ˆβj−βj−2γµ2
s
ν2ss2
1log2dlog(1/δ)
m2n2ϵ2−2γµ2
s
ν2ss2
0log2dlog(1/δ)
n2ϵ2
/r
σ2ˆΘ⊤
jˆΣˆΘj+8∆2
1log(1/δ)
nϵ2∼N(0,1)
Then, we could replace µs, νswith the estimation ˆµs,ˆνsintroduced in Algorithm 5, the
constantcouldbescaledtoonegiventhetailboundofLaplacerandomvariable. Also, for
the estimation of σ, according to the assumption, we have ˆσ=σ+o(1). For simplicity,
49we denote a=2kˆµ2
s
ˆν2ss2
1log2dlog(1 /δ) log3mn
m2n2ϵ2 +2kˆµ2
s
ˆν2ss2
0log2dlog(1 /δ) log3n
n2ϵ2, the confidence is given
by:
Jj(α) =
[ˆβj−a−σΦ−1(1−α/2)√nr
ˆΘ⊤
jˆΣˆΘj+8∆2
1log(1/δ)
nϵ2,ˆβj+a+σΦ−1(1−α/2)√nr
ˆΘ⊤
jˆΣˆΘj+8∆2
1log(1/δ)
nϵ2]
A.9 Proof of Theorem 9
In this proof, we first need to show that our algorithm is (ϵ, δ)private. We assume in two
data sets, the adjacent data set is different in (xij, yij)and(x′
ij, y′
ij). Then, we have:
∥1√nˆΘxijej−1√nˆΘx′
ijej∥∞≤2√n∥ˆΘxijej∥∞
≤2√n∥ˆΘxij∥∞∥ej∥∞
≤2√logn√n∥ˆΘ∥1∥xij∥∞
≤2r
logn
ncx√sc1
According to the choice of B5, the privacy could be guaranteed. Then, let us start the
proof of consistency. In this proof specifically, we define U′= max k∈GˆΘT
k1√nPn
i=1xijej
and also, we define:
M0= max
k∈G1√nnX
j=1ξjk,
where ξjfollows a Gaussian Distribution N(0,Θ⊤
kΣΘkσ2). Also, we define the α-quantile
ofM0asUM0(α). Then, we could start the proof.
We are aiming at proving supα∈(0,1)|P(M≤CU(α))−α|=o(1). First, we could
prove that CU(α)andCU′are close to each other for any α∈(0,1). From the design of
private max algorithm, from Lemma 3.4 in [8], suppose l1is the element chosen from U′
andl2is from Uwithout noise injection, we use wto represent the noise injected when
we pick the largest value privately, we find that, for any c >0:
l2
2≤l2
1≤(1 +c)l2
2+ 4(1 + 1 /c)∥w∥2
∞
From Lemma A.1 in [8], we can verify that there exists constant k0, k1such that ∥w∥2
∞≤
k0·s∗log4dlogn
n. When we choose c=o(1), e.g, c=k1s∗logd
n, then from the conditions,
we could claim that l1=l2+o(1), also notice that the scale of noise we injected is small,
it is easy to verify that U=U′+o(1). The following discussions will be between U′and
UT0.
Motivated by the proof of Theorem 3.1 and Theorem 3.2 in [10], our proof will be
divided into two major parts, to measure the closeness between U′andUM0and measure
50the closeness between TandT0. We start from the measurement between MandM0.
From the definition that M(ˆβ(i)) = max k∈G√n(ˆβ(i)
k−β(i)
k), we notice that for each kin
1,2, . . . , d, we have:
√n(ˆβ(i)−β(i)) =1√nˆΘX⊤
iWi+ (ˆΘΣ−I)(ˆβ−β) +√nE
Then,
|M−M0| ≤(∥1√nˆΘX⊤
iWi∥∞− ∥1√nnX
j=1ξj∥∞) +∥(ˆΘΣ−I)(ˆβ−β) +√nE∥∞
(A.30)
We analyze the two parts in (A.30) separately. For the first term in (A.30). First, from
Lemma 1.1 in [42], we could obtain the result that for any z,supz|P(∥1√nΘX⊤
iWi∥∞≤
z)−P(M0≤z)| ≤c0·1
nc1, where c0andc1are constants. Also,
∥1√nˆΘX⊤
iWi∥∞− ∥1√nΘX⊤
iWi∥∞≤1√n∥ˆΘX⊤
iWi−ΘX⊤
iWi∥∞
≤ ∥ˆΘ−Θ∥1· ∥1√nX⊤
iWi∥∞
≤c·s∗r
logd
np
logd≤c·s∗logdr
1
n=o(1)
On the other hand, we also notice that for the second term in (A.30), following the proof
in Theorem 4, we also know that the second part is o(1), hence finishes the first part of
the proof. In the second part of the proof. By the arguments in the proof of Theorem
3.2 in [10], we have for any v:
sup
α∈(0,1)|P(T≤CU′(α))−α| ≤c01
nc1+c2v1/3(1∨log(d/v))2/3+P(□> v),
where□= max k,lˆΘ⊤
kˆΣˆΘl−Θ⊤
kΣΘ l.Then, we have:
∥ˆΘ⊤ˆΣˆΘ−Θ⊤ΣΘ∥max
≤ ∥ˆΘ⊤ˆΣˆΘ−ˆΘ⊤ΣˆΘ∥max+∥ˆΘΣˆΘ−Θ∥max
≤ ∥ˆΘ∥∞∥ˆΣ−Σ∥max∥ˆΘ∥1+∥(ˆΘ−Θ+Θ)Σ(ˆΘ−Θ+Θ)−Θ∥max
≤L2r
logd
n0+∥ˆΘ−Θ∥2
1∥Σ∥max+ 2∥ˆΘ−Θ∥1
≤k0s∗2logd
n0+k1s∗r
logd
n0,
where k0, k1are constants. Then, with a proper choice of v, we could claim that
supα∈(0,1)|P(T≤CU′(α))−α|=o(1), which finishes the proof.
51B Appendix
In this section, we will give proofs of the corollary in the main proof. We will introduce
them one by one:
B.1 Proof of corollary 1
FollowingtheproofofTheorem1in[2],wecangaintheupperboundofPk
i=1dTV(pZm
+i,pZm
−i),
when we consider the central DP:
1
k kX
i=1dTV(pZm
+i,pZm
−i)!2
≤7mX
t=1EA
kX
i=1Z
Z(Ep⊗n
a[W(z|X)]−Ep⊗n
a⊕i[W(z|X))]2
Epa[W(z|X)]dµ

Also notice that:
Ep⊗n
a⊕i[W(z|X))] =Ep⊗n
a"
dp⊗n
a⊕i
dp⊗naW(z|X))#
=Epa(1 +qa,iϕa,i(X))n· W(z|X)
The last equation is from the definition of condition 1. Also, by the inequality that we
can find constants c0,c1that when x > 0andx≍1/n,(1 + x)n≤1 +c0·nxand
(1−x)n≤1−c0·nx. If we have |qa,iϕa,i(X)| ≍1/n. we could find a constant c2, such
that:
1
k(kX
i=1dTV 
pZm
+i,pZm
−i
)2≤c2q2n2mX
t=1EA"kX
i=1Z
ZEp⊗n
A[ϕa,i(X)W(z|X)]2
Ep⊗n
A[W(z|X)]dµ#
which finishes the proof of corollary 1.
B.2 Proof of Corollary 2
We continue to show the proof of Corollary 2. First, from Theorem 2 in [2], we get a
direct result when condition 2 is satisfied, given all the conditions in corollary 2 hold, we
have:
 
1
kkX
i=1dTV(pZm
+i,pZm
−i)!2
≤7
kq2n2mX
t=1max
a∈AZ
ZVarpa[W(z|X)]
Epa[W(z|X)]dµ
Then, the focus of the proof of this corollary is on the calculation ofR
ZVarpa[W(z|X)]
Epa[W(z|X)]dµ
when the channel Wis a privacy constraint channel Wpriv. For simplicity, we denote
L(z,X) =logWpriv(z|X), where z∈RdandX∈Rn×d. Then, notice that Wprivis
ϵ-differentially private constraint, for two adjacent dataset XandX′, we have:
|L(z,X)−L(z,X′)| ≤ϵ
52By McDiarmid’s inequality, we could claim that Lis√nϵ- subGaussian. So we could
find a constant c, which satisfies that:
E[e2L]≤c·e2E[L]·e2nϵ2
Then, by Jensen inequality, we have:
E[e2L]≤c·(eE[L])2·e2nϵ2
Thus, we have:
Var[Wpriv(z|X)]
E[Wpriv(z|X)]2=E[Wpriv(z|X)2]
(E[Wpriv(z|X)])2−1 =E[e2L]
(E[eL])2−1≤e2nϵ2−1
Thus, we have:
 
1
kkX
i=1dTV(pZm
+i,pZm
−i)!2
≤7
kα2n2mX
t=1max
a∈AZ
ZVarpa[W(z|X)]
Epa[W(z|X)]2·Epa[W(z|X)]dµ
≤7
kα2n2(e2nϵ2−1)mX
t=1max
a∈AZ
ZEpa[W(z|X)]dµ
≤7
kq2mn2(e2nϵ2−1)
which finishes the proof of corollary 2.
B.3 Proof of corollary 3
For an (n, ρ)-estimator ˆθof the true parameter under ℓploss, we define ˆAforAas
ˆA= argmin
a∈A∥θa−ˆθ∥p.
Then, by the triangle inequality, we have
θA−θˆA
p≤θA−ˆθ
p+θˆA−ˆθ
p≤2ˆθ−θA
p.
Because ˆθis an (n, ρ)-estimator under ℓploss, we have,
EZ[EpZ[θZ−θˆZp
p]]≤2pρpP[pZ∈ PΘ] + max
z̸=z′∥θz−θz′∥p
pP[pZ/∈ PΘ](B.1)
≤2pρp+ 4pρp1
τ·τ
4(B.2)
≤3
44pϵp, (B.3)
using the fact that P[pA∈ PΘ]≥1−τ/4and condition 4. Also, from condition 4, Next,
combining condition 4 and B.3, we could have:1
τkPk
i=1P[Ai̸=ˆAi]≤3
4. Also, since the
53Markov relation Ai−Xm−Zm−ˆAiholds for all i, by the standard relation between
total variation distance and hypothesis testing, and also the definition of τto be less
than 1/2, we have:
P[Ai̸=ˆAi]≥τP[ˆAi=−1|Ai= 1] + (1 −τ)P[ˆAi= 1|Ai=−1]
≥τ(P[ˆAi=−1|Ai= 1] + P[ˆAi= 1|Ai=−1])
≥τ(1−dTV(pXm
+i,pXm
−i))
≥τ(1−1/n·dTV(pZm
+i,pZm
−i))
The last inequality uses the definition of total variation, because Zmis generated by Xm
from the privacy constraint channel Wpriv, so for each dataset Xi,i= 1,2, . . . , mon the
i-th machine, let Xijkbe the dataset which changes the order of XijandXik, then for
anyz∈ Z,Wpriv(z|Xi) =Wpriv(z|Xijk). Thus, by the definition of total variation, we
could verify that dTV(pXi
+i,pXi
−i) = 1 /n·dTV(pZi
+i,pZi
−i). Summing over 1≤i≤kand
combining it with the previous bound, we obtain
3
4≥1
τkkX
i=1P[Ai̸=ˆAi]≥1−1
nkkX
i=1dTV(pZn
+i,pZn
−i)
which finishes the proof of corollary 3.
B.4 Proof of Lemma 4.1
Proof of Lemma 4.1: First, we would like to show that our algorithm is (ϵ, δ)-differentially
private. For two adjacent data sets, we have:
1
mn|(πR(yi)−xT
iˆβ)2−(πR(y′
i)−x′
iTˆβ)2|
≤2
mn(πR(yi)−xT
iˆβ)2
≤4
mn(πR(yi)2+ (xT
iˆβ)2)≤4
mn(R2+sc2
0c2
x)
From the definition of Gaussian Mechanism, we could claim that our algorithm is (ϵ, δ)-
differential private. Then, for the convergence rate of our estimated σ, from our algo-
rithm, first, we observe with the choice of R, we claim that with high prob, we have
πR(Y) =Y. Therefore, we have:
|σ2−ˆσ2| ≤ |1
mn∥Xβ+W−Xˆβ∥2
2−σ2|+|E|
≤ |1
mnWTW−σ2|+ (β−ˆβ)ˆΣ(β−ˆβ) +1
mn(β−ˆβ)XTW+|E|
For the first term, we could obtain that |1
mnWTW−σ2|=O(1√mn)Also, we have:
(β−ˆβ)ˆΣ(β−ˆβ)≤λs(Σ)∥β−ˆβ∥2
2
54≤cLslogd
mn+s2log2dlog(1/δ) log3mn
m2n2ϵ2
Then, from Bernstein inequality, we could obtain that:
∥1
mnXTW∥∞=c1·r
logd
mn
Therefore, we claim that:
1
mn(β−ˆβ)XTW
≤1
mn∥β−ˆβ∥1∥XTW∥∞
≤c2√s
mn∥β−ˆβ∥2∥XTW∥∞
≤c3√s r
slogd
mn+slogdp
log(1/δ) log3/2mn
mnϵ!r
logd
mn
=Op 
slogd
mn+slogdp
log(1/δ) log3/2mn
mnϵ·r
slogd
mn!
=Opslogd
mn+s2log2dlog(1/δ) log3mn
m2n2ϵ2
Also, from our algorithm, we have E∼N(0,2B2
2log(1.25/δ)/ϵ2). Then,
|E|=2B2
2log(1/δ)
ϵ2|N(0,1)|=c4R4+s2c4
0c4
xlog(1/δ)
m2n2ϵ2=c5·s2log2dlog(1/δ) log3mn
m2n2ϵ2,
by observing that cx=O(√logd). Combining above inequalities, we have reached our
conclusion. Therefore, we finish our proof.
B.5 Proof of Lemma 4.2
Proof of Lemma 4.2: It is not difficult to verify the privacy conditions. Then, from the
theory of covering number, we could find n1vectors v1,v2, . . . ,vn1, such that for each
s-sparse unit vector v, we have ∥v−vi∥ ≤1/9. Thus, we have:
λs−ˆλs=v∗ˆΣv∗−viˆΣvi
≤v∗ˆΣ(v∗−vi) + (v∗−vi)ˆΣvi
≤2
9λ2s
≤8/9λs
Note that the second last inequality is a direct result of Cauchy inequality and the last
inequality holds because let v∗′be the corresponding eigenvector of λ2s, then we could
55break this eigenvector to two s-sparse vectors v′
1andv′
2such that v∗′=v′
1+v′
2, then
λ2s= (v′
1+v′
2)TˆΣ(v′
1+v′
2)≤4λs.
Also, notice that for the noise ξ, by the concentration of Laplace distribution, we could
find a constant csuch that ξ≤cslogd/√n=o(1)with high probability. By the
definition of λs, we conclude the proof. □
56